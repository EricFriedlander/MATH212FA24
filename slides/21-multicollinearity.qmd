---
title: "Multicollinearity"
author: "Prof. Maria Tackett"
date: "2023-10-25"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 210 - Fall 2023 -  Schedule](https://sta210-fa23.netlify.app/schedule)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: false
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618,
  fig.retina = 3, dpi = 300, fig.align = "center"
)
```

## Announcements

-   Project propsal due

    -   Friday, October 27 (Tuesday labs)

    -   Sunday, October 29 (Thursday labs)

-   HW 03 due Wednesday, November 1

    -   released after Section 002 lecture

## Topics

::: nonincremental
-   Inference for multiple linear regression
-   Checking model conditions
-   Variable transformations
:::

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(patchwork)
library(knitr)
library(kableExtra)
library(countdown)
library(rms)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

## Announcements

-   Project: EDA Due Wednesday, October 30th
-   Oral R Quiz (time to start scheduling it)

::: appex
ðŸ“‹ [AE 13 - Rail Trails](https://mat212fa24.netlify.app/ae/ae-13-mlr-conditions)

- Open up AE 13
:::


## Topics

::: nonincremental
-   Checking model conditions
:::

## Computational setup

```{r}
#| echo: true


# load packages
library(tidyverse)
library(broom)
library(mosaic)
library(mosaicData)
library(patchwork)
library(knitr)
library(kableExtra)
library(scales)
library(countdown)
library(rms)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))
```


## Data: `rail_trail` {.smaller}

::: nonincremental
-   The Pioneer Valley Planning Commission (PVPC) collected data for ninety days from April 5, 2005 to November 15, 2005.
-   Data collectors set up a laser sensor, with breaks in the laser beam recording when a rail-trail user passed the data collection station.
:::

```{r}
#| echo: false
rail_trail <- read_csv("data/rail_trail.csv")
rail_trail
```


Source: [Pioneer Valley Planning Commission](http://www.fvgreenway.org/pdfs/Northampton-Bikepath-Volume-Counts%20_05_LTA.pdf) via the **mosaicData** package.


# Conditions for inference

## Full model

Complete Exercise 0 to fit the so-called "full-model".

## Full model

```{r}
#| echo: FALSE
rt_full_fit <- lm(volume ~ ., data = rail_trail)
tidy(rt_full_fit) |> kable()

rt_full_aug <- augment(rt_full_fit)
```

# Multicollinearity

## What is multicollinearity

**Multicollinearity** is the case when two or more predictor variables are strongly correlated with one another

## Example

Let's assume the true population regression equation is $y = 3 + 4x$

. . .

Suppose we try estimating that equation using a model with variables $x$ and $z = x/10$

$$
\begin{aligned}\hat{y}&= \hat{\beta}_0 + \hat{\beta}_1x  + \hat{\beta}_2z\\
&= \hat{\beta}_0 + \hat{\beta}_1x  + \hat{\beta}_2\frac{x}{10}\\
&= \hat{\beta}_0 + \bigg(\hat{\beta}_1 + \frac{\hat{\beta}_2}{10}\bigg)x
\end{aligned}
$$

## Example

$$\hat{y} = \hat{\beta}_0 + \bigg(\hat{\beta}_1 + \frac{\hat{\beta}_2}{10}\bigg)x$$

-   We can set $\hat{\beta}_1$ and $\hat{\beta}_2$ to any two numbers such that $\hat{\beta}_1 + \frac{\hat{\beta}_2}{10} = 4$

-   Therefore, we are unable to choose the "best" combination of $\hat{\beta}_1$ and $\hat{\beta}_2$

  +   In statistics, we say this model is "unidentifiable" because different parameters combinations can result in the same model

## Why multicollinearity is a problem

-   When we have perfect collinearities, we are unable to get estimates for the coefficients

    -   When we have almost perfect collinearities (i.e. highly correlated predictor variables), the standard errors for our regression coefficients inflate

    -   In other words, we lose precision in our estimates of the regression coefficients

    -   This impedes our ability to use the model for inference

    -   It is also difficult to interpret the model coefficients

## Detecting Multicollinearity {.midi}

Multicollinearity may occur when...

-   There are very high correlations $(r > 0.9)$ among two or more predictor variables, especially when the sample size is small

-   One (or more) predictor variables is an almost perfect linear combination of the others

-   There are interactions between two or more continuous variables

-   There is a categorical predictor with very few observations in the baseline level

## Detecting multicollinearity in the EDA

-   Look at a correlation matrix of the predictor variables, including all indicator variables
    -   Look out for values close to 1 or -1
-   Look at a scatterplot matrix of the predictor variables
    -   Look out for plots that show a relatively linear relationship
-   Look at the distribution of categorical predictors and avoid setting the baseline to a category with very few observations

## Detecting Multicollinearity (VIF)

**Variance Inflation Factor (VIF)**: Measure of multicollinearity in the regression model

$$VIF(\hat{\beta}_j) = \frac{1}{1-R^2_{X_j|X_{-j}}}$$

where $R^2_{X_j|X_{-j}}$ is the proportion of variation $X$ that is explained by the linear combination of the other explanatory variables in the model.

## Detecting Multicollinearity (VIF)

-   Typically $VIF > 10$ indicates concerning multicollinearity

-   Variables with similar values of VIF are typically the ones correlated with each other

-   Use the `vif()` function in the **rms** R package to calculate VIF

## VIF for rail trail model

```{r echo = T}
vif(rt_full_fit)
```

<br>

. . .

`hightemp` and `avgtemp` are correlated. We need to remove <u>**one**</u> of these variables and refit the model.

## Model without `hightemp` {.smaller}

```{r}
m1 <- lm(volume ~ . - hightemp, data = rail_trail)
  
m1 |>
  tidy() |>
  kable(digits = 3)
```

## Model without `avgtemp` {.smaller}

```{r}
m2 <- lm(volume ~ . - avgtemp, data = rail_trail)
  
m2 |>
  tidy() |>
  kable(digits = 3)
```

## Choosing a model {.midi}

Model without **hightemp**:

```{r}
#| echo: false

glance(m1) |>
  select(adj.r.squared, AIC, BIC) |> kable(digits = 2)
```

Model without **avgtemp**:

```{r echo = F}
#| echo: false

glance(m2) |>
  select(adj.r.squared, AIC, BIC) |> kable(digits = 2)
```

. . .

Based on Adjusted $R^2$, AIC, and BIC, the model without **avgtemp** is a better fit. Therefore, we choose to remove **avgtemp** from the model and leave **hightemp** in the model to deal with the multicollinearity.

## Selected model (for now)

```{r}
#| echo: false
tidy(m2) |>
  kable(digits = 3)
```
