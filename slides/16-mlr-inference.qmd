---
title: "MLR: Inference and conditions"
author: "Prof. Eric Friedlander"
date: "2024-10-04"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— MAT 212 - Fall 2024 -  Schedule](https://mat212fa24.netlify.app/schedule)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: false
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
  cache: false
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618,
  fig.retina = 3, dpi = 300, fig.align = "center"
)
```

## Announcements

-   Midterm next Friday 10/11 (right before spring break)
-   Project proposal also due 10/11 but will accept until 10/14 without penalty 

## Topics

::: nonincremental
-   Inference for multiple linear regression
-   Checking model conditions
:::

## Computational setup

```{r}
#| echo: true


# load packages
library(tidyverse)
library(broom)
library(mosaic)
library(ISLR2)
library(patchwork)
library(knitr)
library(kableExtra)
library(scales)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))
```

# Inference for multiple linear regression


## Data: Credit Cards

The data is from the `Credit` data set in the **ISLR2** R package. It is a simulated data set of 400 credit card customers.

```{r}
#| echo: false
Credit |>  glimpse()
```


## Variables

**Features (another name for predictors)**

-   `Income`: Annual income (in 1000's of US dollars)
-   `Rating`: Credit Rating

**Outcome**

-   `Limit`: Credit limit

# Conduct a hypothesis test for $\beta_j$

## [Review: Simple linear regression (SLR)]{.r-fit-text}

```{r}
gf_point(Limit ~ Rating, data = Credit, alpha = 0.5) |> 
  gf_lm()  |> 
  gf_labs(x = "Credit Rating", y = "Income") |> 
  gf_refine(scale_y_continuous(labels = dollar_format()),
            scale_x_continuous(labels = dollar_format()))
```

## SLR model summary

```{r}
income_slr_fit <- lm(Limit ~ Income, data = Credit)

tidy(income_slr_fit) |> kable()
```


## SLR hypothesis test {.midi}

```{r}
#| echo: false

tidy(income_slr_fit) |> kable(digits = 2)
```

1.  **Set hypotheses:** $H_0: \beta_1 = 0$ vs. $H_A: \beta_1 \ne 0$

. . .

2.  **Calculate test statistic and p-value:** The test statistic is $t= 25.89$ . The p-value is calculated using a $t$ distribution with 399 degrees of freedom. The p-value is $\approx 0$ .

. . .

3.  **State the conclusion:** The p-value is small, so we reject $H_0$. The data provide strong evidence that income is a helpful predictor for a credit card holder's credit limit, i.e. there is a linear relationship between income and credit limit.

## Multiple linear regression

```{r}
credit_fit <- lm(Limit ~ Rating + Income, data = Credit)

tidy(credit_fit) |> kable(digits = 2)
```

## Multiple linear regression

The multiple linear regression model assumes $$Y|X_1, X_2,  \ldots, X_p \sim N(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p, \sigma_\epsilon^2)$$

. . .

For a given observation $(x_{i1}, x_{i2}, \ldots, x_{ip}, y_i)$, we can rewrite the previous statement as

$$y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \dots + \beta_p x_{ip} + \epsilon_{i}, \hspace{10mm} \epsilon_i \sim N(0,\sigma_{\epsilon}^2)$$

------------------------------------------------------------------------

## Estimating $\sigma_\epsilon$

For a given observation $(x_{i1}, x_{i2}, \ldots,x_{ip}, y_i)$ the residual is
$$
\begin{aligned}
e_i &= y_{i} - \hat{y_i}\\
&= y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_{i1} + \hat{\beta}_{2} x_{i2} + \dots + \hat{\beta}_p x_{ip})
\end{aligned}
$$

. . .

The estimated value of the regression standard error , $\sigma_{\epsilon}$, is

$$\hat{\sigma}_\epsilon  = \sqrt{\frac{\sum_{i=1}^ne_i^2}{n-p-1}}$$

. . .

As with SLR, we use $\hat{\sigma}_{\epsilon}$ to calculate $SE_{\hat{\beta}_j}$, the standard error of each coefficient. See [Matrix Form of Linear Regression](https://github.com/STA210-Sp19/supplemental-notes/blob/master/regression-basics-matrix.pdf) for more detail.

## MLR hypothesis test: Income {.midi}

1.  **Set hypotheses:** $H_0: \beta_{Income} = 0$ vs. $H_A: \beta_{Income} \ne 0$, given `Rating` is in the model

. . .

2.  **Calculate test statistic and p-value:** The test statistic is $t = 1.32$. The p-value is calculated using a $t$ distribution with $$(n - p - 1) = 400 - 2 -1 = 398$$ degrees of freedom. The p-value is $\approx 0.19$.

. . .

3.  **State the conclusion:** The p-value is not small, so we fail to reject $H_0$. The data does not provide convincing evidence that a borrowers income is a useful predictor in a model that already contains credit rating as a predictor for the credit limit of a borrower.

::: appex
Complete Exercises 1-2.
:::


# Confidence interval for $\beta_j$

## Confidence interval for $\beta_j$ {.midi}

-   The $C\%$ confidence interval for $\beta_j$ $$\hat{\beta}_j \pm t^* SE(\hat{\beta}_j)$$ where $t^*$ follows a $t$ distribution with $n - p - 1$ degrees of freedom.

-   **Generically**: We are $C\%$ confident that the interval LB to UB contains the population coefficient of $x_j$.

-   **In context:** We are $C\%$ confident that for every one unit increase in $x_j$, we expect $y$ to change by LB to UB units, holding all else constant.

::: appex
Complete Exercise 3.
:::

## Confidence interval for $\beta_j$

```{r}
#| echo: FALSE
tidy(credit_fit, conf.int = TRUE) |>
  kable(digits = 2)
```


# Inference pitfalls

## Large sample sizes

::: callout-caution
If the sample size is large enough, the test will likely result in rejecting $H_0: \beta_j = 0$ even $x_j$ has a very small effect on $y$.

::: nonincremental
-   Consider the **practical significance** of the result not just the statistical significance.

-   Use the confidence interval to draw conclusions instead of relying only p-values.
:::
:::

## Small sample sizes

::: callout-caution
If the sample size is small, there may not be enough evidence to reject $H_0: \beta_j=0$.

::: nonincremental
-   When you fail to reject the null hypothesis, **DON'T** immediately conclude that the variable has no association with the response.

-   There may be a linear association that is just not strong enough to detect given your data, or there may be a non-linear association.
:::
:::

::: appex
Complete exercise 4
:::