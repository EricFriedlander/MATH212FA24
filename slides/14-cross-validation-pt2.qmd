---
title: "Cross validation application"
author: "Prof. Maria Tackett"
date: "2023-10-23"
date-format: "MMM DD, YYYY"
footer: "[ðŸ”— STA 210 - Fall 2023 -  Schedule](https://sta210-fa23.netlify.app/schedule)"
logo: "../images/logo.png"
format: 
  revealjs:
    theme: slides.scss
    multiplex: false
    transition: fade
    slide-number: false
    incremental: false 
    chalkboard: true
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
execute:
  freeze: auto
  echo: true
knitr:
  opts_chunk: 
    R.options:      
    width: 200
bibliography: references.bib
---

```{r}
#| include: false

# figure options
knitr::opts_chunk$set(
  fig.width = 10, fig.asp = 0.618,
  fig.retina = 3, dpi = 300, fig.align = "center"
)
```

## Announcements

-   See Ed Discussion for upcoming events and internship opportunities

-   Statistics Experience due Mon, Nov 20 at 11:59pm

-   Prof. Tackett office hours Fridays 1:30 - 3:30pm for the rest of the semester

-   Start the final project in lab this week - start thinking about the data your team wants to use

## Mid-semester survey {.small}

***Thank you to everyone who filled out the mid-semester survey!***

**Aspect of class most helpful with learning**

-   Application exercises
-   Lectures
-   Discussing content with others

**Something to do in class to better help with learning**

-   Zooming out more / reminder of the big picture
-   Taking time to finish AEs (perhaps do some of this in lab)
-   More conceptual questions on assignments, specifically HW

**Things you do that are helpful with learning**

-   Attend office hours!
-   Review course materials
-   Lots practice - review AEs, HW, labs

## Mid-semester survey

**Why we do in-class exams**

-   Opportunity to demonstrate understanding of concepts and how they apply to application

    -   This is what will make you stand out as a statistician/ data scientist!

-   In-class provides the most "level" playing field to demonstrate conceptual understanding, given all the online resources available now

-   Lots of other opportunities to demonstrate application skills through labs, HW, final project, and take-home portion of exam

## Statistician of the day: Felicity Enders {.midi}

::: columns
::: {.column width="40%"}
![](images/statistician-of-the-day/enders.jpg){fig-alt="Photo of Dr. Felicity Enders" fig-align="center"}
:::

::: {.column width="60%"}
*Dr.Â Felicity Enders received her PhD from Johns Hopkins Bloomberg School of Public Health. She is a Professor of Biostatistics at the Mayo Clinic. With close to 200 publications, she has worked closely with clinicians, with particular focus on women's health and psychology. Across the medical spectrum, Dr.Â Enders has provided advanced statistical modeling collaboration in clinical trials.*

*She is also passionate about biostatistics education and works to dissolve the hidden curriculum for research, particularly statistical knowledge needed for non-statisticians.*
:::
:::

Source: [hardin47.github.io/CURV/scholars/enders](https://hardin47.github.io/CURV/scholars/enders.html)

## Felicity Enders {.midi}

Dr. Enders was a statistician on an interdisciplinary research team that used logistic regression to identify demographic, clinical, and laboratory variables associated with the presence (or absence) of advanced fibrosis with the aim to create a scoring system that could be used by clinicians.

*"Data from each of the **4 countries were randomly separated into 2/3 and 1/3 of patients for model building and model validation, respectively**. Hence, data on 480 patients were used to build a model, whereas data on 253 patients were used to validate the model."*

*"...cross-validation was used with 20 subgroups, so that at most 5% of the data under consideration was excluded at any one time. **By employing cross-validation, the possibility of an unusually positive or negative validation subset could be assessed.**"*

Angulo, Paul, et al. "[The NAFLD fibrosis score: a noninvasive system that identifies liver fibrosis in patients with NAFLD](https://aasldpubs.onlinelibrary.wiley.com/doi/10.1002/hep.21496)." *Hepatology* 45.4 (2007): 846-854.

## Topics

::: nonincremental
-   Cross validation application exercise
:::

## Computational setup

```{r}
#| echo: true

# load packages
library(tidyverse)
library(tidymodels)
library(patchwork)
library(knitr)
library(kableExtra)
library(countdown)
library(rms)

# set default theme and larger font size for ggplot2
ggplot2::theme_set(ggplot2::theme_bw(base_size = 20))
```

# Introduction

## Data: Restaurant tips

Which variables help us predict the amount customers tip at a restaurant?

```{r}
#| echo: false
#| message: false
tips <- read_csv(here::here("slides", "data/tip-data.csv")) |>
  filter(!is.na(Party))
```

```{r}
#| echo: false
tips |>
  select(Tip, Party, Meal, Age, Alcohol)

tips <- tips |>
  mutate(
    Meal = fct_relevel(Meal, "Lunch", "Dinner", "Late Night"),
    Age  = fct_relevel(Age, "Yadult", "Middle", "SenCit")
  )
```

## Variables

**Predictors**:

::: nonincremental
-   `Party`: Number of people in the party
-   `Meal`: Time of day (Lunch, Dinner, Late Night)
-   `Age`: Age category of person paying the bill (Yadult, Middle, SenCit)
-   `Alcohol`: Whether the party ordered alcohol with the meal (Yes, No)
:::

**Outcome**: `Tip`: Amount of tip

## Outcome: `Tip`

```{r}
#| echo: false
ggplot(tips, aes(x = Tip)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of tips")
```

## Predictors

```{r}
#| echo: false
p1 <- ggplot(tips, aes(x = Party)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Number of people in party")

p2 <- ggplot(tips, aes(x = Meal)) +
  geom_bar() +
  labs(title = "Meal type")

p3 <- ggplot(tips, aes(x = Age)) +
  geom_bar() +
  labs(title = "Age of payer")

p4 <- ggplot(tips, aes(x = Alcohol))+ 
  geom_bar() + 
  labs(title = "Ordered alcohol")

(p1 + p2) / (p3 + p4)
```

## Outcome vs. predictors

```{r}
#| echo: false
#| fig.width: 12
#| fig.height: 4

p5 <- ggplot(tips, aes(x = Party, y = Tip)) +
  geom_point(color = "#5B888C")

p6 <- ggplot(tips, aes(x = Meal, y = Tip, fill = Meal)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d(end = 0.8)

p7 <- ggplot(tips, aes(x = Age, y = Tip, fill = Age)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d(option = "E", end = 0.8)

p8 <- ggplot(tips, aes(x = Alcohol, y = Tip, fill = Alcohol)) +
  geom_boxplot(show.legend = FALSE) +
  scale_fill_viridis_d(option = "A", end = 0.8)

(p5 + p6)/ (p7 + p8)
```

## Analysis goal {.midi}

::: question
Use cross validation to evaluate and select a model to predict the tip amount
:::

. . .

**v-fold cross validation** -- commonly used resampling technique:

-   Randomly split your **training** **data** into ***v*** partitions
-   Use ***v-1*** partitions for analysis, and the remaining 1 partition for assessment
-   Repeat ***v*** times, updating which partition is used for assessment each time

# Application exercise

::: appex
ðŸ“‹ <https://sta210-fa23.netlify.app/ae/ae-11-cross-validation>
:::

# Inference for multiple linear regression

## Modeling workflow

-   Split data into training and test sets.

-   Use cross validation on the training set to fit, evaluate, and compare candidate models. Choose a final model based on summary of cross validation results.

-   Refit the model using the entire training set and do "final" evaluation on the test set (make sure you have not overfit the model).

    -   Adjust as needed if there is evidence of overfit.

-   Use model fit on training set for inference and prediction.
