{
  "hash": "3322f7b6338b87162958515f822ca08d",
  "result": {
    "markdown": "---\ntitle: Final project\n---\n\n\n\n\nInstructions will be posted when the project is assigned.\n\n## Timeline\n\n[Project proposal](#project-proposal)\n\n-   due Friday, October 27 (Tuesday labs)\n\n-   due Sunday, October 29 (Thursday labs)\n\n[Draft report + peer review](#draft-report-peer-review)\n\n-   due Tuesday, November 14 (Tuesday labs)\n\n-   due Thursday, November 16 (Thursday labs)\n\n[Round 1 submission (optional)](#round1-submission) due Friday, December 1\n\n[Presentation](#presentation) + \\[Presentation comments \\]\n\n-   Tuesday, December 5 (Tuesday labs)\n\n-   Thursday, December 7 (Thursday labs)\n\n[Written report](#written-report) due Wednesday, December 13\n\n[Reproducibility + organization](#reproducibility-organization) due Wednesday, December 13\n\n## Introduction\n\n**TL;DR**: *Pick a data set and do a regression analysis. That is your final project.*\n\nThe goal of the final project is for you to use regression analysis to analyze a data set of your own choosing. The data set may already exist or you may collect your own data by scraping the web.\n\nChoose the data based on your group's interests or work you all have done in other courses or research projects. The goal of this project is for you to demonstrate proficiency in the techniques we have covered in this class (and beyond, if you like!) and apply them to a data set to analyze it in a meaningful way.\n\nAll analyses must be done in RStudio, and your analysis and written report **must be reproducible**.\n\n### Logistics\n\nYou will work on the project with your lab groups.\n\nThe four primary deliverables for the final project are\n\n1.  A written, reproducible report detailing your analysis\n\n2.  A GitHub repository corresponding to your report\n\n3.  Slides + an in-person presentation\n\n4.  Formal peer review on another team's work\n\n## Project proposal {#project-proposal}\n\n::: callout-important\n## Due dates\n\n-   Friday, October 27 (Tuesday labs)\n\n<!-- -->\n\n-   Sunday, October 29 (Thursday labs)\n:::\n\nThe purpose of the project proposal is for your team to identify the data set you're interested in analyzing for the project, do some prelminary exploratory data analysis, and begin to think about a modeling strategy . If you're unsure where to find data, you can use the list of potential data sources on the [Tips + resources](project-tips.qmd) page as a starting point. It may also help to think of topics you're interested in investigating and find data sets on those topics.\n\nThe data set must meet the following criteria:\n\n-   At least 500 observations\n\n-   At least 10 columns, such that at least 6 of the columns are useful and unique predictor variables.\n\n    -   E.g., identifier variables such as \"name\", \"social security number\", etc. are not useful predictor variables.\n    -   E.g., if you have multiple columns with the same information (e.g. \"state abbreviation\" and \"state name\"), then they are not unique predictors.\n\n-   At least one variable that can be identified as a reasonable response variable.\n\n    -   The response variable can be quantitative or categorical.\n\n-   A mix of quantitative and categorical variables that can be used as predictors.\n\n-   May not be data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n::: callout-warning\n## Types of data sets to avoid\n\n-   Data that are likely violate the independence condition. Therefore, avoid data with repeated measures, data collected over time, etc.\n\n-   Data sets in which there is no information about how the data were originally collected\n\n-   Data sets in which there are missing or unclear definitions about the variables\n:::\n\nAsk a member of the teaching team if you're unsure whether your data set meets the criteria.\n\nThe proposal will include the following:\n\n### Section 1: Introduction\n\nThe introduction section includes\n\n-   an introduction to the subject matter you're investigating (citing any relevant literature)\n\n-   the motivation for your research question (citing any relevant literature)\n\n-   the primary research question you are interested in exploring\n\n-   your team's hypotheses regarding the research question\n\n    -   This is narrative about what you think regarding the research question, not formal statistical hypotheses.\n\n### Section 2: Data description\n\nThe data description section includes\n\n-   the source of the data set\n\n-   description of how when and how the data were originally collected (by the original data curator, not necessarily how you found the data)\n\n-   description of the observations and general characteristics being measured\n\n### Section 3: Initial exploratory data analysis\n\nIn this section, you will begin to explore the data. This includes using narrative, visualizations and summary statistics to describe the following:\n\n-   distribution of the response variable\n\n-   distributions of one potential quantitative predictor variable and one potential categorical predictor variable\n\n-   the relationships between the response variable and each of the predictors from the previous step\n\n-   a potential interaction effect you're interested in exploring (it doesn't have to be an interaction with the two predictors from above)\n\nThese steps are just to get your started on exploratory data analysis and will not be the complete EDA for the final report. The requirements above are the minimum requirements, but your group is welcome to include more at this stage.\n\nIn this section, you will also describe any data cleaning you need to do to prepare for modeling, such as imputing missing values, collapsing levels for categorical predictors, creating new variables, summarizing data, etc.\n\n### Section 4: Analysis approach\n\nIn this section, you will provide a brief overview of your analysis approach. This includes\n\n-   description of the response variable and list of all potential predictors\n\n-   regression model technique (multiple linear regression or logistic regression)\n\n### Data dictionary (aka code book)\n\nSubmit a data dictionary for all the variables in your data set in the `README` of the `data` folder. You do [not]{.underline} need to include the data dictionary in the PDF document.\n\n### Submission\n\n::: callout-important\nWrite your narrative for Sections 1 - 4 in the `proposal.qmd` file. Put the data set and the data dictionary in the `data` folder.\n\nSubmit the PDF of the proposal to Gradescope. Mark all pages of the document.\n:::\n\n### Grading\n\nThe anticipated length, including all graphs, tables, narrative, etc., is 2 -4 pages; it may not exceed **5 pages.**\n\nThe proposal is worth 15 points and will be graded based on accurately and comprehensively addressing the criteria stated above. Points will be assigned based on a holistic review of the project proposal.\n\n-   **Excellent (14 - 15 points) :** All required elements are completed and are accurate. There is a thorough exploration of the data and the team has demonstrated a careful and thoughtful approach exploring the data and preparing it for analysis. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\n\n-   **Strong: (11 - 13 points):** Requirements are mostly met, but there are some elements that are incomplete or inaccurate. Some minor revision of the work required before team is ready for modeling.\n\n-   **Satisfactory (8 - 10 points):** Requirements partially met, but there are some elements that are incomplete and/or inaccurate. Major revision of the work required before team is ready for modeling.\n\n-   **Needs Improvement (7 or fewer points points):** Requirements are largely unmet, and there are large elements that are incomplete and/or inaccurate. Substantial revisions of the work required before team is ready for modeling. \\--\\>\n\n## Written report {#written-report}\n\n<!-- Your written report must be completed in the `written-report.qmd` file and must be reproducible. All team members should contribute to the GitHub repository, with regular meaningful commits. -->\n\n<!-- ::: callout-note -->\n\n<!-- Before you finalize your write up, make sure the code chunks are not visible and all messages and warnings are suppressed. -->\n\n<!-- ::: -->\n\n<!-- **You will submit the PDF of your final report on GitHub.** -->\n\n<!-- The PDF you submit must match the .qmd in your GitHub repository *exactly*. The mandatory components of the report are below. You are free to add additional sections as necessary. The report, including visualizations, should be **no more than 10 pages long.** There is no minimum page requirement; however, you should comprehensively address all of the analysis and report. -->\n\n<!-- Be selective in what you include in your final write-up. The goal is to write a cohesive narrative that demonstrates a thorough and comprehensive analysis rather than explain every step of the analysis. -->\n\n<!-- You are welcome to include an appendix with additional work at the end of the written report document; however, grading will largely be based on the content in the main body of the report. You should assume the reader will not see the material in the appendix unless prompted to view it in the main body of the report. The appendix should be neatly formatted and easy for the reader to navigate. It is not included in the 10-page limit. -->\n\n<!-- ### Introduction and data -->\n\n<!-- This section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won't fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships. -->\n\n<!-- **Grading criteria** -->\n\n<!-- The research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics. -->\n\n<!-- ### Methodology -->\n\n<!-- This section includes a brief description of your modeling process. Explain the reasoning for the type of model you're fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process. -->\n\n<!-- **Grading criteria** -->\n\n<!-- The analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content. -->\n\n<!-- ### Results -->\n\n<!-- This is where you will output the final model with any relevant model fit statistics. -->\n\n<!-- Describe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader. -->\n\n<!-- **Grading criteria** -->\n\n<!-- The model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model's predictive power is thoroughly assessed. -->\n\n<!-- ### Discussion + Conclusion -->\n\n<!-- In this section you'll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work. -->\n\n<!-- **Grading criteria** -->\n\n<!-- Overall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described. -->\n\n<!-- ### Organization + formatting -->\n\n<!-- This is an assessment of the overall presentation and formatting of the written report. -->\n\n<!-- **Grading criteria** -->\n\n<!-- The report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages. -->\n\n<!-- ### Submission -->\n\n<!-- ::: callout-important -->\n\n<!-- The written report is due on **Friday, December 09, 11:59pm** and will be accepted with no late penalty until **Sunday, December 11, 11:59pm**. -->\n\n<!-- Push the file `written-report.qmd` and the rendered `written-report.pdf` go the GitHub repo by the deadline. You will \\<u\\>not</u> submit the report on Gradescope. -->\n\n<!-- **The version of the report in the repo by the Sunday, December 11, 11:59pm will be the one that is graded.** -->\n\n<!-- ::: -->\n\n## Draft report + peer review {#draft-report-peer-review}\n\n## Round 1 submission (optional) {#round1-submission}\n\n<!-- ## Round 1 submission (optional) {#draft-report} -->\n\n<!-- The Round 1 submission is an opportunity to receive detailed feedback on your analysis and [written report](#written-report). The feedback will only be on the content that is submitted, so more \"complete\" drafts will receive more detailed feedback. At this stage, you will also be notified of the grade you would receive at that point. You will have the option to keep the grade (and thus you don't need to turn in an updated report) or resubmit the written report by the final submission deadline for grading. -->\n\n<!-- To submit the draft: -->\n\n<!-- 1\\. Push the updated `written-report.qmd` and `written-report.pdf` to your GitHub repo. -->\n\n<!-- 2\\. Open an issue with the title \"Round 1 Submission\". You can use the template issue in the GitHub repo. Make sure I am tagged in the issue (\\@matackett), so I receive notification of your Round 1 submission. See [Creating an issue from a repository](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue#creating-an-issue-from-a-repository) for instructions on opening an issue. Please ask a member of the teaching team for assistance if you need help opening the issue. -->\n\n<!-- ::: callout-important -->\n\n<!-- You must complete <u>both</u> steps by **Tuesday, November 22, 11:59pm** to receive preliminary feedback.\\ -->\n\n<!-- \\ -->\n\n<!-- Reports submitted after that date will not receive preliminary feedback. -->\n\n<!-- ::: -->\n\n<!-- Note that this is optional, so there is <u>**no**</u> grading penalty for turning in nothing for the Round 1 submission. Due to time constraints at the end of the semester, only high-level feedback will be given for the reports submitted at the final written report deadline in December. -->\n\n## Presentation {#presentation}\n\n<!-- ## Video presentation + slides {#video-presentation-slides} -->\n\n<!-- ### Slides -->\n\n<!-- In addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality. -->\n\n<!-- The slide deck should have no more than 6 content slides + 1 title slide. Here is a <u>suggested</u> outline as you think through the slides; you do <u>not</u> have to use this exact format for the 6 slides. -->\n\n<!-- -   Title Slide -->\n\n<!-- -   Slide 1: Introduce the topic and motivation -->\n\n<!-- -   Slide 2: Introduce the data -->\n\n<!-- -   Slide 3: Highlights from EDA -->\n\n<!-- -   Slide 4: Final model -->\n\n<!-- -   Slide 5: Interesting findings from the model -->\n\n<!-- -   Slide 6: Conclusions + future work -->\n\n<!-- ::: callout-important -->\n\n<!-- Create a `presentation` folder in your GitHub repo. Put a PDF of the slides in the `presentation` folder. The slides PDF of your slides must be in the GitHub repo by **Wednesday, December 14, 11:59pm.** -->\n\n<!-- You will \\<u\\>not</u> submit the slides on Gradescope. -->\n\n<!-- ::: -->\n\n<!-- ### Video presentation -->\n\n<!-- For the video presentation, you can speak over your slide deck, similar to the lecture content videos. **The video presentation must be no longer than 7 minutes.** It is fine if the video is shorter than 7 minutes, but it cannot exceed 7 minutes. You may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos: -->\n\n<!-- -   [Recording presentations in Zoom](https://kb.siue.edu/61721) -->\n\n<!-- -   [Apple Quicktime for screen recording](https://support.apple.com/en-gb/guide/quicktime-player/qtp97b08e666/mac) -->\n\n<!-- -   [Windows 10 built-in screen recording functionality](https://www.youtube.com/watch?v=OfPbr1mRDuo) -->\n\n<!-- -   [Kap for screen recording](https://getkap.co/) -->\n\n<!-- Once your video is ready, upload the video to Warpwire, then embed the video in an new discussion post on Sakai. -->\n\n<!-- ::: callout-note -->\n\n<!-- Note: Every team member is expected to speak in the presentation. Part of the grade will be whether every group member had a meaningful speaking role in the presentation. -->\n\n<!-- ::: -->\n\n<!-- #### To upload your video to Warpwire: -->\n\n<!-- -   Click the Warpwire tab in the Sakai site for your section. -->\n\n<!-- -   Click the \"+\" and select \"Upload files\". -->\n\n<!-- -   Locate the video on your computer and click to upload. -->\n\n<!-- -   Once you've uploaded the video to Warpwire, click to share the video and copy the video's URL. You will need this when you post the video in the discussion forum. -->\n\n<!-- #### To post the video to the discussion forum -->\n\n<!-- -   Click the Presentations tab in the course Sakai site. -->\n\n<!-- -   Click the Presentations topic. -->\n\n<!-- -   Click \"Start a new conversation\". -->\n\n<!-- -   Make the title \"Your Team Name: Project Title\". -->\n\n<!-- -   Click the Warpwire icon (between the table and shopping cart icons). -->\n\n<!-- -   Select your video, then click \"Insert 1 item.\" This will embed your video in the conversation. -->\n\n<!-- -   Under the video, paste the URL to your video. This is to ensure peers can see the presentation if they're unable to view the embedded video. -->\n\n<!-- -   You're done! -->\n\n<!-- You can see the Teaching Team example in Sakai. -->\n\n<!-- ::: callout-important -->\n\n<!-- The presentation video must be uploaded to Sakai by **Wednesday, December 14, 11:59pm.** -->\n\n<!-- ::: -->\n\n## **Presentation comments** {#presentation-comments}\n\n<!-- Each student will be assigned 2 presentations to watch. [Click here](https://prodduke-my.sharepoint.com/:x:/g/personal/mt324_duke_edu/ERbjrobTMghFrZDObDgVm44BjK9WcSjtgaZzUoPp1axz9Q?e=aBgZAH) to see your viewing assignments. -->\n\n<!-- Watch the group's video, then click \"Reply\" to post a question for the group. You may not post a question that's already been asked on the discussion thread. Additionally, the question should be (i) substantive (i.e. it shouldn't be \"Why did you use a bar plot instead of a pie chart\"?), (ii) demonstrate your understanding of the content from the course, and (iii) relevant to that group's specific presentation, i.e demonstrating that you've watched the presentation. -->\n\n<!-- ::: callout-important -->\n\n<!-- You may start posting questions and comments on Thursday, December 15. **All comments must be posted by Friday, December 16 at 11:59pm.** -->\n\n<!-- ::: -->\n\n<!-- <i>This portion of the project will be assessed individually.</i> -->\n\n## Reproducibility + organization {#reproducibility-organization}\n\n<!-- All written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized. -->\n\n<!-- The GitHub repo should have the following structure: -->\n\n<!-- -   `README`: Short project description and data dictionary -->\n\n<!-- -   `written-report.qmd` & `written-report.pdf`: Final written report -->\n\n<!-- -   `/data`: Folder that contains the data set for the final project. -->\n\n<!-- -   `/previous-work`: Folder that contains the `topic-ideas`, `project-proposal` , and `written-report-comments.pdf` (if applicable) files. -->\n\n<!-- -   `/presentation`: Folder with the presentation slides. -->\n\n<!--     -   If your presentation slides are online, you can put a link to the slides in a `README.md` file in the `presentation` folder. -->\n\n<!-- -   `*.Rproj`: File specifying the RStudio project -->\n\n<!-- -   `.gitignore`: File listing all files that are in the local RStudio project but not the GitHub repo -->\n\n<!-- Points for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable. -->\n\n<!-- ::: callout-important -->\n\n<!-- **The repo must be ready for grading by Wednesday, December 14, 11:59pm.** -->\n\n<!-- ::: -->\n\n## Peer teamwork evaluation\n\n<!-- You will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly. -->\n\n## Overall grading\n\nThe grade breakdown is as follows:\n\n| Total                          | 100 pts |\n|--------------------------------|---------|\n| Project proposal               | 15 pts  |\n| Draft report + peer review     | 15 pts  |\n| Presentation                   | 20 pts  |\n| Presentation comments          | 5 pts   |\n| Written report                 | 40 pts  |\n| Reproducibility + organization | 5 pts   |\n\n### Grading summary\n\nGrading of the project will take into account the following:\n\n-   Content - What is the quality of research and/or policy question and relevancy of data to those questions?\n\n-   Correctness - Are statistical procedures carried out and explained correctly?\n\n-   Writing and Presentation - What is the quality of the statistical presentation, writing, and explanations?\n\n-   Creativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n-   *90%-100%*: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n\n-   *80%-89%*: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n\n-   *70%-79%*: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n\n-   *60%-69%*: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\n\n-   *Below 60%*: Student is not making a sufficient effort. \\--\\>\n\n## Late work policy\n\nThere is no late work accepted on the draft report or presentation. Other components of the project may be accepted up to 48 hours late. A 10% late deduction will apply for each 24-hour period late.\n\n**Be sure to turn in your work early to avoid any technological mishaps.**\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}