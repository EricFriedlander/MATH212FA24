[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses, with all changes documented here."
  },
  {
    "objectID": "schedule.html#notes",
    "href": "schedule.html#notes",
    "title": "Schedule",
    "section": "Notes",
    "text": "Notes\n\nLab:\n\nLab sections 01 & 02 (Tuesdays): Labs will be due on Fridays at 11:59pm.\nLab sections 03 & 04 (Thursdays): Labs will be due on Sundays at 11:59pm.\n\nProject dates will be added when the project is assigned."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Lecture\nSection 001\nMon & Wed 10:05 - 11:20am\nReuben-Cooke 130\n\n\n\nSection 002\nMon & Wed 1:25 - 2:40pm\nOld Chem 116\n\n\nLab\nLab 01\nTue 10:05 - 11:20am\nReuben-Cooke 129\n\n\n\nLab 02\nTue 11:45am - 1pm\nLSRC A155\n\n\n\nLab 03\nThu 10:05 - 11:20am\nReuben-Cooke 129\n\n\n\nLab 04\nThu 11:45am - 1pm\nSocial Sciences 124\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\n\nProf. Maria Tackett\nInstructor\nOffice Hours: Fri 1 - 3pm\n\n\nSam Rosen\nHead TA\nLab 01: Tue 10:05 - 11:20am\n\n\nBethany Astor\nTA\nLab 02: Tue 11:45am - 1pm\n\n\nJon Campbell\nTA\n\n\n\nDonald Cayton\nTA\nLab 02: Tue 11:45am - 1pm\n\n\nAllison Li\nTA\n\n\n\nMitchelle Mojekwu\nTA\nLab 04: Thu 11:45am - 1pm\n\n\nBen Thorpe\nTA\n\n\n\nLinxuan Wang\nTA\nLab 03: Thu 10:05 - 11:20am\n\n\nXiaojun Zheng\nTA\nLab 04: Thu 11:45am - 1pm\n\n\n\n\n\n\n\n\n\nClick here for schedule of office hours."
  },
  {
    "objectID": "syllabus.html#course-info",
    "href": "syllabus.html#course-info",
    "title": "Syllabus",
    "section": "",
    "text": "Lecture\nSection 001\nMon & Wed 10:05 - 11:20am\nReuben-Cooke 130\n\n\n\nSection 002\nMon & Wed 1:25 - 2:40pm\nOld Chem 116\n\n\nLab\nLab 01\nTue 10:05 - 11:20am\nReuben-Cooke 129\n\n\n\nLab 02\nTue 11:45am - 1pm\nLSRC A155\n\n\n\nLab 03\nThu 10:05 - 11:20am\nReuben-Cooke 129\n\n\n\nLab 04\nThu 11:45am - 1pm\nSocial Sciences 124\n\n\n\n\n\n\n\n\n\nName\nRole\n\n\n\n\n\nProf. Maria Tackett\nInstructor\nOffice Hours: Fri 1 - 3pm\n\n\nSam Rosen\nHead TA\nLab 01: Tue 10:05 - 11:20am\n\n\nBethany Astor\nTA\nLab 02: Tue 11:45am - 1pm\n\n\nJon Campbell\nTA\n\n\n\nDonald Cayton\nTA\nLab 02: Tue 11:45am - 1pm\n\n\nAllison Li\nTA\n\n\n\nMitchelle Mojekwu\nTA\nLab 04: Thu 11:45am - 1pm\n\n\nBen Thorpe\nTA\n\n\n\nLinxuan Wang\nTA\nLab 03: Thu 10:05 - 11:20am\n\n\nXiaojun Zheng\nTA\nLab 04: Thu 11:45am - 1pm\n\n\n\n\n\n\n\n\n\nClick here for schedule of office hours."
  },
  {
    "objectID": "syllabus.html#course-learning-objectives",
    "href": "syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nuse Quarto to write reproducible reports and GitHub for version control and collaboration.\neffectively communicate statistical results through writing and oral presentations."
  },
  {
    "objectID": "syllabus.html#course-community",
    "href": "syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard(DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors;and\nI will act if the Standard is compromised.\n\n\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, sta210-fa23.netlify.app.\nLinks to Zoom meetings may be found in Sakai. Periodic announcements will be sent via email and will also be available through Ed Discussion and Sakai Announcements. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nGetting help in the course\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours1 to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. You are encouraged to use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the class discussion forum Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, you are encouraged to respond!\n\n\n\nEmail\nIf you have questions about assignment extensions or accommodations, please email sta210@duke.edu. This email address is accessible to me and the head TA. Please see Assignment extensions for more information. If you have any other questions that are not appropriate for the public forum, you are welcome to email me directly at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\nCheck out the Support page for more resources."
  },
  {
    "objectID": "syllabus.html#textbook",
    "href": "syllabus.html#textbook",
    "title": "Syllabus",
    "section": "Textbook",
    "text": "Textbook\nWhile there is no official textbook for the course, readings will primarily be assigned from the following texts (all freely available online).\n\nR for Data Science by Garret Grolemund and Hadley Wickham\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin\nTidy modeling with R by Max Kuhn and Julia Silge\nBeyond Multiple Linear Regression by Paul Roback and Julie Legler"
  },
  {
    "objectID": "syllabus.html#lectures-and-labs",
    "href": "syllabus.html#lectures-and-labs",
    "title": "Syllabus",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nLectures and labs are designed to be interactive, so you gain experience applying new concepts and learning from each other. My role as instructor is to introduce you to new methods, tools, and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to prepare for class by completing assigned readings, attend all lecture and lab sessions, and meaningfully contribute to in-class exercises and discussion. Additionally, some lectures will feature application exercises that will be graded based on completing what we do in class.\nYou are expected to bring a laptop, tablet, or Chromebook to each class so that you can participate in the in-class exercises. Please make sure your device is fully charged before you come to class, as the number of outlets in the classroom will not be sufficient to accommodate everyone."
  },
  {
    "objectID": "syllabus.html#teams",
    "href": "syllabus.html#teams",
    "title": "Syllabus",
    "section": "Teams",
    "text": "Teams\nYou will be assigned to a team at the beginning of the semester. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of the labs and project, and you will be asked to evaluate your team members throughout the semester. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark.\nYou are expected to make use of the provided GitHub repository as the central collaborative platform. Commits to this repository will be used as a metric (one of several) of each team member’s relative contribution for each project."
  },
  {
    "objectID": "syllabus.html#activities-assessment",
    "href": "syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nYou will be assessed based on six components: application exercises, homework, labs, exams, project, and teamwork.\n\nApplication Exercises\nParts of some lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Monday lectures are due Thursday by 11:59p ET, and AEs from Wednesday lectures are due Saturday by 11:59p ET.\nBecause these AEs are for practice, they will be graded based on making a good-faith effort in attempting all questions covered in class. You are welcome to, but not required, to work on AEs beyond lecture. Successful on-time effort on at least 80% of AEs will result in full credit for AEs in the final course grade. Because AEs are intended for in-class activities, there are no extensions given on AEs.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation and communication. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams\nThere will be two exams in this course. Each exam will include a closed-notes in-class component and an open-note take-home component. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. The exams will focus on both conceptual understanding of the content and application through analysis and computational tasks. The content of the exam will be related to the content in reading assignments, lectures, application exercises, homework, and lab assignments. More detail about the exams will be given during the semester.\n\n\nProject\nThe purpose of the final project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work through a written report and presentation. More information about the project will be provided during the semester."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n35%\n\n\nFinal project\n15%\n\n\nLab\n15%\n\n\nExam 01\n15%\n\n\nExam 02\n15%\n\n\nApplication exercises\n2.5%\n\n\nTeamwork\n2.5%\n\n\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60"
  },
  {
    "objectID": "syllabus.html#five-tips-for-success",
    "href": "syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this course depends very much on you and the effort you put into it. The course has been organized so that the burden of learning is on you. Your TAs and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the TAs, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you’re not sure about the homework, ask. If you hear something on the news that sounds related to what we discussed, ask. If the reading is confusing, ask.\nDo the readings.\nDo the homework and lab.The earlier you start, the better. It’s not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon’t procrastinate. The content builds upon what was taught in previous weeks, so if something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, etc. Don’t let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, come to office hours and work with a member of the teaching team to help you identify a good (re)starting point."
  },
  {
    "objectID": "syllabus.html#course-policies",
    "href": "syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don’t cheat!\n\nOnly work that is clearly assigned as team work should be completed collaboratively.\n\n\n\nThe homework assignments must be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to homework questions (including any code) with anyone other than myself and the teaching assistants.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nFor the projects and team labs, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project or team labs across teams.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of artificial intelligence (AI): You should treat AI tools, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:2 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\nAI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\nNo AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments. In general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nIf you are unsure if the use of a particular resource complies with the academic honesty policy, please ask a member of the teaching team.\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects,and more).Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\n\n\nLate work policy\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\nHomework and labs may be submitted up to 2 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work is accepted for application exercises, since these are designed as in-class activities to help you prepare for labs and homework.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email sta210@duke.edu before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nAssignment extensions\nSam Rosen (sta210@duke.edu) will serve as the Head TA this semester. Among many things, Sam’s role is to handle all assignment extension questions. This includes answering questions about the late work policy, along with granting extensions based on the documented arrangements for accommodations and extenuating circumstances via the one-time late waiver or documentation from the Academic Dean. Please see Late work policy and Waiver for extenuating circumstances for more information about these policies.\nPlease direct all questions about late work policies to sta210@duke.edu. This email will be directed to Sam and myself. This email address only accept emails from Duke email addresses.\n\n\nRegrade Requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the final project presentations.\n\n\nAttendance policy\nEvery student is expected to attend and participate in lecture and labs. There may be times, however, when you cannot attend class. Lecture recordings are available upon request for students who have an excused absence. See the Lecture recording request policy for more detail. If you miss a lecture, make sure to review the material and complete the application exercise, if applicable, before the next lecture. Labs dedicated to completing the lab assignment and collaborating with your lab team. If you miss a lab session, make sure to communicate with your lab TA and teammates about how you can make up your contribution. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your lab TA and teammates ahead of time.\nMore details on Trinity attendance policies are available here.\n\nAttendance Policy Related to COVID Symptoms, Exposure, or Infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at coronavirus.duke.edu.\nTo keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\n\nLecture recording request\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week after the lecture date. To request a particular lecture’s video, please fill out the form at forms.office.com/r/FbRXJm4Ln1. Please submit the form within 24 hours of missing lecture to ensure you have sufficient time to watch the recording. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\nAbout one week before each exam, the class recordings will be available to all students. These recordings will be available until 10am the day of the exam."
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you are a student with a disability and need accommodations for this class, it is your responsibility to register with the Student Disability Access Office (SDAO) and provide them with documentation of your disability. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: trinity.duke.edu/undergraduate/academic-policies/religious-holidays"
  },
  {
    "objectID": "syllabus.html#academic-and-wellness-support",
    "href": "syllabus.html#academic-and-wellness-support",
    "title": "Syllabus",
    "section": "Academic and wellness support",
    "text": "Academic and wellness support\n\nAcademic Resource Center\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.\n\n\nCAPS\nDuke Counseling & Psychological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000."
  },
  {
    "objectID": "syllabus.html#important-dates",
    "href": "syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAug 28: Classes begin\nSep 8: Drop/add ends\nOct 16 - 17: Fall break\nNov 10: Last day to withdraw with W\nNov 22 - 26: Thanksgiving recess\nDec 8: Classes end\nDec 9 - 12: Reading period\nDec 13 - 18: Final exams\n\nClick here for the full Duke academic calendar."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOffice hours are times the teaching team set aside each week to meet with students. Click here to learn more about how to effectively use office hours.↩︎\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎↩︎"
  },
  {
    "objectID": "stats-experience.html",
    "href": "stats-experience.html",
    "title": "Statistics Experience",
    "section": "",
    "text": "The world of statistics and data science is vast and continually growing! The goal of the statistics experience assignments is to help you engage with the statistics and data science communities outside of the classroom.\nYou may submit the statistics experience assignment anytime between now and the deadline.\nEach experience has two parts:\n1️⃣ Have a statistics experience.\n2️⃣ Make a slide reflecting on your experience.\nYou must complete both parts to receive credit. The statistics experience will count as a homework grade."
  },
  {
    "objectID": "stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "href": "stats-experience.html#part-1-experience-statistics-outside-of-the-classroom",
    "title": "Statistics Experience",
    "section": "Part 1: Experience statistics outside of the classroom",
    "text": "Part 1: Experience statistics outside of the classroom\nComplete an activity in one of the categories below. Under each category are suggested activities. You do not have to do one these suggested activities. You are welcome to find other activities as long as they are related to statistics/data science and they fit in one of the six categories. If there is an activity you’d like to do but you’re not sure if it qualifies for the statistics experience, just ask!\n\nCategory 1: Attend a talk or conference\nAttend an talk, panel, or conference related to statistics or data science. If you are attending a single talk or panel, it must be at least 30 minutes to count towards the statistics experience. The event can be in-person or online.\n\n\nCategory 2: Talk with a statistician/ data scientist\nTalk with someone who uses statistics in their daily work. This could include a professor, professional in industry, graduate student, etc.\n\n\nCategory 3: Listen to a podcast / watch video\nListen to a podcast or watch a video about statistics and data science. The podcast or video must be at least 30 minutes to count towards the statistics experience. A few suggestions are below:\n\nStats + Stories Podcast\nCausal Inference Podcast\nFiveThirtyEight Model Talk\nrstudio::conf talks\n\n2022 conference\n2021 conference\n2020 conference\n\n\nThis list is not exhaustive. You may listen to other podcasts or watch other statistics/data science videos not included on this list. Ask Professor Tackett if you are unsure whether a particular podcast or video will count towards the statistics experience.\n\n\nCategory 4: Participate in a data science competition or challenge\nParticipate in a statistics or data science competition. You can participate individually or with a team.\n\n\nCategory 5: Read a book on statistics/data science\nThere are a lot of books about statistics, data science, and related topics. A few suggestions are below. If you decide to read a book that isn’t on this list, ask Professor Tackett to make sure it counts toward the experience. Many of these books are available through Duke library.\n\nWeapons of Math Destruction by Cathy O’Neil\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nThe Theory that Would Not Die by Sharon Bertsch McGrayne\nThe Art of Statistics: How to learn from data by David Spiegelhalter\nThe Signal and the Noise: Why so many predictions fail - but some don’t by Nate Silver\nList of books about data science ethics\n\nThis list is not exhaustive.\n\n\nCategory 6: TidyTuesday\nYou may also participate in a TidyTuesday challenge. New data sets are announced on Monday afternoons.You can find more information about TidyTuesday and see the data in the TidyTuesday GitHub repo.\nA few guidelines:\n✅ Create a GitHub repo for your TidyTuesday submission. Your repo should include\n\nThe R Markdown file with all the code needed to reproduce your visualization.\nA README that includes an image of your final visualization and a short summary (~ 1 paragraph) about your visualization.\n\n✅ The visualization should include features or customization that are beyond what we’ve done in class .\n✅ Include the link to your GitHub repo in the slide summarizing your experience.\n\n\nCategory 7: CURV - connecting, uplifting, and recognizing voices\nCURV is a project by Dr. Jo Hardin at Pomona College to highlight statisticians and data scientists from groups who have been historically marginalized in the discipline. We will highlight some of the scholars in the CURV data base through the “Statistician of the Day” during lecture each week.\nThere are two options for this statistics experience:\n1️⃣. Present the Statistician of the Day. Learn about one of the scholars in the CURV data base and present what you learn in class.\nA few guidelines:\n\nLet Professor Tackett know at least one week in advance of when you’d like to present a Statistician of the Day. They will take place at the beginning of lectures on Mondays.\nCreate 1 - 2 slides about the scholar.\nPresent at the beginning of lecture for both lectures. If you are unable to attend the beginning of both lectures, you can present in-person during your lecture period and provide a short video for the other lecture period.\n\n2️⃣ Contribute to the CURV data base. If there is a scholar you would like to suggest for the data base, submit your suggestion as an issue or pull request on the CURV GitHub repo and create a sample CURV page.\nA few guidelines:\n✅ Create a draft of the CURV page for your suggested scholar. For reference, click here for the CURV page for W.E.B. Du Bois. The page must be created in a Quarto document.\n\n\n\n\n\n\nTip\n\n\n\nYou can find the Quarto documents for current scholars in the data base in the CURV GitHub repo. You can use one of these as a template to format your page.\n\n\n✅ Make a pull request to the CURV GitHub repo to add the .qmd file for your suggested scholar, OR open an issue with a link to the .qmd file for your suggested scholar. You can ask a member of the teaching team if you have questions about how to do this.\n✅ Include the URL to your pull request or issue in your one-slide reflection."
  },
  {
    "objectID": "stats-experience.html#part-2-reflect-on-your-experience",
    "href": "stats-experience.html#part-2-reflect-on-your-experience",
    "title": "Statistics Experience",
    "section": "Part 2: Reflect on your experience",
    "text": "Part 2: Reflect on your experience\nMake one slide summarizing and reflecting on your experience. Submit the slide as a PDF on Gradescope.\nInclude the following on your slide:\n\nName and brief description of the event/podcast/competition/etc.\nSomething you found new, interesting, or unexpected\nHow the event/podcast/competition/etc. connects to something we’ve done in class.\nCitation or link to web page for event/competition/etc.\n\nClick here to see a template to help you get started on your slide. Your slide does not have to follow this exact format; it just needs to include the information mentioned above and be easily readable (i.e. use a reasonable font size!). Creativity is encouraged!"
  },
  {
    "objectID": "stats-experience.html#submission",
    "href": "stats-experience.html#submission",
    "title": "Statistics Experience",
    "section": "Submission",
    "text": "Submission\nSubmit the reflection as a PDF under the Statistics Experience assignment on Gradescope by Mon, Nov 20 at 11:59pm. Standard homework late policy applies."
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#announcements",
    "href": "slides/07-slr-conditions-eval.html#announcements",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01: due TODAY at 11:59pm\nLab 03:\n\ndue Fri at 11:59pm (Tue labs)\ndue Sun at 11:59pm (Thu labs)\n\nLooking ahead: Exam 01:\n\nClosed note in-class: Wed, Oct 4\nOpen note take-home: Wed, Oct 4 - Fri, Oct 6\n\nReleased after Section 002\n\nMore about the exam next week"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#computational-set-up",
    "href": "slides/07-slr-conditions-eval.html#computational-set-up",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Computational set up",
    "text": "Computational set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#regression-model-revisited",
    "href": "slides/07-slr-conditions-eval.html#regression-model-revisited",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Regression model, revisited",
    "text": "Regression model, revisited\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#mathematical-representation-visualized",
    "href": "slides/07-slr-conditions-eval.html#mathematical-representation-visualized",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\nImage source: Introduction to the Practice of Statistics (5th ed)"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#model-conditions-1",
    "href": "slides/07-slr-conditions-eval.html#model-conditions-1",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Model conditions",
    "text": "Model conditions\n\nLinearity: There is a linear relationship between the outcome and predictor variables\nConstant variance: The variability of the errors is equal for all values of the predictor variable\nNormality: The errors follow a normal distribution\nIndependence: The errors are independent from each other"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#linearity",
    "href": "slides/07-slr-conditions-eval.html#linearity",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Linearity",
    "text": "Linearity\n\nIf the linear model, \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\) adequately describes the relationship between \\(X\\) and \\(Y\\), then the residuals should reflect random (chance) error\nTo assess this, we can look at a plot of the residuals vs. the fitted values\nLinearity satisfied if there is no distinguishable pattern in the residuals plot, i.e. the residuals should be randomly scattered\nA non-random pattern (e.g. a parabola) suggests a linear model does not adequately describe the relationship between \\(X\\) and \\(Y\\)"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#linearity-1",
    "href": "slides/07-slr-conditions-eval.html#linearity-1",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Linearity",
    "text": "Linearity\n✅ The residuals vs. fitted values plot should show a random scatter of residuals (no distinguishable pattern or structure)"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#residuals-vs.-fitted-values-code",
    "href": "slides/07-slr-conditions-eval.html#residuals-vs.-fitted-values-code",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Residuals vs. fitted values (code)",
    "text": "Residuals vs. fitted values (code)\n\ndf_aug &lt;- augment(df_fit$fit)\n\nggplot(df_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  ylim(-1000000, 1000000) +\n  labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#non-linear-relationships",
    "href": "slides/07-slr-conditions-eval.html#non-linear-relationships",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Non-linear relationships",
    "text": "Non-linear relationships"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#constant-variance",
    "href": "slides/07-slr-conditions-eval.html#constant-variance",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Constant variance",
    "text": "Constant variance\n\nIf the spread of the distribution of \\(Y\\) is equal for all values of \\(X\\)then the spread of the residuals should be approximately equal for each value of \\(X\\)\nTo assess this, we can look at a plot of the residuals vs. the fitted values\nConstant variance satisfied if the vertical spread of the residuals is approximately equal as you move from left to right (i.e. there is no “fan” pattern)\nA fan pattern suggests the constant variance assumption is not satisfied and transformation or some other remedy is required (more on this later in the semester)"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#constant-variance-1",
    "href": "slides/07-slr-conditions-eval.html#constant-variance-1",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Constant variance",
    "text": "Constant variance\n✅ The vertical spread of the residuals is relatively constant across the plot"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#non-constant-variance",
    "href": "slides/07-slr-conditions-eval.html#non-constant-variance",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Non-constant variance",
    "text": "Non-constant variance"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#normality",
    "href": "slides/07-slr-conditions-eval.html#normality",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Normality",
    "text": "Normality\n\nThe linear model assumes that the distribution of \\(Y\\) is Normal for every value of \\(X\\)\nThis is impossible to check in practice, so we will look at the overall distribution of the residuals to assess if the normality assumption is satisfied\nNormality satisfied if a histogram of the residuals is approximately normal\n\nCan also check that the points on a normal QQ-plot falls along a diagonal line\n\nMost inferential methods for regression are robust to some departures from normality, so we can proceed with inference if the sample size is sufficiently large, \\(n &gt; 30\\)"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#normality-1",
    "href": "slides/07-slr-conditions-eval.html#normality-1",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Normality",
    "text": "Normality"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#check-normality-using-a-qq-plot",
    "href": "slides/07-slr-conditions-eval.html#check-normality-using-a-qq-plot",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Check normality using a QQ-plot",
    "text": "Check normality using a QQ-plot\n\n\n\n\nCode\nggplot(df_aug, aes(x = .resid)) +\n  geom_histogram(binwidth = 50000, color = \"white\")  +\n  labs(\n    x = \"Residual\",\n    y = \"Count\",\n    title = \"Histogram of residuals\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(df_aug, aes(sample = .resid)) +\n  stat_qq()+\n  stat_qq_line() + \n  labs(x = \"Theoretical quantile\", \n       y = \"Observed quantile\", \n       title = \"Normal QQ-plot of residuals\")\n\n\n\n\n\n\n\n\n\n\n\n\nAssess whether residuals lie along the diagonal line of the Quantile-quantile plot (QQ-plot).\nIf so, the residuals are normally distributed."
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#normality-2",
    "href": "slides/07-slr-conditions-eval.html#normality-2",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Normality",
    "text": "Normality\n\n❌ The residuals do not appear to follow a normal distribution, because the points do not lie on the diagonal line, so normality is not satisfied.\n✅ The sample size \\(n = 98 &gt; 30\\), so the sample size is large enough to relax this condition and proceed with inference."
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#independence",
    "href": "slides/07-slr-conditions-eval.html#independence",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Independence",
    "text": "Independence\n\nWe can often check the independence assumption based on the context of the data and how the observations were collected\nTwo common violations of the independence assumption:\n\nSerial Effect: If the data were collected over time, plot the residuals in time order to see if there is a pattern (serial correlation)\nCluster Effect: If there are subgroups represented in the data that are not accounted for in the model (e.g., type of house), you can color the points in the residual plots by group to see if the model systematically over or under predicts for a particular subgroup"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#independence-1",
    "href": "slides/07-slr-conditions-eval.html#independence-1",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Independence",
    "text": "Independence\nRecall the description of the data:\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\n\n\n✅ Based on the information we have, we can reasonably treat this as a random sample of Duke Forest Houses and assume the error for one house does not tell us anything about the error for another house."
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#recap",
    "href": "slides/07-slr-conditions-eval.html#recap",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Recap",
    "text": "Recap\nUsed residual plots to check conditions for SLR:\n\n\n\n\nLinearity\nConstant variance\n\n\n\n\n\nNormality\nIndependence\n\n\n\n\n\n\nWhich of these conditions are required for fitting a SLR? Which for simulation-based inference for the slope for an SLR? Which for inference with mathematical models?\n\nEd Discussion [Section 001][Section 002]\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#comparing-inferential-methods",
    "href": "slides/07-slr-conditions-eval.html#comparing-inferential-methods",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Comparing inferential methods",
    "text": "Comparing inferential methods\n\n\nWhat are the advantages of using simulation-based inference methods? What are the advantages of using inference methods based on mathematical models?\nUnder what scenario(s) would you prefer to use simulation-based methods? Under what scenario(s) would you prefer to use methods based on mathematical models?\n\n\n\n\n\n−+\n02:00"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#two-statistics",
    "href": "slides/07-slr-conditions-eval.html#two-statistics",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\n\n\n\nWhat indicates a good model fit? Higher or lower \\(R^2\\)? Higher or lower RMSE?"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#r2",
    "href": "slides/07-slr-conditions-eval.html#r2",
    "title": "SLR: Conditions + Model evaluation",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\nRanges between 0 (terrible predictor) and 1 (perfect predictor)\nHas no units\nCalculate with rsq() using the augmented data:\n\n\nrsq(df_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.445"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#interpreting-r2",
    "href": "slides/07-slr-conditions-eval.html#interpreting-r2",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\n🗳️ Discussion\n\n\nThe \\(R^2\\) of the model for price from area of houses in Duke Forest is 44.5%. Which of the following is the correct interpretation of this value?\n\n\nArea correctly predicts 44.5% of price for houses in Duke Forest.\n44.5% of the variability in price for houses in Duke Forest can be explained by area.\n44.5% of the variability in area for houses in Duke Forest can be explained by price\n44.5% of the time price for houses in Duke Forest can be predicted by area."
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#alternative-approach-for-r2",
    "href": "slides/07-slr-conditions-eval.html#alternative-approach-for-r2",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Alternative approach for \\(R^2\\)",
    "text": "Alternative approach for \\(R^2\\)\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(df_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared   sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.445         0.439 168798.      77.0 6.29e-14     1 -1318. 2641. 2649.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\nglance(df_fit)$r.squared\n\n[1] 0.4451945"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#rmse",
    "href": "slides/07-slr-conditions-eval.html#rmse",
    "title": "SLR: Conditions + Model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nCalculate with rmse() using the augmented data:\n\nrmse(df_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     167067.\n\n\nThe value of RMSE is not very meaningful on its own, but it’s useful for comparing across models (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/07-slr-conditions-eval.html#obtaining-r2-and-rmse",
    "href": "slides/07-slr-conditions-eval.html#obtaining-r2-and-rmse",
    "title": "SLR: Conditions + Model evaluation",
    "section": "Obtaining \\(R^2\\) and RMSE",
    "text": "Obtaining \\(R^2\\) and RMSE\n\n\nUse rsq() and rmse(), respectively\n\nrsq(df_aug, truth = price, estimate = .fitted)\nrmse(df_aug, truth = price, estimate = .fitted)\n\nFirst argument: data frame containing truth and estimate columns\nSecond argument: name of the column containing truth (observed outcome)\nThird argument: name of the column containing estimate (predicted outcome)"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#announcements",
    "href": "slides/05-slr-sim-testing.html#announcements",
    "title": "SLR: Randomization test for the slope",
    "section": "Announcements",
    "text": "Announcements\n\nLab 02 due\n\nFriday, Sep 15 at 11:59pm (Tuesday labs)\nSunday, Sep 17 at 11:59pm (Thursday labs)\n\nHW 01\n\nReleased later today (will get email when HW is available)\ndue Wed, Sep 20 at 11:59pm\n\nStatistics experience - due Mon, Nov 20 at 11:59pm"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#topics",
    "href": "slides/05-slr-sim-testing.html#topics",
    "title": "SLR: Randomization test for the slope",
    "section": "Topics",
    "text": "Topics\n\nEvaluate a claim about the slope using hypothesis testing\nDefine mathematical models to conduct inference for slope"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#computational-setup",
    "href": "slides/05-slr-sim-testing.html#computational-setup",
    "title": "SLR: Randomization test for the slope",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#data-duke-forest-houses",
    "href": "slides/05-slr-sim-testing.html#data-duke-forest-houses",
    "title": "SLR: Randomization test for the slope",
    "section": "Data: Duke Forest houses",
    "text": "Data: Duke Forest houses"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#the-regression-model",
    "href": "slides/05-slr-sim-testing.html#the-regression-model",
    "title": "SLR: Randomization test for the slope",
    "section": "The regression model",
    "text": "The regression model\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#inference-for-simple-linear-regression",
    "href": "slides/05-slr-sim-testing.html#inference-for-simple-linear-regression",
    "title": "SLR: Randomization test for the slope",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope, \\(\\beta_1\\)"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#sampling-is-natural",
    "href": "slides/05-slr-sim-testing.html#sampling-is-natural",
    "title": "SLR: Randomization test for the slope",
    "section": "Sampling is natural",
    "text": "Sampling is natural\n\n\nWhen you taste a spoonful of soup and decide the spoonful you tasted isn’t salty enough, that’s exploratory analysis\nIf you generalize and conclude that your entire soup needs salt, that’s an inference\nFor your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#confidence-interval-via-bootstrapping",
    "href": "slides/05-slr-sim-testing.html#confidence-interval-via-bootstrapping",
    "title": "SLR: Randomization test for the slope",
    "section": "Confidence interval via bootstrapping",
    "text": "Confidence interval via bootstrapping\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-i",
    "href": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-i",
    "title": "SLR: Randomization test for the slope",
    "section": "Bootstrapping pipeline I",
    "text": "Bootstrapping pipeline I\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-ii",
    "href": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-ii",
    "title": "SLR: Randomization test for the slope",
    "section": "Bootstrapping pipeline II",
    "text": "Bootstrapping pipeline II\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n   replicate   price  area\n       &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1         1  290000  2414\n 2         1  285000  2108\n 3         1  265000  1300\n 4         1  416000  2949\n 5         1  541000  2740\n 6         1  525000  2256\n 7         1 1270000  3909\n 8         1  265000  1300\n 9         1  815000  3904\n10         1  535000  2937\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-iii",
    "href": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-iii",
    "title": "SLR: Randomization test for the slope",
    "section": "Bootstrapping pipeline III",
    "text": "Bootstrapping pipeline III\n\nset.seed(210)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   80699.\n 2         1 area          168.\n 3         2 intercept  -18821.\n 4         2 area          205.\n 5         3 intercept  234297.\n 6         3 area          117.\n 7         4 intercept  134481.\n 8         4 area          150.\n 9         5 intercept   23861.\n10         5 area          190.\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-iv",
    "href": "slides/05-slr-sim-testing.html#bootstrapping-pipeline-iv",
    "title": "SLR: Randomization test for the slope",
    "section": "Bootstrapping pipeline IV",
    "text": "Bootstrapping pipeline IV\n\nset.seed(210)\n\nboot_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#visualize-the-bootstrap-distribution",
    "href": "slides/05-slr-sim-testing.html#visualize-the-bootstrap-distribution",
    "title": "SLR: Randomization test for the slope",
    "section": "Visualize the bootstrap distribution",
    "text": "Visualize the bootstrap distribution\n\nboot_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10)"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#compute-the-ci",
    "href": "slides/05-slr-sim-testing.html#compute-the-ci",
    "title": "SLR: Randomization test for the slope",
    "section": "Compute the CI",
    "text": "Compute the CI"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#but-first",
    "href": "slides/05-slr-sim-testing.html#but-first",
    "title": "SLR: Randomization test for the slope",
    "section": "But first…",
    "text": "But first…\n\nobs_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobs_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#compute-95-confidence-interval",
    "href": "slides/05-slr-sim-testing.html#compute-95-confidence-interval",
    "title": "SLR: Randomization test for the slope",
    "section": "Compute 95% confidence interval",
    "text": "Compute 95% confidence interval\n\nboot_dist |&gt;\n  get_confidence_interval(\n    point_estimate = obs_fit,\n    level = 0.95,\n    type = \"percentile\"\n  )\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          91.7     211.\n2 intercept -18290.   287711."
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#research-question-and-hypotheses",
    "href": "slides/05-slr-sim-testing.html#research-question-and-hypotheses",
    "title": "SLR: Randomization test for the slope",
    "section": "Research question and hypotheses",
    "text": "Research question and hypotheses\n“Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”\n\nNull hypothesis: there is no linear relationship between area and price\n\\[\nH_0: \\beta_1 = 0\n\\]\n\n\nAlternative hypothesis: there is a linear relationship between area and price\n\\[\nH_A: \\beta_1 \\ne 0\n\\]"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#hypothesis-testing-as-a-court-trial",
    "href": "slides/05-slr-sim-testing.html#hypothesis-testing-as-a-court-trial",
    "title": "SLR: Randomization test for the slope",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#hypothesis-testing-framework",
    "href": "slides/05-slr-sim-testing.html#hypothesis-testing-framework",
    "title": "SLR: Randomization test for the slope",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\) that represents the status quo\nSet an alternative hypothesis, \\(H_A\\) that represents the research question, i.e. claim we’re testing\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of getting the observed or a more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#quantify-the-variability-of-the-slope",
    "href": "slides/05-slr-sim-testing.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Randomization test for the slope",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor testing\n\n\nTwo approaches:\n\nVia simulation\nVia mathematical models\n\nUse Randomization to quantify the variability of the slope for the purpose of testing, under the assumption that the null hypothesis is true:\n\nSimulate new samples from the original sample via permutation\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the permuted slopes to conduct a hypothesis test"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-described",
    "href": "slides/05-slr-sim-testing.html#permutation-described",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation, described",
    "text": "Permutation, described\n\n\n\nUse permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, not due to variables being correlated\n\nPermute one variable to eliminate any existing relationship between the variables\n\nEach price value is randomly assigned to the area of a given house, i.e. area and price are no longer matched for a given house\n\n\n\n\n# A tibble: 98 × 3\n   price_Observed price_Permuted  area\n            &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1        1520000         342500  6040\n 2        1030000         750000  4475\n 3         420000         645000  1745\n 4         680000         697500  2091\n 5         428500         428500  1772\n 6         456000         481000  1950\n 7        1270000         610000  3909\n 8         557450         680000  2841\n 9         697500         485000  3924\n10         650000         105000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-visualized",
    "href": "slides/05-slr-sim-testing.html#permutation-visualized",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation, visualized",
    "text": "Permutation, visualized\n\n\n\nEach of the observed values for area (and for price) exist in both the observed data plot as well as the permuted price plot\nThe permutation removes the relationship between area and price\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-repeated",
    "href": "slides/05-slr-sim-testing.html#permutation-repeated",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation, repeated",
    "text": "Permutation, repeated\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#concluding-the-hypothesis-test",
    "href": "slides/05-slr-sim-testing.html#concluding-the-hypothesis-test",
    "title": "SLR: Randomization test for the slope",
    "section": "Concluding the hypothesis test",
    "text": "Concluding the hypothesis test\n\nIs the observed slope of \\(\\hat{\\beta_1} = 159\\) (or an even more extreme slope) a likely outcome under the null hypothesis that \\(\\beta = 0\\)? What does this mean for our original question: “Do the data provide sufficient evidence that \\(\\beta_1\\) (the true slope for the population) is different from 0?”\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values (`geom_bar()`)."
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-pipeline-i",
    "href": "slides/05-slr-sim-testing.html#permutation-pipeline-i",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation pipeline I",
    "text": "Permutation pipeline I\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area)\n\nResponse: price (numeric)\nExplanatory: area (numeric)\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-pipeline-ii",
    "href": "slides/05-slr-sim-testing.html#permutation-pipeline-ii",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation pipeline II",
    "text": "Permutation pipeline II\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98 × 2\n     price  area\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 1520000  6040\n 2 1030000  4475\n 3  420000  1745\n 4  680000  2091\n 5  428500  1772\n 6  456000  1950\n 7 1270000  3909\n 8  557450  2841\n 9  697500  3924\n10  650000  2173\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-pipeline-iii",
    "href": "slides/05-slr-sim-testing.html#permutation-pipeline-iii",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation pipeline III",
    "text": "Permutation pipeline III\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\")\n\nResponse: price (numeric)\nExplanatory: area (numeric)\nNull Hypothesis: independence\n# A tibble: 98,000 × 3\n# Groups:   replicate [1,000]\n     price  area replicate\n     &lt;dbl&gt; &lt;dbl&gt;     &lt;int&gt;\n 1  465000  6040         1\n 2  481000  4475         1\n 3 1020000  1745         1\n 4  520000  2091         1\n 5  592000  1772         1\n 6  650000  1950         1\n 7  473000  3909         1\n 8  705000  2841         1\n 9  785000  3924         1\n10  671500  2173         1\n# ℹ 97,990 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-pipeline-iv",
    "href": "slides/05-slr-sim-testing.html#permutation-pipeline-iv",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation pipeline IV",
    "text": "Permutation pipeline IV\n\nset.seed(1125)\n\nduke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()\n\n# A tibble: 2,000 × 3\n# Groups:   replicate [1,000]\n   replicate term       estimate\n       &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1         1 intercept 553355.  \n 2         1 area           2.35\n 3         2 intercept 635824.  \n 4         2 area         -27.3 \n 5         3 intercept 536072.  \n 6         3 area           8.57\n 7         4 intercept 598649.  \n 8         4 area         -13.9 \n 9         5 intercept 556202.  \n10         5 area           1.33\n# ℹ 1,990 more rows"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#permutation-pipeline-v",
    "href": "slides/05-slr-sim-testing.html#permutation-pipeline-v",
    "title": "SLR: Randomization test for the slope",
    "section": "Permutation pipeline V",
    "text": "Permutation pipeline V\n\nset.seed(1125)\n\nnull_dist &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  fit()"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#visualize-the-null-distribution",
    "href": "slides/05-slr-sim-testing.html#visualize-the-null-distribution",
    "title": "SLR: Randomization test for the slope",
    "section": "Visualize the null distribution",
    "text": "Visualize the null distribution\n\nnull_dist |&gt;\n  filter(term == \"area\") |&gt;\n  ggplot(aes(x = estimate)) +\n  geom_histogram(binwidth = 10, color = \"white\")"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#reason-around-the-p-value",
    "href": "slides/05-slr-sim-testing.html#reason-around-the-p-value",
    "title": "SLR: Randomization test for the slope",
    "section": "Reason around the p-value",
    "text": "Reason around the p-value\n\nIn a world where the there is no relationship between the area of a Duke Forest house and in its price (\\(\\beta_1 = 0\\)), what is the probability that we observe a sample of 98 houses where the slope fo the model predicting price from area is 159 or even more extreme?\n\n\n\nWarning: Removed 2 rows containing missing values (`geom_bar()`)."
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#compute-the-p-value",
    "href": "slides/05-slr-sim-testing.html#compute-the-p-value",
    "title": "SLR: Randomization test for the slope",
    "section": "Compute the p-value",
    "text": "Compute the p-value\n\nWhat does this warning mean?\n\n\nget_p_value(\n  null_dist,\n  obs_stat = obs_fit,\n  direction = \"two-sided\"\n)\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step.\nSee `?get_p_value()` for more information.\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the `generate()` step.\nSee `?get_p_value()` for more information.\n\n\n# A tibble: 2 × 2\n  term      p_value\n  &lt;chr&gt;       &lt;dbl&gt;\n1 area            0\n2 intercept       0"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#the-regression-model-revisited",
    "href": "slides/05-slr-sim-testing.html#the-regression-model-revisited",
    "title": "SLR: Randomization test for the slope",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#inference-revisited",
    "href": "slides/05-slr-sim-testing.html#inference-revisited",
    "title": "SLR: Randomization test for the slope",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#mathematical-representation-of-the-model",
    "href": "slides/05-slr-sim-testing.html#mathematical-representation-of-the-model",
    "title": "SLR: Randomization test for the slope",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= Model + Error \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#mathematical-representation-visualized",
    "href": "slides/05-slr-sim-testing.html#mathematical-representation-visualized",
    "title": "SLR: Randomization test for the slope",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nGraph reproduced from Beyond Multiple Linear Regression.\n\n\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#regression-standard-error",
    "href": "slides/05-slr-sim-testing.html#regression-standard-error",
    "title": "SLR: Randomization test for the slope",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error (the spread of the distribution of the response, for a given value of the predictor variable):\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/05-slr-sim-testing.html#standard-error-of-hatbeta_1",
    "href": "slides/05-slr-sim-testing.html#standard-error-of-hatbeta_1",
    "title": "SLR: Randomization test for the slope",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\nor…\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/02-big-picture.html#announcements",
    "href": "slides/02-big-picture.html#announcements",
    "title": "The big picture",
    "section": "Announcements",
    "text": "Announcements\n\nResources for extra R review\n\nLearn R: An interactive introduction to data analysis R (focus on Chapters 4 - 6)\nDuke Library Center for Data and Visualization Sciences workshops\n\nR for Lunch: data wrangling with dplyr (Fri, Sep 1, 12:30 - 1:30)\nR for Lunch: visualization with ggplot2 (Fri, Sep 8, 12:30 - 1:30)\nSee the CDVS website for more information and to register.\n\n\nLast day of in-person work for this class is Dec 7\nLecture recordings request policy\nReadings for next week will be posted later this week"
  },
  {
    "objectID": "slides/02-big-picture.html#topics",
    "href": "slides/02-big-picture.html#topics",
    "title": "The big picture",
    "section": "Topics",
    "text": "Topics\n\nData analysis life cycle\nReproducible data analysis\nAnalyzing multivariable relationships"
  },
  {
    "objectID": "slides/02-big-picture.html#reproducibility-checklist",
    "href": "slides/02-big-picture.html#reproducibility-checklist",
    "title": "The big picture",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Can the tables and figures be exactly reproduced from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/02-big-picture.html#why-is-reproducibility-important",
    "href": "slides/02-big-picture.html#why-is-reproducibility-important",
    "title": "The big picture",
    "section": "Why is reproducibility important?",
    "text": "Why is reproducibility important?\n\nResults produced are more reliable and trustworthy (Ostblom and Timbers 2022)\nFacilitates more effective collaboration (Ostblom and Timbers 2022)\nContributing to science, which builds and organizes knowledge in terms of testable hypotheses (Alexander 2023)\nPossible to identify and correct errors or biases in the analysis process (Alexander 2023)"
  },
  {
    "objectID": "slides/02-big-picture.html#when-things-go-wrong",
    "href": "slides/02-big-picture.html#when-things-go-wrong",
    "title": "The big picture",
    "section": "When things go wrong",
    "text": "When things go wrong\n\n\n\nReproducibility error\nConsequence\nSource(s)\n\n\n\n\nLimitations in Excel data formats\nLoss of 16,000 COVID case records in the UK\n(Kelion 2020)\n\n\nAutomatic formatting in Excel\nImportant genes disregarded in scientific studies\n(Ziemann, Eren, and El-Osta 2016)\n\n\nDeletion of a cell caused rows to shift\nMix-up of which patient group received the treatment\n(Wallensteen et al. 2018)\n\n\nUsing binary instead of explanatory labels\nMix-up of the intervention with the control group\n(Aboumatar and Wise 2019)\n\n\nUsing the same notation for missing data and zero values\nPaper retraction\n(Whitehouse et al. 2021)\n\n\nIncorrectly copying data in a spreadsheet\nDelay in the opening of a hospital\n(Picken 2020)\n\n\n\nSource: Ostblom and Timbers (2022)"
  },
  {
    "objectID": "slides/02-big-picture.html#toolkit",
    "href": "slides/02-big-picture.html#toolkit",
    "title": "The big picture",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub\n\n\n\n\n\n\n\nNote\n\n\nYou will start using these computing tools in Lab 01."
  },
  {
    "objectID": "slides/02-big-picture.html#r-and-rstudio",
    "href": "slides/02-big-picture.html#r-and-rstudio",
    "title": "The big picture",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\nSource: Statistical Inference via Data Science"
  },
  {
    "objectID": "slides/02-big-picture.html#rstudio-ide",
    "href": "slides/02-big-picture.html#rstudio-ide",
    "title": "The big picture",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto",
    "href": "slides/02-big-picture.html#quarto",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/02-big-picture.html#quarto-1",
    "href": "slides/02-big-picture.html#quarto-1",
    "title": "The big picture",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/02-big-picture.html#how-will-we-use-quarto",
    "href": "slides/02-big-picture.html#how-will-we-use-quarto",
    "title": "The big picture",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning",
    "href": "slides/02-big-picture.html#what-is-versioning",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?"
  },
  {
    "objectID": "slides/02-big-picture.html#what-is-versioning-1",
    "href": "slides/02-big-picture.html#what-is-versioning-1",
    "title": "The big picture",
    "section": "What is versioning?",
    "text": "What is versioning?\nwith human readable messages"
  },
  {
    "objectID": "slides/02-big-picture.html#why-do-we-need-version-control",
    "href": "slides/02-big-picture.html#why-do-we-need-version-control",
    "title": "The big picture",
    "section": "Why do we need version control?",
    "text": "Why do we need version control?\n\n\n\n\n\n\n\n\nProvides a clear record of how the analysis methods evolved. This makes analysis auditable and thus more trustworthy and reliable. (Ostblom and Timbers 2022)"
  },
  {
    "objectID": "slides/02-big-picture.html#git-and-github",
    "href": "slides/02-big-picture.html#git-and-github",
    "title": "The big picture",
    "section": "git and GitHub",
    "text": "git and GitHub\n\n\ngit is a version control system – like “Track Changes” features from Microsoft Word.\nGitHub is the home for your git-based projects on the internet (like DropBox but much better).\nThere are a lot of git commands and very few people know them all. 99% of the time you will use git to add, commit, push, and pull."
  },
  {
    "objectID": "slides/02-big-picture.html#carbohydrates-in-starbucks-food",
    "href": "slides/02-big-picture.html#carbohydrates-in-starbucks-food",
    "title": "The big picture",
    "section": "Carbohydrates in Starbucks food",
    "text": "Carbohydrates in Starbucks food\n\nStarbucks often displays the total calories in their food items but not the other nutritional information.\nCarbohydrates are a body’s main fuel source. The Dietary Guidelines for America recommend that carbohydrates make up 45% to 65% of total daily calories.1\nOur goal is to understand the relationship between the amount of carbohydrates and calories in Starbucks food items. We’d also like to assess if the relationship differs based on the type of food item (bakery, salad, sandwich, etc.)\n\nSource: Mayo Clinic"
  },
  {
    "objectID": "slides/02-big-picture.html#starbucks-data",
    "href": "slides/02-big-picture.html#starbucks-data",
    "title": "The big picture",
    "section": "Starbucks data",
    "text": "Starbucks data\n\n\nObservations: 77 Starbucks food items\nVariables:\n\ncarb: Total carbohydrates (in grams)\ncalories: Total calories\nbakery: 1: bakery food item, 0: other food type"
  },
  {
    "objectID": "slides/02-big-picture.html#terminology",
    "href": "slides/02-big-picture.html#terminology",
    "title": "The big picture",
    "section": "Terminology",
    "text": "Terminology\n\ncarb is the response variable\n\nvariable whose variation we want to understand / variable we wish to predict\nalso known as outcome or dependent variable\n\n\n\n\ncalories, bakery are the predictor variables\n\nvariables used to account for variation in the response\nalso known as explanatory, independent, or input variables"
  },
  {
    "objectID": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#univariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Univariate exploratory data analysis",
    "text": "Univariate exploratory data analysis\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "href": "slides/02-big-picture.html#bivariate-exploratory-data-analysis",
    "title": "The big picture",
    "section": "Bivariate exploratory data analysis",
    "text": "Bivariate exploratory data analysis\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/02-big-picture.html#function-between-response-and-predictors",
    "href": "slides/02-big-picture.html#function-between-response-and-predictors",
    "title": "The big picture",
    "section": "Function between response and predictors",
    "text": "Function between response and predictors\n\n\\[\\text{carb} = f(\\text{calories}, \\text{bakery}) + \\epsilon\\]\n\n\nGoal: Determine \\(f\\)\nHow do we determine \\(f\\)?\n\nMake an assumption about the functional form \\(f\\) (parametric model)\nUse the data to fit a model based on that form"
  },
  {
    "objectID": "slides/02-big-picture.html#determine-f",
    "href": "slides/02-big-picture.html#determine-f",
    "title": "The big picture",
    "section": "Determine \\(f\\)",
    "text": "Determine \\(f\\)\n\nChoose the functional form of \\(f\\), i.e., choose the appropriate model given the response variable\n\n\nSuppose \\(f\\) takes the form of a linear model\n\\[y = f(\\mathbf{X}) = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_p x_p + \\epsilon\\]\n\n\n\nUse the data to fit (or train) the model, i.e, estimate the model parameters, \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\)"
  },
  {
    "objectID": "slides/02-big-picture.html#carb-vs.-calories",
    "href": "slides/02-big-picture.html#carb-vs.-calories",
    "title": "The big picture",
    "section": "Carb vs. Calories",
    "text": "Carb vs. Calories\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\\[\\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\epsilon\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#carb-vs.-calories-bakery",
    "href": "slides/02-big-picture.html#carb-vs.-calories-bakery",
    "title": "The big picture",
    "section": "Carb vs. Calories + Bakery",
    "text": "Carb vs. Calories + Bakery\n\n\\[\\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\beta_2 ~\\text{bakery} + \\epsilon\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#carb-vs.-calories-bakery-with-interaction",
    "href": "slides/02-big-picture.html#carb-vs.-calories-bakery-with-interaction",
    "title": "The big picture",
    "section": "Carb vs. Calories + Bakery (with interaction)",
    "text": "Carb vs. Calories + Bakery (with interaction)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\\[{\\small \\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\beta_2 ~\\text{bakery} + \\beta_3 ~ \\text{calories} \\times \\text{bakery}  + \\epsilon}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "href": "slides/02-big-picture.html#statistical-model-vs.-regression-equation",
    "title": "The big picture",
    "section": "Statistical model vs. regression equation",
    "text": "Statistical model vs. regression equation\nStatistical model (also known as data-generating model)\n\\[{\\small \\text{carb} = \\beta_0 + \\beta_1 ~\\text{calories} + \\beta_2 ~\\text{bakery} + \\beta_3 ~ \\text{calories} \\times \\text{bakery}  + \\epsilon}\\]\nModels the process for generating values of the response in the population (function + error)\n\n\nRegression equation\nEstimate of the function using the sample data\n\\[{\\small \\hat{\\text{carb}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~\\text{calories} + \\hat{\\beta}_2 ~\\text{bakery} + \\hat{\\beta}_3 ~ \\text{calories} \\times \\text{bakery}}\\]"
  },
  {
    "objectID": "slides/02-big-picture.html#why-fit-a-model",
    "href": "slides/02-big-picture.html#why-fit-a-model",
    "title": "The big picture",
    "section": "Why fit a model?",
    "text": "Why fit a model?\n\nPrediction: Expected value of the response variable for given values of the predictor variables\nInference: Conclusion about the relationship between the response and predictor variables\n\n\n\nWhat is an example of a prediction question that can be answered using the model of carb vs. calories and bakery?\nWhat is an example of an inference question that can be answered using the model of carb vs. calories and bakery?"
  },
  {
    "objectID": "slides/02-big-picture.html#recap",
    "href": "slides/02-big-picture.html#recap",
    "title": "The big picture",
    "section": "Recap",
    "text": "Recap\n\nReproducibility\n\nIt is best practice conduct all data analysis in a reproducible way\nWe will implement a reproducible workflow using R, Quarto, and git/GitHub\n\n\n\n\nMultivariable relationships\n\nWe can use exploratory data analysis to describe the relationship between two variables\nWe make an assumption about the relationship between variables when doing linear regression\nThe two main objectives for fitting a linear regression model are (1) prediction and (2) inference"
  },
  {
    "objectID": "slides/02-big-picture.html#references",
    "href": "slides/02-big-picture.html#references",
    "title": "The big picture",
    "section": "References",
    "text": "References\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule\n\n\n\nAlexander, Rohan. 2023. “Telling Stories with Data,” June. https://doi.org/10.1201/9781003229407.\n\n\nOstblom, Joel, and Tiffany Timbers. 2022. “Opinionated Practices for Teaching Reproducibility: Motivation, Guided Instruction and Practice.” Journal of Statistics and Data Science Education 30 (3): 241–50. https://doi.org/10.1080/26939169.2022.2074922."
  },
  {
    "objectID": "slides/09-mlr.html#announcements",
    "href": "slides/09-mlr.html#announcements",
    "title": "Multiple linear regression (MLR)",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due Mon, Oct 2 at 11:59pm.\nAll lecture recordings available until Wed, Oct 4 at 9am.\n\nClick here for link to videos. You can also find the link in the navigation bar of the course website.\n\nLab groups start this week. You will get your assigned group when you go to lab.\nSubmit questions about SLR by Thu, Sep 28. These questions will be used to make the Exam Review. Click here for more info.\nExam 01: Wed, Oct 4 (in-class + take-home)\nExam 01 review: Mon, Oct 2"
  },
  {
    "objectID": "slides/09-mlr.html#computational-setup",
    "href": "slides/09-mlr.html#computational-setup",
    "title": "Multiple linear regression (MLR)",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(colorblindr)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))"
  },
  {
    "objectID": "slides/09-mlr.html#data-peer-to-peer-lender",
    "href": "slides/09-mlr.html#data-peer-to-peer-lender",
    "title": "Multiple linear regression (MLR)",
    "section": "Data: Peer-to-peer lender",
    "text": "Data: Peer-to-peer lender\nToday’s data is a sample of 50 loans made through a peer-to-peer lending club. The data is in the loan50 data frame in the openintro R package.\n\n\n# A tibble: 50 × 4\n   annual_income debt_to_income verified_income interest_rate\n           &lt;dbl&gt;          &lt;dbl&gt; &lt;fct&gt;                   &lt;dbl&gt;\n 1         59000         0.558  Not Verified            10.9 \n 2         60000         1.31   Not Verified             9.92\n 3         75000         1.06   Verified                26.3 \n 4         75000         0.574  Not Verified             9.92\n 5        254000         0.238  Not Verified             9.43\n 6         67000         1.08   Source Verified          9.92\n 7         28800         0.0997 Source Verified         17.1 \n 8         80000         0.351  Not Verified             6.08\n 9         34000         0.698  Not Verified             7.97\n10         80000         0.167  Source Verified         12.6 \n# ℹ 40 more rows"
  },
  {
    "objectID": "slides/09-mlr.html#variables",
    "href": "slides/09-mlr.html#variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Variables",
    "text": "Variables\nPredictors:\n\n\nannual_income: Annual income\ndebt_to_income: Debt-to-income ratio, i.e. the percentage of a borrower’s total debt divided by their total income\nverified_income: Whether borrower’s income source and amount have been verified (Not Verified, Source Verified, Verified)\n\n\nOutcome: interest_rate: Interest rate for the loan"
  },
  {
    "objectID": "slides/09-mlr.html#outcome-interest_rate",
    "href": "slides/09-mlr.html#outcome-interest_rate",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome: interest_rate",
    "text": "Outcome: interest_rate\n\n\n\n\n\n\nmin\nmedian\nmax\niqr\n\n\n\n\n5.31\n9.93\n26.3\n5.755"
  },
  {
    "objectID": "slides/09-mlr.html#predictors",
    "href": "slides/09-mlr.html#predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Predictors",
    "text": "Predictors"
  },
  {
    "objectID": "slides/09-mlr.html#data-manipulation-1-rescale-income",
    "href": "slides/09-mlr.html#data-manipulation-1-rescale-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 1: Rescale income",
    "text": "Data manipulation 1: Rescale income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(annual_income_th = annual_income / 1000)\n\nggplot(loan50, aes(x = annual_income_th)) +\n  geom_histogram(binwidth = 20) +\n  labs(title = \"Annual income (in $1000s)\", \n       x = \"\")"
  },
  {
    "objectID": "slides/09-mlr.html#outcome-vs.-predictors",
    "href": "slides/09-mlr.html#outcome-vs.-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Outcome vs. predictors",
    "text": "Outcome vs. predictors"
  },
  {
    "objectID": "slides/09-mlr.html#single-vs.-multiple-predictors",
    "href": "slides/09-mlr.html#single-vs.-multiple-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Single vs. multiple predictors",
    "text": "Single vs. multiple predictors\nSo far we’ve used a single predictor variable to understand variation in a quantitative response variable\n\nNow we want to use multiple predictor variables to understand variation in a quantitative response variable"
  },
  {
    "objectID": "slides/09-mlr.html#multiple-linear-regression-mlr",
    "href": "slides/09-mlr.html#multiple-linear-regression-mlr",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression (MLR)",
    "text": "Multiple linear regression (MLR)\nBased on the analysis goals, we will use a multiple linear regression model of the following form\n\\[\n\\begin{aligned}\\hat{\\text{interest_rate}} ~ =\n\\hat{\\beta}_0 & + \\hat{\\beta}_1 \\text{debt_to_income} \\\\ & + \\hat{\\beta}_2 \\text{verified_income} \\\\ &+ \\hat{\\beta}_3 \\text{annual_income_th}\n\\end{aligned}\n\\]\nSimilar to simple linear regression, this model assumes that at each combination of the predictor variables, the values interest_rate follow a Normal distribution."
  },
  {
    "objectID": "slides/09-mlr.html#multiple-linear-regression-1",
    "href": "slides/09-mlr.html#multiple-linear-regression-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nRecall: The simple linear regression model assumes\n\\[\nY|X\\sim N(\\beta_0 + \\beta_1 X, \\sigma_{\\epsilon}^2)\n\\]\n\nSimilarly: The multiple linear regression model assumes\n\\[\nY|X_1, X_2, \\ldots, X_p \\sim N(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p, \\sigma_{\\epsilon}^2)\n\\]"
  },
  {
    "objectID": "slides/09-mlr.html#multiple-linear-regression-2",
    "href": "slides/09-mlr.html#multiple-linear-regression-2",
    "title": "Multiple linear regression (MLR)",
    "section": "Multiple linear regression",
    "text": "Multiple linear regression\nAt any combination of the predictors, the mean value of the response \\(Y\\), is\n\\[\n\\mu_{Y|X_1, \\ldots, X_p} = \\beta_0 + \\beta_1 X_{1} + \\beta_2 X_2 + \\dots + \\beta_p X_p\n\\]\n\nUsing multiple linear regression, we can estimate the mean response for any combination of predictors\n\\[\n\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{1} + \\hat{\\beta}_2 X_2 + \\dots + \\hat{\\beta}_p X_{p}\n\\]"
  },
  {
    "objectID": "slides/09-mlr.html#model-fit",
    "href": "slides/09-mlr.html#model-fit",
    "title": "Multiple linear regression (MLR)",
    "section": "Model fit",
    "text": "Model fit\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078"
  },
  {
    "objectID": "slides/09-mlr.html#model-equation",
    "href": "slides/09-mlr.html#model-equation",
    "title": "Multiple linear regression (MLR)",
    "section": "Model equation",
    "text": "Model equation\n\\[\n\\begin{align}\\hat{\\text{interest_rate}} =  10.726 &+0.671 \\times \\text{debt_to_income}\\\\\n&+ 2.211 \\times \\text{source_verified}\\\\  \n&+ 6.880 \\times \\text{verified}\\\\\n& -0.021 \\times \\text{annual_income_th}\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\nWe will talk about why there are two terms in the model for verified_income shortly!"
  },
  {
    "objectID": "slides/09-mlr.html#interpreting-hatbeta_j",
    "href": "slides/09-mlr.html#interpreting-hatbeta_j",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting \\(\\hat{\\beta}_j\\)",
    "text": "Interpreting \\(\\hat{\\beta}_j\\)\n\nThe estimated coefficient \\(\\hat{\\beta}_j\\) is the expected change in the mean of \\(y\\) when \\(x_j\\) increases by one unit, holding the values of all other predictor variables constant.\n\n\n\nExample: The estimated coefficient for debt_to_income is 0.671. This means for each point in an borrower’s debt to income ratio, the interest rate on the loan is expected to be greater by 0.671%, holding annual income and income verification constant."
  },
  {
    "objectID": "slides/09-mlr.html#prediction",
    "href": "slides/09-mlr.html#prediction",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction",
    "text": "Prediction\n\nWhat is the predicted interest rate for an borrower with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000?\n\n\n\n10.726 + 0.671 * 0.558 + 2.211 * 0 + 6.880 * 0 - 0.021 * 59\n\n[1] 9.861418\n\n\n\nThe predicted interest rate for an borrower with with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000 is 9.86%."
  },
  {
    "objectID": "slides/09-mlr.html#prediction-revisited",
    "href": "slides/09-mlr.html#prediction-revisited",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction, revisited",
    "text": "Prediction, revisited\nJust like with simple linear regression, we can use the predict() function in R to calculate the appropriate intervals for our predicted values:\n\nnew_borrower &lt;- tibble(\n  debt_to_income  = 0.558, \n  verified_income = \"Not Verified\", \n  annual_income_th = 59\n)\n\npredict(int_fit, new_borrower)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  9.89\n\n\n\n\n\n\n\n\nNote\n\n\nDifference in predicted value due to rounding the coefficients on the previous slide."
  },
  {
    "objectID": "slides/09-mlr.html#confidence-interval-for-hatmu_y",
    "href": "slides/09-mlr.html#confidence-interval-for-hatmu_y",
    "title": "Multiple linear regression (MLR)",
    "section": "Confidence interval for \\(\\hat{\\mu}_y\\)",
    "text": "Confidence interval for \\(\\hat{\\mu}_y\\)\n\nCalculate a 90% confidence interval for the estimated mean interest rate for borrowers with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000.\n\n\n\npredict(int_fit, new_borrower, type = \"conf_int\", level = 0.90)\n\n# A tibble: 1 × 2\n  .pred_lower .pred_upper\n        &lt;dbl&gt;       &lt;dbl&gt;\n1        8.16        11.6"
  },
  {
    "objectID": "slides/09-mlr.html#prediction-interval-for-haty",
    "href": "slides/09-mlr.html#prediction-interval-for-haty",
    "title": "Multiple linear regression (MLR)",
    "section": "Prediction interval for \\(\\hat{y}\\)",
    "text": "Prediction interval for \\(\\hat{y}\\)\n\nCalculate a 90% confidence interval for the predicted interest rate for an individual appllicant with an debt-to-income ratio of 0.558, whose income is not verified, and who has an annual income of $59,000.\n\n\n\npredict(int_fit, new_borrower, type = \"pred_int\", level = 0.90)\n\n# A tibble: 1 × 2\n  .pred_lower .pred_upper\n        &lt;dbl&gt;       &lt;dbl&gt;\n1        2.18        17.6"
  },
  {
    "objectID": "slides/09-mlr.html#cautions",
    "href": "slides/09-mlr.html#cautions",
    "title": "Multiple linear regression (MLR)",
    "section": "Cautions",
    "text": "Cautions\n\nDo not extrapolate! Because there are multiple predictor variables, there is the potential to extrapolate in many directions\nThe multiple regression model only shows association, not causality\n\nTo show causality, you must have a carefully designed experiment or carefully account for confounding variables in an observational study"
  },
  {
    "objectID": "slides/09-mlr.html#interpreting-results",
    "href": "slides/09-mlr.html#interpreting-results",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting results",
    "text": "Interpreting results\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n10.726\n1.507\n7.116\n0.000\n7.690\n13.762\n\n\ndebt_to_income\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\n\nDescribe the subset of borrowers who are expected to get an interest rate of 10.726% based on our model. Is this interpretation meaningful? Why or why not?"
  },
  {
    "objectID": "slides/09-mlr.html#mean-centering",
    "href": "slides/09-mlr.html#mean-centering",
    "title": "Multiple linear regression (MLR)",
    "section": "Mean-centering",
    "text": "Mean-centering\nIf we are interested in interpreting the intercept, we can mean-center the quantitative predictors in the model.\nWe can mean-center a quantitative predictor \\(X_j\\) using the following:\n\\[X_{j_{Cent}} = X_{j}- \\bar{X}_{j}\\]\n\nIf we mean-center all quantitative variables, then the intercept is interpreted as the expected value of the response variable when all quantitative variables are at their mean value."
  },
  {
    "objectID": "slides/09-mlr.html#data-manipulation-2-mean-center-numeric-predictors",
    "href": "slides/09-mlr.html#data-manipulation-2-mean-center-numeric-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 2: Mean-center numeric predictors",
    "text": "Data manipulation 2: Mean-center numeric predictors\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    debt_inc_cent = debt_to_income - mean(debt_to_income), \n    annual_income_th_cent = annual_income_th - mean(annual_income_th)\n    )"
  },
  {
    "objectID": "slides/09-mlr.html#visualize-mean-centered-predictors",
    "href": "slides/09-mlr.html#visualize-mean-centered-predictors",
    "title": "Multiple linear regression (MLR)",
    "section": "Visualize mean-centered predictors",
    "text": "Visualize mean-centered predictors"
  },
  {
    "objectID": "slides/09-mlr.html#using-mean-centered-variables-in-the-model",
    "href": "slides/09-mlr.html#using-mean-centered-variables-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Using mean-centered variables in the model",
    "text": "Using mean-centered variables in the model\n\nHow do you expect the model to change if we use the debt_inc_cent and annual_income_cent in the model?\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n7.476\n11.413\n\n\ndebt_inc_cent\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th_cent\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002"
  },
  {
    "objectID": "slides/09-mlr.html#original-vs.-mean-centered-model",
    "href": "slides/09-mlr.html#original-vs.-mean-centered-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Original vs. mean-centered model",
    "text": "Original vs. mean-centered model\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n10.726\n\n\ndebt_to_income\n0.671\n\n\nverified_incomeSource Verified\n2.211\n\n\nverified_incomeVerified\n6.880\n\n\nannual_income_th\n-0.021\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\n\n\n\n\n(Intercept)\n9.444\n\n\ndebt_inc_cent\n0.671\n\n\nverified_incomeSource Verified\n2.211\n\n\nverified_incomeVerified\n6.880\n\n\nannual_income_th_cent\n-0.021"
  },
  {
    "objectID": "slides/09-mlr.html#indicator-variables-1",
    "href": "slides/09-mlr.html#indicator-variables-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicator variables",
    "text": "Indicator variables\n\nSuppose there is a categorical variable with \\(K\\) categories (levels)\nWe can make \\(K\\) indicator variables - one indicator for each category\nAn indicator variable takes values 1 or 0\n\n1 if the observation belongs to that category\n0 if the observation does not belong to that category"
  },
  {
    "objectID": "slides/09-mlr.html#data-manipulation-3-create-indicator-variables-for-verified_income",
    "href": "slides/09-mlr.html#data-manipulation-3-create-indicator-variables-for-verified_income",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 3: Create indicator variables for verified_income",
    "text": "Data manipulation 3: Create indicator variables for verified_income\n\nloan50 &lt;- loan50 |&gt;\n  mutate(\n    not_verified = if_else(verified_income == \"Not Verified\", 1, 0),\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0)\n  )\n\n\n\n\n# A tibble: 3 × 4\n  verified_income not_verified source_verified verified\n  &lt;fct&gt;                  &lt;dbl&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n1 Not Verified               1               0        0\n2 Verified                   0               0        1\n3 Source Verified            0               1        0"
  },
  {
    "objectID": "slides/09-mlr.html#indicators-in-the-model",
    "href": "slides/09-mlr.html#indicators-in-the-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Indicators in the model",
    "text": "Indicators in the model\n\nWe will use \\(K-1\\) of the indicator variables in the model.\nThe baseline is the category that doesn’t have a term in the model.\nThe coefficients of the indicator variables in the model are interpreted as the expected change in the response compared to the baseline, holding all other variables constant.\nThis approach is also called dummy coding.\n\n\n\nloan50 |&gt;\n  select(verified_income, source_verified, verified) |&gt;\n  slice(1, 3, 6)\n\n# A tibble: 3 × 3\n  verified_income source_verified verified\n  &lt;fct&gt;                     &lt;dbl&gt;    &lt;dbl&gt;\n1 Not Verified                  0        0\n2 Verified                      0        1\n3 Source Verified               1        0"
  },
  {
    "objectID": "slides/09-mlr.html#interpreting-verified_income",
    "href": "slides/09-mlr.html#interpreting-verified_income",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting verified_income",
    "text": "Interpreting verified_income\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n9.444\n0.977\n9.663\n0.000\n7.476\n11.413\n\n\ndebt_inc_cent\n0.671\n0.676\n0.993\n0.326\n-0.690\n2.033\n\n\nverified_incomeSource Verified\n2.211\n1.399\n1.581\n0.121\n-0.606\n5.028\n\n\nverified_incomeVerified\n6.880\n1.801\n3.820\n0.000\n3.253\n10.508\n\n\nannual_income_th_cent\n-0.021\n0.011\n-1.804\n0.078\n-0.043\n0.002\n\n\n\n\n\n\n\n\n\n\nThe baseline category is Not verified.\nPeople with source verified income are expected to take a loan with an interest rate that is 2.211% higher, on average, than the rate on loans to those whose income is not verified, holding all else constant.\n\n\n\n\n\nInterpret the coefficient of Verified in the context of the data."
  },
  {
    "objectID": "slides/09-mlr.html#interaction-terms-1",
    "href": "slides/09-mlr.html#interaction-terms-1",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction terms",
    "text": "Interaction terms\n\nSometimes the relationship between a predictor variable and the response depends on the value of another predictor variable.\nThis is an interaction effect.\nTo account for this, we can include interaction terms in the model."
  },
  {
    "objectID": "slides/09-mlr.html#interest-rate-vs.-annual-income",
    "href": "slides/09-mlr.html#interest-rate-vs.-annual-income",
    "title": "Multiple linear regression (MLR)",
    "section": "Interest rate vs. annual income",
    "text": "Interest rate vs. annual income\nThe lines are not parallel indicating there is an interaction effect. The slope of annual income differs based on the income verification."
  },
  {
    "objectID": "slides/09-mlr.html#interaction-term-in-model",
    "href": "slides/09-mlr.html#interaction-term-in-model",
    "title": "Multiple linear regression (MLR)",
    "section": "Interaction term in model",
    "text": "Interaction term in model\n\nint_cent_int_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(interest_rate ~ debt_inc_cent + verified_income + annual_income_th_cent + verified_income * annual_income_th_cent,\n      data = loan50)\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n9.484\n0.989\n9.586\n0.000\n\n\ndebt_inc_cent\n0.691\n0.685\n1.009\n0.319\n\n\nverified_incomeSource Verified\n2.157\n1.418\n1.522\n0.135\n\n\nverified_incomeVerified\n7.181\n1.870\n3.840\n0.000\n\n\nannual_income_th_cent\n-0.007\n0.020\n-0.341\n0.735\n\n\nverified_incomeSource Verified:annual_income_th_cent\n-0.016\n0.026\n-0.643\n0.523\n\n\nverified_incomeVerified:annual_income_th_cent\n-0.032\n0.033\n-0.979\n0.333"
  },
  {
    "objectID": "slides/09-mlr.html#interpreting-interaction-terms",
    "href": "slides/09-mlr.html#interpreting-interaction-terms",
    "title": "Multiple linear regression (MLR)",
    "section": "Interpreting interaction terms",
    "text": "Interpreting interaction terms\n\nWhat the interaction means: The effect of annual income on the interest rate differs by -0.016 when the income is source verified compared to when it is not verified, holding all else constant.\nInterpreting annual_income for source verified: If the income is source verified, we expect the interest rate to decrease by 0.023% (-0.007 + -0.016) for each additional thousand dollars in annual income, holding all else constant."
  },
  {
    "objectID": "slides/09-mlr.html#data-manipulation-4-create-interaction-variables",
    "href": "slides/09-mlr.html#data-manipulation-4-create-interaction-variables",
    "title": "Multiple linear regression (MLR)",
    "section": "Data manipulation 4: Create interaction variables",
    "text": "Data manipulation 4: Create interaction variables\nDefining the interaction variable in the model formula as verified_income * annual_income_th_cent is an implicit data manipulation step as well\n\n\nRows: 50\nColumns: 9\n$ `(Intercept)`                                          &lt;dbl&gt; 1, 1, 1, 1, 1, …\n$ debt_inc_cent                                          &lt;dbl&gt; -0.16511719, 0.…\n$ annual_income_th_cent                                  &lt;dbl&gt; -27.17, -26.17,…\n$ `verified_incomeNot Verified`                          &lt;dbl&gt; 1, 1, 0, 1, 1, …\n$ `verified_incomeSource Verified`                       &lt;dbl&gt; 0, 0, 0, 0, 0, …\n$ verified_incomeVerified                                &lt;dbl&gt; 0, 0, 1, 0, 0, …\n$ `annual_income_th_cent:verified_incomeNot Verified`    &lt;dbl&gt; -27.17, -26.17,…\n$ `annual_income_th_cent:verified_incomeSource Verified` &lt;dbl&gt; 0.00, 0.00, 0.0…\n$ `annual_income_th_cent:verified_incomeVerified`        &lt;dbl&gt; 0.00, 0.00, -11…"
  },
  {
    "objectID": "slides/09-mlr.html#recap",
    "href": "slides/09-mlr.html#recap",
    "title": "Multiple linear regression (MLR)",
    "section": "Recap",
    "text": "Recap\n\nIntroduced multiple linear regression\nInterpreted coefficients in the multiple linear regression model\nCalculated predictions and associated intervals for multiple linear regression models\nMean-centered quantitative predictors\nUsed indicator variables for categorical predictors\nUsed interaction terms"
  },
  {
    "objectID": "slides/09-mlr.html#looking-backward",
    "href": "slides/09-mlr.html#looking-backward",
    "title": "Multiple linear regression (MLR)",
    "section": "Looking backward",
    "text": "Looking backward\nData manipulation, with dplyr (from tidyverse):\n\nloan50 |&gt;\n  select(interest_rate, annual_income, debt_to_income, verified_income) |&gt;\n  mutate(\n    # 1. rescale income\n    annual_income_th = annual_income / 1000,\n    # 2. mean-center quantitative predictors\n    debt_inc_cent = debt_to_income - mean(debt_to_income),\n    annual_income_th_cent = annual_income_th - mean(annual_income_th),\n    # 3. create dummy variables for verified_income\n    source_verified = if_else(verified_income == \"Source Verified\", 1, 0),\n    verified = if_else(verified_income == \"Verified\", 1, 0),\n    # 4. create interaction variables\n    `annual_income_th_cent:verified_incomeSource Verified` = annual_income_th_cent * source_verified,\n    `annual_income_th_cent:verified_incomeVerified` = annual_income_th_cent * verified\n  )"
  },
  {
    "objectID": "slides/09-mlr.html#looking-forward-after-exam-01",
    "href": "slides/09-mlr.html#looking-forward-after-exam-01",
    "title": "Multiple linear regression (MLR)",
    "section": "Looking forward (after Exam 01)",
    "text": "Looking forward (after Exam 01)\nFeature engineering, with recipes (from tidymodels):\n\nloan_rec &lt;- recipe( ~ ., data = loan50) |&gt;\n  # 1. rescale income\n  step_mutate(annual_income_th = annual_income / 1000) |&gt;\n  # 2. mean-center quantitative predictors\n  step_center(all_numeric_predictors()) |&gt;\n  # 3. create dummy variables for verified_income\n  step_dummy(verified_income) |&gt;\n  # 4. create interaction variables\n  step_interact(terms = ~ annual_income_th:verified_income)"
  },
  {
    "objectID": "slides/09-mlr.html#recipe",
    "href": "slides/09-mlr.html#recipe",
    "title": "Multiple linear regression (MLR)",
    "section": "Recipe",
    "text": "Recipe\n\nloan_rec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\npredictor: 24\n\n\n\n\n\n── Operations \n\n\n• Variable mutation for: annual_income / 1000\n\n\n• Centering for: all_numeric_predictors()\n\n\n• Dummy variables from: verified_income\n\n\n• Interactions with: annual_income_th:verified_income\n\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/06-slr-math-models.html#announcements",
    "href": "slides/06-slr-math-models.html#announcements",
    "title": "SLR: Mathematical models for inference",
    "section": "Announcements",
    "text": "Announcements\n\nHW 01: due Wed, Sep 20 at 11:59pm\n\nQuestions?\n\nStatistics experience - due Mon, Nov 20 at 11:59pm"
  },
  {
    "objectID": "slides/06-slr-math-models.html#course-policy-reminders",
    "href": "slides/06-slr-math-models.html#course-policy-reminders",
    "title": "SLR: Mathematical models for inference",
    "section": "Course policy reminders",
    "text": "Course policy reminders\n\nLate work\n\nHW and labs accepted up to 2 days late.\n5% deduction for each 24-hour period the assignment is late.\n\nOne time late waiver\n\nCan use on HW and individual labs\n\nLowest HW and lowest lab grade dropped at the end of the semester."
  },
  {
    "objectID": "slides/06-slr-math-models.html#course-policy-reminders-1",
    "href": "slides/06-slr-math-models.html#course-policy-reminders-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Course policy reminders",
    "text": "Course policy reminders\n\nRegrade requests\n\nOpened 1 day after assignment is returned and due within 1 week\nOnly submit regrade if there is an error in the grading not to dispute points\nProf. Tackett or Sam the Head TA will regrade the entire exercise being disputed, which could result in a lower grade\n\n\n\n\n\n\n\nTip\n\n\nSee the posted solutions and ask during office hours before submitting a regrade request"
  },
  {
    "objectID": "slides/06-slr-math-models.html#statistician-of-the-day-regina-nuzzo",
    "href": "slides/06-slr-math-models.html#statistician-of-the-day-regina-nuzzo",
    "title": "SLR: Mathematical models for inference",
    "section": "Statistician of the day: Regina Nuzzo",
    "text": "Statistician of the day: Regina Nuzzo\n\n\n\n\n\n\n\n\nDr. Nuzzo received her PhD in Statistics from Stanford University and is now Professor of Science, Technology, & Mathematics at Gallaudet University. Dr. Nuzzo teaches statistics using American Sign Language.\nHer work has appeared in Nature, Los Angeles Times, New York Times, Reader’s Digest, New Scientist, and Scientific American. Primarily, she works to help lay-audiences understand science and statistics in particular. She earned the American Statistical Association’s 2014 Excellence in Statistical Reporting Award for her article on p-values in Nature. Her work led to the ASA’s statement on p-values.\nSource: hardin47.github.io/CURV/scholars/nuzzo"
  },
  {
    "objectID": "slides/06-slr-math-models.html#regina-nuzzo",
    "href": "slides/06-slr-math-models.html#regina-nuzzo",
    "title": "SLR: Mathematical models for inference",
    "section": "Regina Nuzzo",
    "text": "Regina Nuzzo\nFrom “Tips for Communicating Statistical Significance.”\n“That we use p-values to alert us to surprising data results, not to give a final answer on anything. (Or at least that’s what we should be doing). And that results can get flagged as”statistically surprising” with a small p-value for a number of reasons”\n\nThere was a fluke.\nSomething was violated.\nThere was a real but tiny relationship.\nThere was a relationship that is worth more study.\n\nOr any combination of the above."
  },
  {
    "objectID": "slides/06-slr-math-models.html#topics",
    "href": "slides/06-slr-math-models.html#topics",
    "title": "SLR: Mathematical models for inference",
    "section": "Topics",
    "text": "Topics\n\nDefine mathematical models to conduct inference for the slope\nUse mathematical models to\n\ncalculate confidence interval for the slope\nconduct a hypothesis test for the slope"
  },
  {
    "objectID": "slides/06-slr-math-models.html#computational-setup",
    "href": "slides/06-slr-math-models.html#computational-setup",
    "title": "SLR: Mathematical models for inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/06-slr-math-models.html#the-regression-model-revisited",
    "href": "slides/06-slr-math-models.html#the-regression-model-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "The regression model, revisited",
    "text": "The regression model, revisited\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.325\n53302.463\n2.188\n0.031\n\n\narea\n159.483\n18.171\n8.777\n0.000"
  },
  {
    "objectID": "slides/06-slr-math-models.html#inference-revisited",
    "href": "slides/06-slr-math-models.html#inference-revisited",
    "title": "SLR: Mathematical models for inference",
    "section": "Inference, revisited",
    "text": "Inference, revisited\n\n\nEarlier we computed a confidence interval and conducted a hypothesis test via simulation:\n\nCI: Bootstrap the observed sample to simulate the distribution of the slope\nHT: Permute the observed sample to simulate the distribution of the slope under the assumption that the null hypothesis is true\n\nNow we’ll do these based on theoretical results, i.e., by using the Central Limit Theorem to define the distribution of the slope and use features (shape, center, spread) of this distribution to compute bounds of the confidence interval and the p-value for the hypothesis test"
  },
  {
    "objectID": "slides/06-slr-math-models.html#mathematical-representation-of-the-model",
    "href": "slides/06-slr-math-models.html#mathematical-representation-of-the-model",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation of the model",
    "text": "Mathematical representation of the model\n\\[\n\\begin{aligned}\nY &= Model + Error \\\\\n&= f(X) + \\epsilon \\\\\n&= \\mu_{Y|X} + \\epsilon \\\\\n&= \\beta_0 + \\beta_1 X + \\epsilon\n\\end{aligned}\n\\]\nwhere the errors are independent and normally distributed:\n\n\nindependent: Knowing the error term for one observation doesn’t tell you anything about the error term for another observation\nnormally distributed: \\(\\epsilon \\sim N(0, \\sigma_\\epsilon^2)\\)"
  },
  {
    "objectID": "slides/06-slr-math-models.html#mathematical-representation-visualized",
    "href": "slides/06-slr-math-models.html#mathematical-representation-visualized",
    "title": "SLR: Mathematical models for inference",
    "section": "Mathematical representation, visualized",
    "text": "Mathematical representation, visualized\n\\[\nY|X \\sim N(\\beta_0 + \\beta_1 X, \\sigma_\\epsilon^2)\n\\]\n\n\n\n\n\nImage source: Introduction to the Practice of Statistics (5th ed)\n\n\n\n\nMean: \\(\\beta_0 + \\beta_1 X\\), the predicted value based on the regression model\nVariance: \\(\\sigma_\\epsilon^2\\), constant across the range of \\(X\\)\n\nHow do we estimate \\(\\sigma_\\epsilon^2\\)?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#regression-standard-error",
    "href": "slides/06-slr-math-models.html#regression-standard-error",
    "title": "SLR: Mathematical models for inference",
    "section": "Regression standard error",
    "text": "Regression standard error\nOnce we fit the model, we can use the residuals to estimate the regression standard error, the average distance between the observed values and the regression line\n\\[\n\\hat{\\sigma}_\\epsilon = \\sqrt{\\frac{\\sum_\\limits{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}} = \\sqrt{\\frac{\\sum_\\limits{i=1}^ne_i^2}{n-2}}\n\\]\n\n\n\nWhy divide by \\(n - 2\\)?\nWhy do we care about the value of the regression standard error?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-error-of-hatbeta_1",
    "href": "slides/06-slr-math-models.html#standard-error-of-hatbeta_1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard error of \\(\\hat{\\beta}_1\\)",
    "text": "Standard error of \\(\\hat{\\beta}_1\\)\nThe standard error of \\(\\hat{\\beta}_1\\) quantifies the sampling variability in the estimated slopes\n\\[\nSE_{\\hat{\\beta}_1} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{(n-1)s_X^2}}\n\\]\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-for-the-slope",
    "href": "slides/06-slr-math-models.html#hypothesis-test-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test for the slope",
    "text": "Hypothesis test for the slope\nHypotheses: \\(H_0: \\beta_1 = 0\\) vs. \\(H_A: \\beta_1 \\ne 0\\)\n\nTest statistic: Number of standard errors the estimate is away from the null\n\\[\nT = \\frac{\\text{Estimate - Null}}{\\text{Standard error}} \\\\\n\\]\n\n\np-value: Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\\[\np-value = P(|t| &gt; |\\text{test statistic}|),\n\\]\ncalculated from a \\(t\\) distribution with \\(n - 2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-test-statistic",
    "href": "slides/06-slr-math-models.html#hypothesis-test-test-statistic",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Test statistic",
    "text": "Hypothesis test: Test statistic\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\nT = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}} = \\frac{159.48 - 0}{18.17} = 8.78\n\\]\n\nSelect the best interpretation of the test statistic on Ed Discussion.\n[10:05am lecture] [1:25pm lecture]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-p-value",
    "href": "slides/06-slr-math-models.html#hypothesis-test-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-p-value-1",
    "href": "slides/06-slr-math-models.html#hypothesis-test-p-value-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: p-value",
    "text": "Hypothesis test: p-value\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\nA more exact p-value\n\n2 * pt(q = 8.78, df = 96, lower.tail = FALSE)\n\n[1] 6.19602e-14\n\n\n\nSelect the meaning of the p-value on Ed Discussion.\n[10:05am lecture][1:25pm lecture]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#understanding-the-p-value",
    "href": "slides/06-slr-math-models.html#understanding-the-p-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Understanding the p-value",
    "text": "Understanding the p-value\n\n\n\nMagnitude of p-value\nInterpretation\n\n\n\n\np-value &lt; 0.01\nstrong evidence against \\(H_0\\)\n\n\n0.01 &lt; p-value &lt; 0.05\nmoderate evidence against \\(H_0\\)\n\n\n0.05 &lt; p-value &lt; 0.1\nweak evidence against \\(H_0\\)\n\n\np-value &gt; 0.1\neffectively no evidence against \\(H_0\\)\n\n\n\n\n\n\n\n\n\nImportant\n\n\nThese are general guidelines. The strength of evidence depends on the context of the problem."
  },
  {
    "objectID": "slides/06-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "href": "slides/06-slr-math-models.html#hypothesis-test-conclusion-in-context",
    "title": "SLR: Mathematical models for inference",
    "section": "Hypothesis test: Conclusion, in context",
    "text": "Hypothesis test: Conclusion, in context\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\nThe data provide convincing evidence that the population slope \\(\\beta_1\\) is different from 0.\nThe data provide convincing evidence of a linear relationship between area and price of houses in Duke Forest."
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval-for-the-slope",
    "href": "slides/06-slr-math-models.html#confidence-interval-for-the-slope",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\n\\[\n\\text{Estimate} \\pm \\text{ (critical value) } \\times \\text{SE}\n\\]\n\n\\[\n\\hat{\\beta}_1 \\pm t^* \\times SE_{\\hat{\\beta}_1}\n\\]\nwhere \\(t^*\\) is calculated from a \\(t\\) distribution with \\(n-2\\) degrees of freedom"
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval-critical-value",
    "href": "slides/06-slr-math-models.html#confidence-interval-critical-value",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval: Critical value",
    "text": "Confidence interval: Critical value\n\n\n\n\n# confidence level: 95%\nqt(0.975, df = nrow(duke_forest) - 2)\n\n[1] 1.984984\n\n\n\n\n\n# confidence level: 90%\nqt(0.95, df = nrow(duke_forest) - 2)\n\n[1] 1.660881\n\n\n\n\n\n# confidence level: 99%\nqt(0.995, df = nrow(duke_forest) - 2)\n\n[1] 2.628016"
  },
  {
    "objectID": "slides/06-slr-math-models.html#ci-for-the-slope-calculation",
    "href": "slides/06-slr-math-models.html#ci-for-the-slope-calculation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Calculation",
    "text": "95% CI for the slope: Calculation\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\\[\\hat{\\beta}_1 = 159.48 \\hspace{15mm} t^* = 1.98 \\hspace{15mm} SE_{\\hat{\\beta}_1} = 18.17\\]\n\n\\[\n159.48 \\pm 1.98 \\times 18.17 = (123.50, 195.46)\n\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#ci-for-the-slope-computation",
    "href": "slides/06-slr-math-models.html#ci-for-the-slope-computation",
    "title": "SLR: Mathematical models for inference",
    "section": "95% CI for the slope: Computation",
    "text": "95% CI for the slope: Computation\n\ntidy(df_fit, conf.int = TRUE, conf.level = 0.95) |&gt; \n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n10847.77\n222456.88\n\n\narea\n159.48\n18.17\n8.78\n0.00\n123.41\n195.55"
  },
  {
    "objectID": "slides/06-slr-math-models.html#intervals-for-predictions-1",
    "href": "slides/06-slr-math-models.html#intervals-for-predictions-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Intervals for predictions",
    "text": "Intervals for predictions\n\nSuppose we want to answer the question “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\nWe said reporting a single estimate for the slope is not wise, and we should report a plausible range instead\nSimilarly, reporting a single prediction for a new value is not wise, and we should report a plausible range instead"
  },
  {
    "objectID": "slides/06-slr-math-models.html#two-types-of-predictions",
    "href": "slides/06-slr-math-models.html#two-types-of-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Two types of predictions",
    "text": "Two types of predictions\n\nPrediction for the mean: “What is the average predicted sale price of Duke Forest houses that are 2,800 square feet?”\nPrediction for an individual observation: “What is the predicted sale price of a Duke Forest house that is 2,800 square feet?”\n\n\n\nWhich would you expect to be more variable? The average prediction or the prediction for an individual observation? Based on your answer, how would you expect the widths of plausible ranges for these two predictions to compare?"
  },
  {
    "objectID": "slides/06-slr-math-models.html#uncertainty-in-predictions",
    "href": "slides/06-slr-math-models.html#uncertainty-in-predictions",
    "title": "SLR: Mathematical models for inference",
    "section": "Uncertainty in predictions",
    "text": "Uncertainty in predictions\nConfidence interval for the mean outcome: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE}_{\\hat{\\boldsymbol{\\mu}}}}}\\]\n\nPrediction interval for an individual observation: \\[\\large{\\hat{y} \\pm t_{n-2}^* \\times \\color{purple}{\\mathbf{SE_{\\hat{y}}}}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-errors",
    "href": "slides/06-slr-math-models.html#standard-errors",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\n\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{1 + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#standard-errors-1",
    "href": "slides/06-slr-math-models.html#standard-errors-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Standard errors",
    "text": "Standard errors\nStandard error of the mean outcome: \\[SE_{\\hat{\\mu}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]\nStandard error of an individual outcome: \\[SE_{\\hat{y}} = \\hat{\\sigma}_\\epsilon\\sqrt{\\mathbf{\\color{purple}{\\Large{1}}} + \\frac{1}{n} + \\frac{(x-\\bar{x})^2}{\\sum\\limits_{i=1}^n(x_i - \\bar{x})^2}}\\]"
  },
  {
    "objectID": "slides/06-slr-math-models.html#confidence-interval",
    "href": "slides/06-slr-math-models.html#confidence-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Confidence interval",
    "text": "Confidence interval\nThe 95% confidence interval for the mean outcome:\n\nnew_house &lt;- tibble(area = 2800)\n\npredict(df_fit, new_data = new_house, type = \"conf_int\", level = 0.95) |&gt;\n  kable()\n\n\n\n\n.pred_lower\n.pred_upper\n\n\n\n\n529351\n597060.1\n\n\n\n\n\n\n\n\nWe are 95% confident that mean sale price of Duke Forest houses that are 2,800 square feet is between $529,351 and $597,060."
  },
  {
    "objectID": "slides/06-slr-math-models.html#prediction-interval",
    "href": "slides/06-slr-math-models.html#prediction-interval",
    "title": "SLR: Mathematical models for inference",
    "section": "Prediction interval",
    "text": "Prediction interval\nThe 95% prediction interval for an individual outcome:\n\npredict(df_fit, new_data = new_house, type = \"pred_int\", level = 0.95) |&gt;\n  kable()\n\n\n\n\n.pred_lower\n.pred_upper\n\n\n\n\n226438.3\n899972.7\n\n\n\n\n\n\n\n\nWe are 95% confident that predicted sale price of a Duke Forest house that is 2,800 square feet is between $226,438 and $899,973."
  },
  {
    "objectID": "slides/06-slr-math-models.html#comparing-intervals",
    "href": "slides/06-slr-math-models.html#comparing-intervals",
    "title": "SLR: Mathematical models for inference",
    "section": "Comparing intervals",
    "text": "Comparing intervals"
  },
  {
    "objectID": "slides/06-slr-math-models.html#extrapolation",
    "href": "slides/06-slr-math-models.html#extrapolation",
    "title": "SLR: Mathematical models for inference",
    "section": "Extrapolation",
    "text": "Extrapolation\nUsing the model to predict for values outside the range of the original data is extrapolation.\n\n\n\n\nCalculate the prediction interval for the sale price of a “tiny house” in Duke Forest that is 225 square feet.\n\n\n\n\n\n\n\n\n\n\n\nNo, thanks!"
  },
  {
    "objectID": "slides/06-slr-math-models.html#extrapolation-1",
    "href": "slides/06-slr-math-models.html#extrapolation-1",
    "title": "SLR: Mathematical models for inference",
    "section": "Extrapolation",
    "text": "Extrapolation\n\nWhy do we want to avoid extrapolation?\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/lab-04.html#goals",
    "href": "slides/lab-04.html#goals",
    "title": "Lab 04",
    "section": "Goals",
    "text": "Goals\n\nMeet your team!\nTeam agreement\nLab 04: Alumni jobs"
  },
  {
    "objectID": "slides/lab-04.html#meet-your-team",
    "href": "slides/lab-04.html#meet-your-team",
    "title": "Lab 04",
    "section": "Meet your team!",
    "text": "Meet your team!\n\nClick here to find your team.\nSit with your team."
  },
  {
    "objectID": "slides/lab-04.html#team-name-agreement",
    "href": "slides/lab-04.html#team-name-agreement",
    "title": "Lab 04",
    "section": "Team name + agreement",
    "text": "Team name + agreement\n\nCome up with a team name. You can’t have the same name as another group in the class, so be creative!\n\nYour TA will get your team name by the end of lab.\n\nFill out the team agreement. The goals of the agreement are to…\n\nGain a common understanding of the team’s goals and expectations for collaboration\nMake a plan for team communication\nMake a plan for working outside of lab"
  },
  {
    "objectID": "slides/lab-04.html#team-workflow",
    "href": "slides/lab-04.html#team-workflow",
    "title": "Lab 04",
    "section": "Team workflow",
    "text": "Team workflow\n\nOnly one team member should type at a time. There are markers in today’s lab to help you determine whose turn it is to type.\n\nEvery team member should still be engaged in discussion for all questions, even if it’s not your turn type.\n\nDon’t forget to pull to get your teammates’ updates before making changes to the .qmd file.\n\n\n\n\n\n\nImportant\n\n\nOnly one submission per team on Gradescope. Read the submission instructions carefully!"
  },
  {
    "objectID": "slides/lab-04.html#team-workflow-in-action",
    "href": "slides/lab-04.html#team-workflow-in-action",
    "title": "Lab 04",
    "section": "Team workflow, in action",
    "text": "Team workflow, in action\n\nComplete the “Workflow: Using Git and GitHub as a team” section of the lab in your teams.\nRaise your hand if you have any questions about the workflow.\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "slides/lab-04.html#tips-for-working-on-a-team",
    "href": "slides/lab-04.html#tips-for-working-on-a-team",
    "title": "Lab 04",
    "section": "Tips for working on a team",
    "text": "Tips for working on a team\n\nDo not pressure each other to finish early; use the time wisely to really learn the material and produce a quality report.\nThe labs are structured to help you learn the steps of a data analysis. Do not split up the lab among the team members; work on it together in its entirety.\nEveryone has something to contribute! Use the lab groups as an opportunity to share ideas and learn from each other.\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/lab-01.html#do-you-have-the-lab-01-repo",
    "href": "slides/lab-01.html#do-you-have-the-lab-01-repo",
    "title": "Lab 01",
    "section": "Do you have the lab-01 repo?",
    "text": "Do you have the lab-01 repo?\n\nGo to the GitHub course organization: https://github.com/sta210-fa23\nYou should see a repo with the prefix lab-01- followed by your GitHub username\nIf you do not have this repo\n\nClickhere to create your lab-01 repo, AND\nGo to the course organization and accept the invite in the banner at the top of the page. If you do not see the invite, click here to (re)submit your GitHub username."
  },
  {
    "objectID": "slides/lab-01.html#demo",
    "href": "slides/lab-01.html#demo",
    "title": "Lab 01",
    "section": "Demo",
    "text": "Demo\nFollow along as your TA demonstrates the following:\n\nConfigure Git using SSH\nClone repo (using SSH) and start new project in RStudio\nRender document and produce PDF\nUpdate name in YAML in the Quarto doc\n\nRender, commit, push changes to GitHub\nSee updates in your GitHub repo\n\nAdd an R code chunk to the Quarto doc"
  },
  {
    "objectID": "slides/lab-01.html#tips-for-working-on-lab",
    "href": "slides/lab-01.html#tips-for-working-on-lab",
    "title": "Lab 01",
    "section": "Tips for working on lab",
    "text": "Tips for working on lab\n\nYou do not have to finish the lab in class, they will always be due Friday (Tuesday labs) or Sunday (Thursday labs). One work strategy is to get through portions that you think will be most challenging (which initially might be the coding component) during lab when a TA can help you on the spot and leave the narrative writing until later.\nDo not pressure each other to finish early (particularly once you start working on teams); use the time wisely to really learn the material and produce a quality report."
  },
  {
    "objectID": "slides/lab-01.html#when-youre-done-with-lab",
    "href": "slides/lab-01.html#when-youre-done-with-lab",
    "title": "Lab 01",
    "section": "When you’re done with lab",
    "text": "When you’re done with lab\n\nMake sure all your final changes have been pushed to your GitHub repo\n\nSubmit the PDF of your responses to Gradescope\n\nYou can access Gradescope through Sakai or the course website\nLogin using your Duke NetID credentials\nSee Lab 01 instructions for details on submitting an assignment on Gradescope"
  },
  {
    "objectID": "slides/lab-01.html#lab-01-park-access",
    "href": "slides/lab-01.html#lab-01-park-access",
    "title": "Lab 01",
    "section": "Lab 01: Park access",
    "text": "Lab 01: Park access\n\nToday’s lab focuses on exploratory data analysis and simple linear regression. Read the lab instructions carefully.\nThere are markers throughout suggesting when to render, commit, and push changes to GitHub. These are to help you start using version control in your workflow.\nThere are points for having a neatly formatted document and implementing a reproducible workflow. See the Workflow & Formatting section in the Lab 01 instructions.\n\n🔗 sta210-fa23.netlify.app/labs/lab-01.html\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/lab-03.html#reminders",
    "href": "slides/lab-03.html#reminders",
    "title": "Lab 03",
    "section": "Reminders",
    "text": "Reminders\nMake sure to do the following as you complete the assignment:\n\nWrite all narrative in complete sentences.\nUse informative axis titles and labels on all graphs.\nImplement version control in your reproducible workflow.\n\nThroughout the assignment periodically render your Quarto document to produce the updated PDF, commit the changes in the Git pane, and push the updated files to GitHub.\nBenchmark: Push changes to GitHub at least three times as you work on the assignment."
  },
  {
    "objectID": "slides/lab-03.html#todays-lab",
    "href": "slides/lab-03.html#todays-lab",
    "title": "Lab 03",
    "section": "Today’s lab",
    "text": "Today’s lab\n\nFocused on mathematical inference for simple linear regression and checking model conditions.\n\nWe will talk about model conditions in the September 20 lecture.\n\nRemember to mark all pages in your Gradescope submission. The first page should be marked for the “Workflow & formatting” section.\nUse lectures and application exercises as reference as you complete the lab.\n\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 210: Regression Analysis",
    "section": "",
    "text": "Learn approaches for analyzing multivariate data sets, emphasizing analysis of variance, linear regression, and logistic regression. Learn techniques for checking the appropriateness of proposed models, such as residual analyses and case influence diagnostics, and techniques for selecting models. Gain experience dealing with the challenges that arise in practice through assignments that utilize real-world data. This class emphasizes data analysis over mathematical theory."
  },
  {
    "objectID": "index.html#teaching-assistants",
    "href": "index.html#teaching-assistants",
    "title": "STA 210: Regression Analysis",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\n\n\nClick here for schedule of office hours.\n\n\n\n\n\n\nName\nRole\n\n\n\n\n\nSam Rosen\nHead TA\nLab 01: Tue 10:05 - 11:20am\n\n\nBethany Astor\nTA\nLab 02: Tue 11:45am - 1pm\n\n\nJon Campbell\nTA\n\n\n\nDonald Cayton\nTA\nLab 02: Tue 11:45am - 1pm\n\n\nAllison Li\nTA\n\n\n\nMitchelle Mojekwu\nTA\nLab 04: Thu 11:45am - 1pm\n\n\nBen Thorpe\nTA\n\n\n\nLinxuan Wang\nTA\nLab 03: Thu 10:05 - 11:20am\n\n\nXiaojun Zheng\nTA\nLab 04: Thu 11:45am - 1pm"
  },
  {
    "objectID": "computing-r-resources.html",
    "href": "computing-r-resources.html",
    "title": "Resources for learning R",
    "section": "",
    "text": "R for Data Science by Hadley Wickham & Garrett Grolemund\nTidy Modeling with R by Max Kuhn & Julia Silge"
  },
  {
    "objectID": "computing-r-resources.html#books-free-online",
    "href": "computing-r-resources.html#books-free-online",
    "title": "Resources for learning R",
    "section": "",
    "text": "R for Data Science by Hadley Wickham & Garrett Grolemund\nTidy Modeling with R by Max Kuhn & Julia Silge"
  },
  {
    "objectID": "computing-r-resources.html#rstudio-primers",
    "href": "computing-r-resources.html#rstudio-primers",
    "title": "Resources for learning R",
    "section": "RStudio Primers",
    "text": "RStudio Primers\nTutorials most relevant to this course:\n\nThe Basics\nWork with Data\nVisualize Data\nTidy your Data\n\nClick here for full list of tutorials."
  },
  {
    "objectID": "computing-r-resources.html#additional-resources",
    "href": "computing-r-resources.html#additional-resources",
    "title": "Resources for learning R",
    "section": "Additional resources",
    "text": "Additional resources\n\nRStudio Cheatsheets\nR Fun workshops and videos by Duke Center for Data and Visualization Sciences."
  },
  {
    "objectID": "support.html",
    "href": "support.html",
    "title": "Course support",
    "section": "",
    "text": "We expect everyone will have questions at some point in the semester, so we want to make sure you can identify when that is and feel comfortable seeking help."
  },
  {
    "objectID": "support.html#lectures-and-labs",
    "href": "support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "support.html#office-hours",
    "href": "support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage you to take advantage of them!\nMake a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "support.html#ed-discussion",
    "href": "support.html#ed-discussion",
    "title": "Course support",
    "section": "Ed Discussion",
    "text": "Ed Discussion\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts on Ed Discussion before adding a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "support.html#email",
    "href": "support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nIf you have questions about personal matters that are not appropriate for the class discussion forum (e.g. illness, accommodations, etc.), you may email Professor Tackett at maria.tackett@duke.edu. If you email me, please include “STA 210” in the subject line. Barring extenuating circumstances, I will respond to STA 210 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\nIf you have questions about assignment extensions, please email sta210@duke.edu. This email is accessible to the Head TA Sam Rosen and Professor Tackett."
  },
  {
    "objectID": "support.html#academic-support",
    "href": "support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "support.html#mental-health-and-wellness",
    "href": "support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well being. If you have concerns about a student’s behavior or health visit the website for resources and assistance. Go to studentaffairs.duke.edu/dukereach\nCounseling and Psychological Services (CAPS): CAPS services include individual, group, and couples counseling services, health coaching, psychiatric services, and workshops and discussions. (919) 660-1000 or students.duke.edu/wellness/caps\nTimelyCare (formerly known as Blue Devils Care): An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling. bluedevilscare.duke.edu"
  },
  {
    "objectID": "support.html#technology-accommodations",
    "href": "support.html#technology-accommodations",
    "title": "Course support",
    "section": "Technology accommodations",
    "text": "Technology accommodations\nHighly aided students who have limited access to computers may request loaner laptops through the DukeLIFE Technology Assistance Program. Please note that supplies are limited.\nNote that we will be using Duke’s computational resources in this course. These resources are freely available to you. As long as your computer can connect to the internet and open a browser window, you can perform the necessary computing for this course. All software we use is open-source and/or freely available."
  },
  {
    "objectID": "support.html#course-materials-costs",
    "href": "support.html#course-materials-costs",
    "title": "Course support",
    "section": "Course materials costs",
    "text": "Course materials costs\nThere are no costs associated with this course. All readings will come from freely available, open resources (open-source textbooks, journal articles, etc.)."
  },
  {
    "objectID": "support.html#assistance-with-zoom-or-sakai",
    "href": "support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission and discussion will take place on GitHub instead.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "ae/ae-01-movies.html",
    "href": "ae/ae-01-movies.html",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups and submit answers on Ed Discussion. This AE does not count towards the Application Exercise grade.\nWe will look at the relationship between budget and revenue for movies made in the United States in 1986 to 2020. The dataset is created based on data from the Internet Movie Database (IMDB).\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(DT)"
  },
  {
    "objectID": "ae/ae-01-movies.html#data",
    "href": "ae/ae-01-movies.html#data",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Data",
    "text": "Data\nThe movies data set includes basic information about each movie including budget, genre, movie studio, director, etc. A full list of the variables may be found here.\n\nmovies &lt;- read_csv(\"https://raw.githubusercontent.com/danielgrijalva/movie-stats/master/movies.csv\")\n\nView the first 10 rows of data.\n\nmovies |&gt;\n  slice(1:10)\n\n# A tibble: 10 × 15\n   name   rating genre  year released score  votes director writer star  country\n   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;  \n 1 The S… R      Drama  1980 June 13…   8.4 9.27e5 Stanley… Steph… Jack… United…\n 2 The B… R      Adve…  1980 July 2,…   5.8 6.5 e4 Randal … Henry… Broo… United…\n 3 Star … PG     Acti…  1980 June 20…   8.7 1.20e6 Irvin K… Leigh… Mark… United…\n 4 Airpl… PG     Come…  1980 July 2,…   7.7 2.21e5 Jim Abr… Jim A… Robe… United…\n 5 Caddy… R      Come…  1980 July 25…   7.3 1.08e5 Harold … Brian… Chev… United…\n 6 Frida… R      Horr…  1980 May 9, …   6.4 1.23e5 Sean S.… Victo… Bets… United…\n 7 The B… R      Acti…  1980 June 20…   7.9 1.88e5 John La… Dan A… John… United…\n 8 Ragin… R      Biog…  1980 Decembe…   8.2 3.30e5 Martin … Jake … Robe… United…\n 9 Super… PG     Acti…  1980 June 19…   6.8 1.01e5 Richard… Jerry… Gene… United…\n10 The L… R      Biog…  1980 May 16,…   7   1   e4 Walter … Bill … Davi… United…\n# ℹ 4 more variables: budget &lt;dbl&gt;, gross &lt;dbl&gt;, company &lt;chr&gt;, runtime &lt;dbl&gt;"
  },
  {
    "objectID": "ae/ae-01-movies.html#analysis",
    "href": "ae/ae-01-movies.html#analysis",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Analysis",
    "text": "Analysis\nWe begin by looking at how the average gross revenue (gross) has changed over time. Since we want to visualize the results, we will choose a few genres of interest for the analysis.\n\ngenre_list &lt;- c(\"Comedy\", \"Action\", \"Animation\", \"Horror\")\n\n\nmovies |&gt;\n  filter(genre %in% genre_list) |&gt; \n  group_by(genre,year) |&gt;\n  summarise(avg_gross = mean(gross)) |&gt;\n  ggplot(mapping = aes(x = year, y = avg_gross, color=genre)) +\n    geom_point() + \n    geom_line() +\n    ylab(\"Average Gross Revenue (in US Dollars)\") +\n    ggtitle(\"Gross Revenue Over Time\") +\n    scale_color_viridis_d()\n\n\n\n\n\n\n\n\n\n\nWhat do you observe from the plot?\n\n\n\nNext, let’s see the relationship between a movie’s budget and its gross revenue.\n\nmovies |&gt;\n  filter(genre %in% genre_list, budget &gt; 0) |&gt; \n  ggplot(mapping = aes(x=log(budget), y = log(gross), color=genre)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) + \n  xlab(\"Log-transformed Budget\")+\n  ylab(\"Log-transformed Gross Revenue\") +\n  facet_wrap(~ genre) + \n  scale_color_viridis_d()"
  },
  {
    "objectID": "ae/ae-01-movies.html#exercises",
    "href": "ae/ae-01-movies.html#exercises",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Exercises",
    "text": "Exercises\n\nSuppose we fit a regression model for each genre that uses budget to predict gross revenue. What are the signs of the correlation between budget and gross and the slope in each regression equation?\nSuppose we fit the regression model from the previous question. Which genre would you expect to have the smallest residuals, on average (residual = observed revenue - predicted revenue)?\nPost your response on ED Discussion.\n\nSection 001 (10:05am lecture)\nSection 002 (1:25pm lecture)\n\n[Time permitting] Discuss the following: Notice in the graph above that budget and gross are log-transformed. Why are the log-transformed values of the variables displayed rather than the original values (in U.S. dollars)? Post your group’s response in the AE 01 Movie Budgets comments on Ed Discussion."
  },
  {
    "objectID": "ae/ae-01-movies.html#references",
    "href": "ae/ae-01-movies.html#references",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "References",
    "text": "References\n\ngithub.com/danielgrijalva/movie-stats\nInternet Movie Database"
  },
  {
    "objectID": "ae/ae-01-movies.html#appendix",
    "href": "ae/ae-01-movies.html#appendix",
    "title": "AE 01: Movie Budgets and Revenues",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of genres in the data set:\n\nmovies |&gt; \n  arrange(genre) |&gt; \n  select(genre) |&gt;\n  distinct() |&gt;\n  datatable()"
  },
  {
    "objectID": "ae/ae-03-slr.html",
    "href": "ae/ae-03-slr.html",
    "title": "AE 03: Bike rentals in Washington, DC",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-03 repo to get started. If you do not see an ae-03 repo, click here to create one.\nRender, commit, and push your responses to GitHub by the end of class. The responses are due in your GitHub repo no later than Saturday, September 9 at 11:59pm.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-03-slr.html#data",
    "href": "ae/ae-03-slr.html#data",
    "title": "AE 03: Bike rentals in Washington, DC",
    "section": "Data",
    "text": "Data\nOur data set contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare &lt;- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-03-slr.html#exercises",
    "href": "ae/ae-03-slr.html#exercises",
    "title": "AE 03: Bike rentals in Washington, DC",
    "section": "Exercises",
    "text": "Exercises\n\nExercise 1\nBelow are visualizations of the distributions of daily bike rentals and temperature as well as the relationship between these two variables.\n\np1 &lt;- ggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250) + \n  labs(x = \"Daily bike rentals\")\n\np2 &lt;- ggplot(bikeshare, aes(x = temp_orig)) +\n  geom_histogram() + \n  labs(x = \"Temperature (Celsius)\")\n\np3 &lt;- ggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point() + \n  labs(x = \"Temperature (Celsius)\", \n       y = \"Daily bike rentals\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\n\n\n\n\nThere appears to be one day with a very small number of bike rentals. What was the day? Why were the number of bike rentals so low on that day? Hint: You can Google the date to figure out what was going on that day.\n\n\n\n[Add your answer here]\n\n\nExercise 2\n\n\n\n\n\n\nIn the raw data, seasons are coded as 1, 2, 3, 4 as numerical values, corresponding to winter, spring, summer, and fall respectively. Recode the season variable to make it a categorical variable (a factor) with levels corresponding to season names, making sure that the levels appear in a reasonable order in the variable (i.e., not alphabetical).\n\n\n\n\n# add code developed during livecoding here\n\n\n\nExercise 3\n\n\n\n\n\n\nWe want to evaluate whether the relationship between temperature and daily bike rentals is the same for each season. To answer this question, first create a scatter plot of daily bike rentals vs. temperature faceted by season.\n\n\n\n\n# add code developed during livecoding here\n\n\n\nExercise 4\n\n\n\n\n\n\n\nWhich season appears to have the strongest relationship between temperature and daily bike rentals? Why do you think the relationship is strongest in this season?\nWhich season appears to have the weakest relationship between temperature and daily bike rentals? Why do you think the relationship is weakest in this season?\n\n\n\n\n[Add your answer here]\n\n\nExercise 5\n\n\n\n\n\n\nFilter your data for the season with the strongest apparent relationship between temperature and daily bike rentals.\n\n\n\n\n# add code developed during livecoding here\n\n\n\nExercise 6\n\n\n\n\n\n\nUsing the subset of the data from Exercise 5, fit a linear model for predicting daily bike rentals from temperature for this season.\n\n\n\n\n# add code developed during livecoding here\n\n\n\nExercise 7\n\n\n\n\n\n\nUse the output to write out the estimated regression equation.\n\n\n\n[Add your answer here]\n\n\nExercise 8\n\n\n\n\n\n\nInterpret the slope in the context of the data.\n\n\n\n[Add your answer here]\n\n\nExercise 9\n\n\n\n\n\n\nInterpret the intercept in the context of the data.\n\n\n\n[Add your answer here]\n\n\nExercise 10\n\n\n\n\n\n\nSuppose you work for a bike share company in Durham, NC, and they want to predict daily bike rentals in 2024. What is one reason you might recommend they use your analysis for this task? What is one reason you would recommend they not use your analysis for this task?\n\n\n\n[Add your answer here]\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-03- repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-06-conditions.html",
    "href": "ae/ae-06-conditions.html",
    "title": "AE 06: Conditions and model evaluation",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-06 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class. The responses are due in your GitHub repo no later than Saturday, September 23 at 11:59pm.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork) #arrange plots in a grid"
  },
  {
    "objectID": "ae/ae-06-conditions.html#data",
    "href": "ae/ae-06-conditions.html#data",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Data",
    "text": "Data\nThe data set for this assignment is a subset from the Spotify Songs Tidy Tuesday data set. The data were originally obtained from Spotify using the spotifyr R package.\nIt contains numerous characteristics for each song. You can see the full list of variables and definitions here. This analysis will focus specifically on the following variables:\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\ntrack_id\ncharacter\nSong unique ID\n\n\ntrack_name\ncharacter\nSong Name\n\n\ntrack_artist\ncharacter\nSong Artist\n\n\ntrack_popularity\ndouble\nSong Popularity (0-100) where higher is better\n\n\nenergy\ndouble\nEnergy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n\n\nvalence\ndouble\nA measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n\n\n\nspotify &lt;- read_csv(\"data/spotify-popular.csv\")\n\nAre high energy songs more positive? To answer this question, we’ll analyze data on some of the most popular songs on Spotify, i.e. those with track_popularity &gt;= 80. We’ll use linear regression to fit a model to predict a song’s positiveness (valence) based on its energy level (energy).\nBelow are plots as part of the exploratory data analysis.\n\np1 &lt;- ggplot(data = spotify, aes(x = valence)) + \n  geom_histogram() + \n  labs(title = \"Distribution of Valence\", \n       subtitle = \" for Popular songs on Spotify\", \n       x = \"Valence\")\n\np2 &lt;- ggplot(data = spotify, aes(x = energy)) + \n  geom_histogram() + \n  labs(title = \"Distribution of Energy\", \n       subtitle = \"for Popular songs on Spotify\", \n       x = \"Energy\")\np1 + p2\n\n\n\n\n\nggplot(data = spotify, aes(x = energy, y = valence)) + \n  geom_point() + \n  labs(title = \"Valence vs. Energy\", \n       subtitle = \"Popular songs on Spotify\", \n       x = \"Energy\", \n       y = \"Valence\")"
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-1",
    "href": "ae/ae-06-conditions.html#exercise-1",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 1",
    "text": "Exercise 1\nFit a model using the energy of a song to predict its valence, i.e. positiveness. Include the 90% confidence interval for the coefficients, and display the output using 3 digits.\n\n## add code"
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-2",
    "href": "ae/ae-06-conditions.html#exercise-2",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 2",
    "text": "Exercise 2\nLet’s check the model conditions before doing any inference. Fill in the code below to use the augment() function to create a new data frame containing the residuals and fitted values (among other information)\n\n\n\n\n\n\nImportant\n\n\n\nNote: Remove #|eval: false from the code chunk after you have filled in the code.\n\n\n\nspotify_aug &lt;- augment(_____)"
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-3",
    "href": "ae/ae-06-conditions.html#exercise-3",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 3",
    "text": "Exercise 3\nMake a plot of the residual vs. fitted values.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-4",
    "href": "ae/ae-06-conditions.html#exercise-4",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 4",
    "text": "Exercise 4\nFill in the code to make a histogram of the residuals and a normal QQ-plot.\n\nresid_hist &lt;- ggplot(data = ____, aes(x = ____)) +\n  geom_histogram() +\n  labs(x = \"_____\", \n       y = \"_____\", \n       title = \"____\")\n\nresid_qq &lt;- ggplot(data = ____, aes(sample = ____)) + \n  stat_qq() + \n ____() + \n  labs(x = \"_____\", \n       y = \"_____\", \n       title = \"____\")\n\nresid_hist + resid_qq"
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-5",
    "href": "ae/ae-06-conditions.html#exercise-5",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 5",
    "text": "Exercise 5\nAssess the four model conditions. Use the plots from the previous exercises to help make the assessment.\n\nLinearity\nConstant variance\nNormality\nIndependence"
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-6",
    "href": "ae/ae-06-conditions.html#exercise-6",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 6",
    "text": "Exercise 6\nCalculate \\(R^2\\) and interpret this value in the context of the data."
  },
  {
    "objectID": "ae/ae-06-conditions.html#exercise-7",
    "href": "ae/ae-06-conditions.html#exercise-7",
    "title": "AE 06: Conditions and model evaluation",
    "section": "Exercise 7",
    "text": "Exercise 7\nCalculate RMSE and interpret this value in the context of the data.\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-06 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "prepare/week-14.html",
    "href": "prepare/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Important\n\n\n\n\nAE 15 due Sat, Dec 03, 11:59pm\nTeam Feedback #2 due Tue, Dec 06, 11:59pm\nLooking ahead\n\nExam 02: Dec 05 (evening) - Dec 08, 12pm (noon)\n\nClick here for all lecture recordings\n\n\n\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 Beyond Multiple Linear Regression, Chapter 7: Correlated Data (optional)\nNov 28\n\n\n📖 Beyond Multiple Linear Regression, Chapter 8:Introduction to Multilevel Models (optional)\nNov 28 & Nov 30\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Introduction to Multilevel Models\nNov 28\n\n\n💻 Fitting Multilevel Models\nNov 30\n\n\n💻 Lab: Written report\nDec 01 & 02\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 15: Introduction to Multilevel Models\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\n📝 Project written report\ndue Fri, Dec 09, 11:59pm (accepted until Sun, Dec 11, 11:59pm)\n\n\n📝 Statistics experience\ndue Fri, Dec 09, 11:59pm"
  },
  {
    "objectID": "prepare/week-01.html",
    "href": "prepare/week-01.html",
    "title": "Week 01",
    "section": "",
    "text": "Prepare\n\n\n\n\n\n\n📖 Syllabus\n\n\n📖 Course support\n\n\n📖 Introduction to Modern Statistics (IMS), Ch 7: Linear regression with a single predictor\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Welcome to STA 210!\nAug 29\n\n\n💻 Simple Linear Regression\nAug 31\n\n\n💻 Lab 00\nSep 01 & 02\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 01-Movie Budgets\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\n📝 Complete STA 210 Student Survey\ndue Fri, Sep 02 at 11:59pm\n\n\n📝 Reserve STA 210 RStudio Docker Container\nMon, Sep 05 at the beginning of class"
  },
  {
    "objectID": "prepare/week-16.html",
    "href": "prepare/week-16.html",
    "title": "Week 16",
    "section": "",
    "text": "Prepare\nNo reading assignments.\n\n\nParticipate\nNo lecture slides.\n\n\nPractice\nNo AEs.\n\n\nPerform\n\n\n\n\n\n\n\n📝 Project: Video presentation + slides\ndue Wed, Dec 14, 11:59pm\n\n\n📝 Project: Organized GitHub repo\ndue Wed, Dec 14, 11:59pm\n\n\n📝 Project: Presentation comments\ndue Fri, Dec 16, 11:59pm"
  },
  {
    "objectID": "prepare/week-06.html",
    "href": "prepare/week-06.html",
    "title": "Week 06",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 04:\n\ndue Thu, Oct 13, 11:59pm (Thu lab)\ndue Fri, Oct 14, 11:59pm (Fri lab)\n\nHW 02:\n\ndue Wed, Oct 19, 11:59pm\n\n\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 Tidy Modeling in R - Chapter 8: Feature engineering with recipes\nOct 05\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Feature engineering\nOct 03\n\n\n💻 Feature engineering: Model workflow\nOct 05\n\n\n💻 Lab 04\nOct 06 & 07\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 08: Feature engineering\n\n\n\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\n📝 Lab 04\nThu, Oct 13, 11:59pm (Thu lab)\nFri, Oct 14, 11:59pm (Fri lab)"
  },
  {
    "objectID": "prepare/week-13.html",
    "href": "prepare/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Important\n\n\n\n\nNo office hours Nov 21 - 25.\nNo class Nov 21 or Nov 23.\nNo labs Nov 24 - 25.\n\n🍁 Have a good Thanksgiving break! 🍁\n\n\n\nPrepare\nNo readings.\n\n\nParticipate\nNo lecture slides.\n\n\nPractice\nNo application exercises.\n\n\nPerform\n\n\n\n\n\n\n\n📝 Project written report\ndue Fri, Dec 09, 11:59pm (accepted until Sun, Dec 11, 11:59pm)\n\n\n📝 Statistics experience\ndue Fri, Dec 09, 11:59pm"
  },
  {
    "objectID": "prepare/sep-11.html",
    "href": "prepare/sep-11.html",
    "title": "September 11 lecture",
    "section": "",
    "text": "📖 IMS, Sec 24.2: Randomization test for the slope\n📖 IMS, Sec 24.3: Bootstrap confidence interval for the slope"
  },
  {
    "objectID": "prepare/sep-11.html#assigned-reading",
    "href": "prepare/sep-11.html#assigned-reading",
    "title": "September 11 lecture",
    "section": "",
    "text": "📖 IMS, Sec 24.2: Randomization test for the slope\n📖 IMS, Sec 24.3: Bootstrap confidence interval for the slope"
  },
  {
    "objectID": "prepare/week-11.html",
    "href": "prepare/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Important\n\n\n\n\nLab 07\n\ndue Mon, Nov 14, 11:59pm (Thu labs)\ndue Tue, Nov 15, 11:59pm (Fri labs)\n\n\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 IMS, Chap 9: Logistic Regression\nNov 07 & Nov 09\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Logistic regression: Odds ratios\nNov 07\n\n\n💻 Logistic regression: Prediction + classification\nNov 09\n\n\n\n\n\nPractice\nNo AEs this week.\n\n\nPerform\n\n\n\n\n\n\n\n📝 Lab 07\n\ndue Mon, Nov 14, 11:59pm (Thu labs)\ndue Tue, Nov 15, 11:59pm (Fri labs)\n\n\n\n📝 Statistics Experience\ndue Fri, Dec 09, 11:59pm"
  },
  {
    "objectID": "prepare/week-04.html",
    "href": "prepare/week-04.html",
    "title": "Week 04",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nAE 05: due Sat, Sep 24, 11:59pm\nHW 01: due Wed, Sep 21, 11:59pm\nLab 03:\n\ndue Mon, Sep 26, 11:59pm (Thu labs)\ndue Tue, Sep 27, 11:59pm (Fri labs)\n\n\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 IMS, Sec 24.4: Mathematical model for testing the slope\n📖 IMS, Sec 24.5: Mathematical model, interval for the slope\n📖 IMS, Sec 24.6: Checking model conditions\n📖 IMS, Sec 24.7: Chapter review\nSep 19\n\n\n📖 IMS, Sec 8.2: Many predictors in a model\nSep 21\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 SLR: Mathematical models for inference\nSep 19\n\n\n💻 SLR: Model conditions\nSep 21\n\n\n💻 Multiple linear regression\nSep 21\n\n\n💻 Lab 03\nSep 22 & 23\n\n\n\n\n\nPractice\n\n\n\n\n\n\nAE 05: Multiple linear regression\n\n\n\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\n📝 HW 01\nWed, Sep 21, 11:59pm\n\n\n📝 Lab 03\nMon, Sep 26, 11:59pm (Thu labs)\nTue, Sep 27, 11:59pm (Fri labs)\n\n\n📝 Statistics experience\nFri, Dec 09, 11:59pm"
  },
  {
    "objectID": "prepare/week-08.html",
    "href": "prepare/week-08.html",
    "title": "Week 08",
    "section": "",
    "text": "Important\n\n\n\n\nAE 09 due Sat, Oct 22, 11:59pm\nLab 05:\n\ndue Mon, Oct 24, 11:59pm (Thu lab)\ndue Tue, Oct 25 11:59pm (Fri lab)\n\n\n\n\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 Tidy Modeling in R - Chapter 8: Feature engineering with recipes\nOct 19\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Variable transformations: Log-transformed predictor\nOct 17\n\n\n💻 Model comparison\nOct 19\n\n\n💻 Lab 05\nOct 20 - 21\n\n\n\n\n\nPractice\n📋 AE 09: Model comparison\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nLab 05\n\ndue Mon, Oct 24, 11:59pm (Thu lab)\ndue Tue, Oct 25, 11:59pm (Fri lab)"
  },
  {
    "objectID": "hw/hw-01.html",
    "href": "hw/hw-01.html",
    "title": "HW 01: Education & median income in US Counties",
    "section": "",
    "text": "In this assignment, you will use simple linear regression to examine the association between between the percent of adults with a bachelor’s degree and the median household income for counties in the United States."
  },
  {
    "objectID": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "href": "hw/hw-01.html#part-1-exploratory-data-analysis",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 1: Exploratory data analysis",
    "text": "Part 1: Exploratory data analysis\n\nExercise 1\nCreate a histogram of the distribution of the predictor variable bachelorsand calculate appropriate summary statistics. Use the visualization and summary statistics to describe the distribution. Include an informative title and axis labels on the plot.\n\n\nExercise 2\nLet’s view the data in another way. Use the code below to make a map of the United States with the color of the counties filled in based on the percent of residents 25 years old and older who have a Bachelor’s degree. Fill in title and axis labels.\nThen use the plot answer the following:\n\nWhat are 2 observations you have from the map?\nWhat is a feature that is apparent in the map that wasn’t as easily apparent from the histogram in the previous exercise? What is a feature that is apparent in the histogram that is not as easily apparent from the map?\n\n\ncounty_map_data &lt;- left_join(county_data_sample, map_data_sample)\n\nggplot(data = map_data_all) +\n  geom_polygon(aes(x = long, y = lat, group = group),\n    fill = \"lightgray\", color = \"white\"\n    ) +\n  geom_polygon(data = county_map_data, aes(x = long, y = lat, group = group,\n    fill = bachelors)\n    ) +\n  labs(\n    x = \"Longitude\",\n    y = \"Latitude\",\n    fill = \"_____\",\n    title = \"_____\"\n  ) +\n  scale_fill_viridis_c(labels = label_percent(scale = 1)) +\n  coord_quickmap()\n\n\n\nExercise 3\nCreate a visualization of the relationship between bachelors and median_household_income and calculate the correlation. Use the visualization and correlation to describe the relationship between the two variables.\n\n\n\n\n\n\nTip\n\n\n\nRecall the analysis objective stated at the beginning of the Exercises section.\n\n\n\nIf you haven’t yet done so, now is a good time to render your document and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#part-2-modeling",
    "href": "hw/hw-01.html#part-2-modeling",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 2: Modeling",
    "text": "Part 2: Modeling\n\nExercise 4\nWe will use a linear regression model to better quantify the relationship between bachelors and median_household_income.\nWrite the form of the statistical model we will use for this task using mathematical notation. Use variable names (bachelors and median_household_income) in the equation for your model1.\n\n\nExercise 5\n\nFit the regression line corresponding to the statistical model in the previous exercise. Neatly display the model output using 3 digits.\nWrite the equation of the fitted model using mathematical notation. Use variable names (bachelors and median_household_income) in the equation.\n\n\n\nExercise 6\n\nInterpret the slope. The interpretation should be written in a way that is meaningful in the context of the data.\nIs it useful to interpret the intercept for this data? If so, write the interpretation in the context of the data. Otherwise, briefly explain why not.\n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "href": "hw/hw-01.html#part-3-inference-for-the-u.s.",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Part 3: Inference for the U.S.",
    "text": "Part 3: Inference for the U.S.\nWe want to use the data from these 600 randomly selected counties to draw conclusions about the relationship between the percent of adults age 25 and older with a bachelor’s degree and median household income for the over 3,000 counties in the United States.\n\nExercise 7\n\nWhat is the population of interest? What is the sample?\nIs it reasonable to treat the sample in this analysis as representative of the population? Briefly explain why or why not.\n\n\n\nExercise 8\nConduct a hypothesis test for the slope to assess whether there is sufficient evidence of a linear relationship between the percent of adults age 25 and older with a bachelor’s degree and the median household income in a county. Use a randomization (permutation) test. In your response:\n\nState the null and alternative hypotheses in words and mathematical notation\nShow all relevant code and output used to conduct the test. Use set.seed(2023) and 1000 iterations to construct the appropriate distribution.\nState the conclusion in the context of the data.\n\n\n\nExercise 9\nNext, construct a 95% confidence interval for the slope using bootstrapping with set.seed(2023) and 1000 iterations.\n\nShow all relevant code and output used to calculate the interval.\nInterpret the confidence interval in the context of the data.\nIs the confidence interval consistent with the results of the test from the previous exercise? Briefly explain why or why not.\n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#reproducibility",
    "href": "hw/hw-01.html#reproducibility",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Reproducibility",
    "text": "Reproducibility\n\nExercise 10\nYou are asked to use a reproducible workflow for all of your work in the class, and the goal of this question to is better understand potential real-world implications of doing (or not) doing so. Below are some real-life examples in which having a non-reproducible workflow resulted in errors that impacted research and public records.\n\nSource: Ostblom and Timbers (2022)\n\n\nReproducibility error\nConsequence\nSource(s)\n\n\n\n\nLimitations in Excel data formats\nLoss of 16,000 COVID case records in the UK\n(Kelion 2020)\n\n\nAutomatic formatting in Excel\nImportant genes disregarded in scientific studies\n(Ziemann, Eren, and El-Osta 2016)\n\n\nDeletion of a cell caused rows to shift\nMix-up of which patient group received the treatment\n(Wallensteen et al. 2018)\n\n\nUsing binary instead of explanatory labels\nMix-up of the intervention with the control group\n(Aboumatar and Wise 2019)\n\n\nUsing the same notation for missing data and zero values\nPaper retraction\n(Whitehouse et al. 2021)\n\n\nIncorrectly copying data in a spreadsheet\nDelay in the opening of a hospital\n(Picken 2020)\n\n\n\nChoose one of the scenarios from the table and read the linked article discussing what went wrong. Then,\n\nBriefly describe what went wrong, i.e., what part of the process of was not reproducible and what error or impact that had.\nThen, describe how the researchers could make the process reproducible.\n\n\nNow is a good time to render your document again if you haven’t done so recently and commit (with a meaningful commit message) and push all updates."
  },
  {
    "objectID": "hw/hw-01.html#submission",
    "href": "hw/hw-01.html#submission",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Submission",
    "text": "Submission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to commit and push changes.\nRemember – you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials ➡️ Duke NetID and log in using your NetID credentials.\nClick on your STA 210 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be “checked”).\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” section."
  },
  {
    "objectID": "hw/hw-01.html#grading-50-points",
    "href": "hw/hw-01.html#grading-50-points",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Grading (50 points)",
    "text": "Grading (50 points)\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1\n5\n\n\nEx 2\n5\n\n\nEx 3\n4\n\n\nEx 4\n3\n\n\nEx 5\n4\n\n\nEx 6\n4\n\n\nEx 7\n3\n\n\nEx 8\n7\n\n\nEx 9\n7\n\n\nEx 10\n5\n\n\nWorkflow & formatting\n32"
  },
  {
    "objectID": "hw/hw-01.html#footnotes",
    "href": "hw/hw-01.html#footnotes",
    "title": "HW 01: Education & median income in US Counties",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClick here for a guide on writing mathematical symbols using LaTex.↩︎\nThe “Workflow & formatting” grade is to assess the reproducible workflow and document format. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date in the YAML.↩︎"
  },
  {
    "objectID": "labs/lab-00.html",
    "href": "labs/lab-00.html",
    "title": "Lab 00: Getting started",
    "section": "",
    "text": "Important\n\n\n\nPlease complete all today’s lab tasks before leaving lab today.\n\n\n\nReserve a STA 210 container\n\nMake sure to reserve the container titled “STA210” not “RStudio”\nStart the container and confirm you see the RStudio interface\n\nSubmit your GitHub username and confirm you have access to the 210 container\n\nIf you do not have a GitHub username, click here for information on registering for a GitHub account and choosing a username\n\nComplete the STA 210 Student Survey"
  },
  {
    "objectID": "labs/lab-03.html",
    "href": "labs/lab-03.html",
    "title": "Lab 03: Coffee grades",
    "section": "",
    "text": "Important\n\n\n\nDue:\n\nFriday, September 22, 11:59pm (Tuesday labs)\nSunday, September 24, 11:59pm (Thursday labs)"
  },
  {
    "objectID": "labs/lab-03.html#learning-goals",
    "href": "labs/lab-03.html#learning-goals",
    "title": "Lab 03: Coffee grades",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you will…\n\nbe able to use mathematical models to conduct inference for the slope\nbe able to assess conditions for simple linear regression"
  },
  {
    "objectID": "labs/lab-03.html#grading-50-pts",
    "href": "labs/lab-03.html#grading-50-pts",
    "title": "Lab 03: Coffee grades",
    "section": "Grading (50 pts)",
    "text": "Grading (50 pts)\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1\n4\n\n\nEx 2\n3\n\n\nEx 3\n4\n\n\nEx 4\n3\n\n\nEx 5\n8\n\n\nEx 6\n5\n\n\nEx 7\n8\n\n\nEx 8\n6\n\n\nEx 9\n4\n\n\nEx 10\n2\n\n\nWorkflow & formatting\n31"
  },
  {
    "objectID": "labs/lab-03.html#footnotes",
    "href": "labs/lab-03.html#footnotes",
    "title": "Lab 03: Coffee grades",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow and document format. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date in the YAML.↩︎"
  },
  {
    "objectID": "labs/lab-02.html",
    "href": "labs/lab-02.html",
    "title": "Lab 02: Ice duration and air temperature in Madison, WI",
    "section": "",
    "text": "Important\n\n\n\nDue:\n\nFriday, September 15, 11:59pm (Tuesday labs)\nSunday, September 17, 11:59pm (Thursday labs)"
  },
  {
    "objectID": "labs/lab-02.html#learning-goals",
    "href": "labs/lab-02.html#learning-goals",
    "title": "Lab 02: Ice duration and air temperature in Madison, WI",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab you will…\n\nBe able to fit a simple linear regression model using R.\nBe able to interpret the slope and intercept for the model.\nBe able to use simulation-based inference to draw conclusions about the slope.\nContinue developing a workflow for reproducible data analysis."
  },
  {
    "objectID": "labs/lab-02.html#exercise-10",
    "href": "labs/lab-02.html#exercise-10",
    "title": "Lab 02: Ice duration and air temperature in Madison, WI",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nThere is a statistically significant linear relationship between average air temperature and average ice duration on Lake Monona \\((\\beta_1 \\neq 0)\\).\n\nDoes the confidence interval you calculated in the previous exercise support or refute this claim? Briefly explain.\n\nRender, commit, and push your final changes to your remote lab repo on GitHub. Click the checkbox next to each file in the Git pane to stage the updates you’ve made, write an informative commit message, and push. After you push the changes, the Git pane in RStudio should be empty."
  },
  {
    "objectID": "labs/lab-02.html#footnotes",
    "href": "labs/lab-02.html#footnotes",
    "title": "Lab 02: Ice duration and air temperature in Madison, WI",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://lter.github.io/lterdatasampler/index.html↩︎\nThe “Workflow & formatting” grade is to assess the reproducible workflow and document format. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date in the YAML.↩︎"
  },
  {
    "objectID": "labs/lab-01.html",
    "href": "labs/lab-01.html",
    "title": "Lab 01: Park access",
    "section": "",
    "text": "Important\n\n\n\nDue\n\nFriday, September 8, 11:59pm (Tuesday labs)\nSunday, September 10, 11:59pm (Thursday labs)"
  },
  {
    "objectID": "labs/lab-01.html#learning-goals",
    "href": "labs/lab-01.html#learning-goals",
    "title": "Lab 01: Park access",
    "section": "Learning goals",
    "text": "Learning goals\nBy the end of the lab, you will…\n\nBe familiar with the workflow using RStudio and GitHub\nGain practice writing a reproducible report using Quarto\nPractice version control using GitHub\nBe able to create data visualizations using ggplot2 and use those visualizations to describe distributions\nBe gain to fit, interpret, and evaluate simple linear regression models"
  },
  {
    "objectID": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-01.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 01: Park access",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta210-fa23 organization on GitHub. Click on the repo with the prefix lab-01-. It contains the starter documents you need to complete the lab.\n\nIf you do not see your lab-01 repo, click here to create your repo. Then, click here to (re)submit your GitHub username.\n\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File \\(\\rightarrow\\) New Project \\(\\rightarrow\\) Version Control \\(\\rightarrow\\) Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-01.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab."
  },
  {
    "objectID": "labs/lab-01.html#r-and-r-studio",
    "href": "labs/lab-01.html#r-and-r-studio",
    "title": "Lab 01: Park access",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of an Quarto (.Rmd) file.\n\n\n\n\n\n\nYAML\nThe top portion of your Quarto file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document.\n\n\n\n\nCommitting changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Quarto (.qmd) file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!\n\n\nPush changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push."
  },
  {
    "objectID": "labs/lab-01.html#footnotes",
    "href": "labs/lab-01.html#footnotes",
    "title": "Lab 01: Park access",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow and document format. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date in the YAML.↩︎"
  },
  {
    "objectID": "labs/lab-04.html",
    "href": "labs/lab-04.html",
    "title": "Lab 04: Alumni jobs",
    "section": "",
    "text": "Important\n\n\n\nDue:\n\nFriday, September 29, 11:59pm (Tuesday labs)\nSunday, October 1, 11:59pm (Thursday labs)\nIn today’s lab, you’ll use simple linear regression to analyze the relationship between the median early career salary and percent of alumni who perceive their job as making the world a better place for colleges and universities in the United States. You will also start working with your lab teams, write a team agreement, and be introduced to using GitHub for collaboration."
  },
  {
    "objectID": "labs/lab-04.html#exercise-1",
    "href": "labs/lab-04.html#exercise-1",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 1",
    "text": "Exercise 1\nFit a linear model that can be used to predict the typical (median) early career pay based on the percent of STEM degrees. Display the model output using 3 digits for numerical values."
  },
  {
    "objectID": "labs/lab-04.html#exercise-2",
    "href": "labs/lab-04.html#exercise-2",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate the predicted values and residuals from your model and save these results in a data frame. Print the first five rows of the new data frame.\n\nTeam Member 1: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercises 1- 2.\nTeam Member 2: It’s your turn! Type the team’s response to exercise 3."
  },
  {
    "objectID": "labs/lab-04.html#exercise-3",
    "href": "labs/lab-04.html#exercise-3",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 3",
    "text": "Exercise 3\nBefore using the model for prediction, let’s check the model conditions. To figure out how to do so, we type the following prompt into ChatGPT (“an AI powered language model”) “How do you check the model conditions for simple linear regression?”\nThe response from ChatGPT shown below would receive partial credit. For each condition, state whether it is correct or incorrect/ incomplete. If it incorrect/incomplete, state what is wrong or missing, then write the correct response.\n\nIn simple linear regression, you’re trying to establish a linear relationship between two variables: a dependent variable (Y) and an independent variable (X). The model conditions or assumptions for simple linear regression are important to check to ensure that your model is valid and reliable. Here are the key assumptions and how to check them:\n1. Linearity Assumption:\n\nAssumption: The relationship between the independent variable (X) and the dependent variable (Y) is linear.\nHow to Check: Create a scatterplot of Y against X. If the points roughly form a straight line, the linearity assumption is likely met.\n\n2. Independence Assumption:\n\nAssumption: The residuals (the differences between observed Y and predicted Y) are independent of each other.\nHow to Check: Plot the residuals against the independent variable (X) or the predicted values. Look for patterns or trends in the residuals. There should be no clear structure or autocorrelation in the residuals.\n\n3. Homoscedasticity [Constant variance] Assumption:\n\nAssumption: The variance of the residuals is constant across all levels of the independent variable.\nHow to Check: Plot the residuals against the predicted values or the independent variable (X). The spread of the residuals should remain roughly constant across the range of X.\n\n4. Normality Assumption:\n\nAssumption: The residuals follow a normal distribution.\nHow to Check: Create a histogram or a normal probability plot (Q-Q plot) of the residuals. If the residuals are approximately normally distributed, they should follow a bell-shaped curve in the histogram and lie along a straight line in the Q-Q plot.\n\nIt’s important to note that these assumptions may not always hold perfectly in real-world data, and minor violations may not necessarily invalidate your model. However, if you detect significant violations of these assumptions, you may need to consider alternative modeling techniques or transformations of your data to address the issues.\n\n\n✅ ⬆️ Team Member 2: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercise 3.\nTeam Member 3: It’s your turn! Type the team’s response to exercises 4 - 5.\n\n\n\n\n\n\n\nImportant\n\n\n\nYou can proceed assuming all the model conditions are satisfied."
  },
  {
    "objectID": "labs/lab-04.html#exercise-4",
    "href": "labs/lab-04.html#exercise-4",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 4",
    "text": "Exercise 4\n\n31 percent of the alumni at Johns Hopkins University received a STEM degree. Calculate the predicted early career pay at this university and the appropriate 95% interval. Interpret the interval in the context of the data.\nThe actual early career pay at this university is $67,200. Is this what you expected based on your analysis? Briefly explain your reasoning."
  },
  {
    "objectID": "labs/lab-04.html#exercise-5",
    "href": "labs/lab-04.html#exercise-5",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 5",
    "text": "Exercise 5\nNext, let’s consider how well the model fits the relationship between the early career pay and percent with a STEM degree.\n\nCalculate \\(R^2\\) and interpret it in the context of the data.\nCalculate RMSE and interpret it in the context of the data.\n\n\nTeam Member 3: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercise 4 - 5.\nTeam Member 4: It’s your turn! Type the team’s response to exercise 6."
  },
  {
    "objectID": "labs/lab-04.html#exercise-6",
    "href": "labs/lab-04.html#exercise-6",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 6",
    "text": "Exercise 6\nDo you think the model is useful for understanding and predicting the typical early career pay for alumni at a university? Briefly explain your reasoning.\n\nTeam Member 4: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the responses to exercise 6.\nTeam Member 1: It’s your turn! Type the team’s response to exercise 7."
  },
  {
    "objectID": "labs/lab-04.html#exercise-7",
    "href": "labs/lab-04.html#exercise-7",
    "title": "Lab 04: Alumni jobs",
    "section": "Exercise 7",
    "text": "Exercise 7\nFit another model which predicts the typical early career pay using only the percentage of alumni that believe their career will make the world a better place.\n\nNeatly display this model with 3 digits.\nWhich model do you think is better - this model or the model fit in Exercise 1? Explain your response showing any analysis used to make the decision.\n\n\nTeam Member 1: Knit, commit and push your changes to GitHub with an appropriate commit message again. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and the rest of the team can see the completed lab.\n\n\nAll other team members: Pull to get the updated documents from GitHub. Click on the .qmd file, and you should see the team’s completed lab!"
  },
  {
    "objectID": "labs/lab-04.html#footnotes",
    "href": "labs/lab-04.html#footnotes",
    "title": "Lab 04: Alumni jobs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDon’t trust yourself to keep your hands off the keyboard? Put them in your pocket or cross your arms. No matter how silly it might feel, resist the urge to touch your keyboard until otherwise instructed!↩︎\nThe “Workflow & formatting” grade is to assess the reproducible workflow and collaboration. This includes having at least one meaningful commit from each team member and updating the team name and date in the YAML.↩︎↩︎"
  },
  {
    "objectID": "hw/hw-02.html",
    "href": "hw/hw-02.html",
    "title": "HW 02: Palmer penguins",
    "section": "",
    "text": "In this analysis you will use simple and multiple linear regression to analyze relationships between variables in three different scenarios."
  },
  {
    "objectID": "hw/hw-02.html#exercise-1",
    "href": "hw/hw-02.html#exercise-1",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 1",
    "text": "Exercise 1\nOur eventual goal is to fit a model predicting body mass (which is more difficult to measure) from island, bill length, bill depth, flipper length, species, and sex.\nWe will start by preparing the data.\n\nUse the drop_na() function to remove any observations from the penguins data frame that has missing values. Your resulting data frame should have 333 observations.\n\n\n\n\n\n\n\nNote\n\n\n\nFor the purposes of this assignment, we will treat the missingness as random, i.e., this is still a representative sample even though we removed observations with missing values."
  },
  {
    "objectID": "hw/hw-02.html#exercise-2",
    "href": "hw/hw-02.html#exercise-2",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nUse the data to fit a model predicting body mass (which can be difficult to measure) from bill length.\nNeatly display the model using 3 digits.\nWrite the estimated regression equation. Use the variable names in your equation.\nInterpret the slope in the context of the data.\nCalculate the \\(R^2\\) value."
  },
  {
    "objectID": "hw/hw-02.html#exercise-3",
    "href": "hw/hw-02.html#exercise-3",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nPlot the fitted values vs. the residual values for the model in the previous exercise.\nMake another plot of the histogram of the residuals.\nIs inference for linear regression appropriate? Why or why not?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-4",
    "href": "hw/hw-02.html#exercise-4",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nThe p-value in Exercise 2 indicates statistical significance. Does this mean the model is a good fit for the data?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-5",
    "href": "hw/hw-02.html#exercise-5",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nNow, use the data to fit a model predicting body mass (which can be difficult to measure) from bill length, bill depth, flipper length, island, species, and sex. Only include main effects, i.e., no interaction terms, in this model.\nNeatly display the model using 3 digits.\nWrite the estimated regression equation. Use the variable names in your equation.\nCalculate the \\(R^2\\) value. Why is it larger than the previous one? Interpret this value in context of the data and the model.\n\n\n\n\n\n\n\nTip\n\n\n\nThe code for fitting multiple linear regression models is the same as simple linear regression. Use + to add multiple predictor variables to the model."
  },
  {
    "objectID": "hw/hw-02.html#exercise-6",
    "href": "hw/hw-02.html#exercise-6",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nPlot the fitted values vs. the residual values for the model in the previous exercise.\nMake another plot of the histogram of the residuals.\nIs a linear regression appropriate? Why or why not?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-7",
    "href": "hw/hw-02.html#exercise-7",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nInterpret the intercept in the context of the data.\nInterpret the coefficient of sex in the context of the data.\nInterpret coefficient (slope) of bill length in the context of the data.\nIs the coefficient of bill length the same as in Exercise 2. Briefly explain why or why not?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-8",
    "href": "hw/hw-02.html#exercise-8",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nCalculate the residual for a female Gentoo penguin on the Biscoe island that weighs 4450 grams with the following body measurements: bill_length_mm = 43.2, bill_depth_mm = 14.5, flipper_length_mm = 208.\nDoes the model overpredict or underpredict this penguin’s mass?"
  },
  {
    "objectID": "hw/hw-02.html#exercise-9",
    "href": "hw/hw-02.html#exercise-9",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 9",
    "text": "Exercise 9\nFill in the starter code below to write the function predict_boots which takes a bootstrap sample, calculates \\(R^2\\) terms for the two models listed below. Set the seed to 29.\n\nModel 1: The model from Exercise 5. Model 2: The model from Exercise 5, without the island term.\nThe last line of the code runs the function predict_boots for 1000 iterations and saves the output as the object r_squared_diffs. Create a new variable that calculates the difference between the \\(R^2\\) values for the two models.\nMake a histogram of the differences.\nWhat do you notice about the histogram?\nWhich model is best for predicting body mass of a penguin?\n\n\nset.seed(29)\n\npredict_boots &lt;- function(i) {\n  # take a bootstrap sample\n  boot &lt;- penguins |&gt;\n    slice_sample(n = nrow(penguins), replace = TRUE) |&gt;\n    mutate(boot_samp = i)\n  \n  #fit the model with island to the bootstrap sample\n  fit_island &lt;- linear_reg() |&gt;\n    fit(_____, data = boot)\n  \n  # fit the model without island to the bootstrap sample\n  fit_no_island &lt;- linear_reg() |&gt;\n    fit(_______, data = boot)\n  \n  #save the rsq values for each model\n  tibble(\n    island_r2 = glance(fit_island)$r.squared,\n    no_island_r2 = glance(fit_no_island)$r.squared\n  )\n}\n\n# run the function 1000 times and save the differences between\nr_squared_diffs &lt;- map_df(1:1000, predict_boots)"
  },
  {
    "objectID": "hw/hw-02.html#exercise-10",
    "href": "hw/hw-02.html#exercise-10",
    "title": "HW 02: Palmer penguins",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nUse the model from the previous exercise without island, and set the seed to 210.\nFit the model to 1000 bootstrap samples.\nMake a scatterplot of the estimated coefficients for flipper length (y-axis) vs. bill length (x-axis).\nCalculate a 95% confidence interval for the difference between these coefficient values. Is there evidence that either bill length or flipper length has a larger influence on the model? Briefly explain.\n\n\n\n\n\n\n\nTip\n\n\n\nThe code for bootstrapping in multiple linear regression is the same as the code for simple linear regression."
  },
  {
    "objectID": "hw/hw-02.html#footnotes",
    "href": "hw/hw-02.html#footnotes",
    "title": "HW 02: Palmer penguins",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe “Workflow & formatting” grade is to assess the reproducible workflow and document format. This includes having at least 3 informative commit messages, a neatly organized document with readable code and your name and the date in the YAML.↩︎"
  },
  {
    "objectID": "prepare/week-09.html",
    "href": "prepare/week-09.html",
    "title": "Week 09",
    "section": "",
    "text": "Important\n\n\n\n\nAE 10 due Thu, Oct 27, 11:59pm\nProject Proposal: due Fri, Nov 04: 11:59pm\n\nHW 03 moved to next week\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 Tidy Modeling in R - Chapter 10: Resampling for evaluating performance\nOct 24\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\n💻 MLR: Cross validation\nOct 24\n\n\n💻 MLR: Inference\nOct 26\n\n\n💻 MLR: Conditions\nOct 26\n\n\n💻 Lab: Project proposal\nOct 27 & 28\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 10: Cross validation\n\n\n📋 AE 11: MLR Inference + conditions\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\n📝 Project Proposal\ndue Fri, Nov 04, 11:59pm"
  },
  {
    "objectID": "prepare/week-10.html",
    "href": "prepare/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Important\n\n\n\n\nAE 12 due Thu, Nov 03, 11:59pm\nAE 13 due Sat, Nov 05, 11:59pm\nProject Proposal due Fri, Nov 04: 11:59pm\nHW 03 due Mon, Nov 07, 11:59pm\nLab 06:\n\ndue Mon, Nov 07, 11:59pm (Thu labs)\ndue Tue, Nov 08, 11:59pm (Fri labs)\n\n\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 IMS, Chap 9: Logistic Regression\nNov 02\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 MLR: Conditions\nOct 31\n\n\n💻 Logistic Regression: Introduction\nNov 02\n\n\n💻 Lab 06\nNov 03 - 04\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 12: Multiple Linear Regression Review\n\n\n📋 AE 13: Logistic Regression Intro\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\n📝 Project Proposal\ndue Fri, Nov 04, 11:59pm\n\n\n📝 HW 03\ndue Mon, Nov 07, 11:59pm\n\n\n📝 Lab 06\n\ndue Mon, Nov 07, 11:59pm (Thu labs)\ndue Tue, Nov 08, 11:59pm (Fri labs)\n\n\n\n📝 Statistics Experience\ndue Fri, Dec 09, 11:59pm"
  },
  {
    "objectID": "prepare/week-05.html",
    "href": "prepare/week-05.html",
    "title": "Week 05",
    "section": "",
    "text": "Important\n\n\n\nAnnouncements:\n\nNo labs this week - work on Exam 01\nNo TA office hours Wed - Fri\n\nProf. Tackett office hours Thu 10 - 11am\n\nNo Ed Discussion Wed - Fri\n\nDue dates:\n\nAE 06: due Thu, Sep 29, 11:59pm\nAE 07: due Sat, Oct 01, 11:59pm\nExam 01: Wed, Sep 28 - Fri, Sep 30 at 11:59pm\n\n\n\n\nPrepare\nNo readings this week.\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 MLR: Types of predictors\nSep 26\n\n\n💻 Exam 01 review\nSep 28\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 06: Prediction for MLR\n\n\n📋 AE 07: Exam 01 review\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\n📝 Exam 01\nFri, Sep 30, 11:59pm"
  },
  {
    "objectID": "prepare/sep-13.html",
    "href": "prepare/sep-13.html",
    "title": "September 13 lecture",
    "section": "",
    "text": "📖 IMS, Sec 24.2: Randomization test for the slope\n📖 IMS, Sec 24.3: Bootstrap confidence interval for the slope"
  },
  {
    "objectID": "prepare/sep-13.html#assigned-reading",
    "href": "prepare/sep-13.html#assigned-reading",
    "title": "September 13 lecture",
    "section": "",
    "text": "📖 IMS, Sec 24.2: Randomization test for the slope\n📖 IMS, Sec 24.3: Bootstrap confidence interval for the slope"
  },
  {
    "objectID": "prepare/week-07.html",
    "href": "prepare/week-07.html",
    "title": "Week 07",
    "section": "",
    "text": "Important\n\n\n\nDue dates:\n\nLab 04:\n\ndue Thu, Oct 13, 11:59pm (Thu lab)\ndue Fri, Oct 14, 11:59pm (Fri lab)\n\nProject topic ideas:\n\ndue Mon, Oct 17, 11:59pm (Thu lab)\ndue Tue, Oct 18, 11:59pm (Fri lab)\n\nHW 02:\n\ndue Wed, Oct 19, 11:59pm\n\n\n\n\n\nPrepare\nNo readings this week.\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Variable transformations\nOct 12\n\n\n\n\n\nPractice\nNo Application Exercises this week.\n\n\nPerform\n\n\n\n\n\n\n\nAssignment\nDue date\n\n\n\n\nProject topic ideas\n\ndue Mon, Oct 17, 11:59pm (Thu lab)\ndue Tue, Oct 18, 11:59pm (Fri lab)\n\n\n\n📝 HW 02\nWed, Oct 19, 11:59pm"
  },
  {
    "objectID": "prepare/week-12.html",
    "href": "prepare/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Important\n\n\n\n\nAE 14: due Thu, Nov 17, 11:59pm\nHW 04: due Mon, Nov 21, 11:59pm\n\n\n\n\nPrepare\n\n\n\n\n\n\n\nReading\nCorresponding lecture\n\n\n\n\n📖 IMS, Chp 26: Inference for logistic regression\nNov 16\n\n\n\n\n\nParticipate\n\n\n\n\n\n\n\n💻 Logistic regression: Model comparison\nNov 14\n\n\n💻 Logistic Regression: Inference + conditions\nNov 16\n\n\n💻 Lab: Project analysis + write up\nNov 17 + 18\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 14: Logistic regression - Model Comparison\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\n📝 HW 04\ndue Mon, Nov 21, 11:59pm\n\n\n📝 Statistics experience\ndue Fri, Dec 09, 11:59pm"
  },
  {
    "objectID": "prepare/week-02.html",
    "href": "prepare/week-02.html",
    "title": "September 06 lecture",
    "section": "",
    "text": "📖 STA 210 Notes: Ch 1: Simple linear regression"
  },
  {
    "objectID": "prepare/week-02.html#assigned-reading",
    "href": "prepare/week-02.html#assigned-reading",
    "title": "September 06 lecture",
    "section": "",
    "text": "📖 STA 210 Notes: Ch 1: Simple linear regression"
  },
  {
    "objectID": "prepare/week-02.html#additional-resources-optional",
    "href": "prepare/week-02.html#additional-resources-optional",
    "title": "September 06 lecture",
    "section": "Additional resources (optional)",
    "text": "Additional resources (optional)\n📖 Introduction to Modern Statistics (IMS) Ch 7: Linear regression with a single predictor"
  },
  {
    "objectID": "prepare/week-15.html",
    "href": "prepare/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Important\n\n\n\n\nExam 02: Mon, Dec 05 (evening) - Thu, Dec 08 at 12pm (noon)\nTeam Feedback #2 due Tue, Dec 06, 11:59pm\nNo class Wed, Dec 07\n\nOnline exam office hours (Zoom link in Sakai)\n\nStatistics experience due Fri, Dec 09, 11:59pm\nProject written report due Fri, Dec 09, 11:59pm (accepted until Sun, Dec 11, 11:59pm)\n\n\n\n\nPrepare\nNo readings this week.\n\n\nParticipate\n\n\n\n\n\n\n\nTopic\nDate\n\n\n\n\n💻 Exam 02 Review\nDec 05\n\n\n\n\n\nPractice\n\n\n\n\n\n\n📋 AE 16: Exam 02 Review\n\n\n\n\n\nPerform\n\n\n\n\n\n\n\n📝 Exam 02\nMon, Dec 05 evening - Thu, Dec 08, 12pm (noon)\n\n\n📝 Project written report\ndue Fri, Dec 09, 11:59pm (accepted until Sun, Dec 11, 11:59pm)\n\n\n📝 Statistics experience\ndue Fri, Dec 09, 11:59pm"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html",
    "href": "ae/ae-04-bootstrap.html",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-04 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class. The responses are due in your GitHub repo no later than Thursday, September 14 at 11:59pm.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#data",
    "href": "ae/ae-04-bootstrap.html#data",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "href": "ae/ae-04-bootstrap.html#exploratory-data-analysis",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#model",
    "href": "ae/ae-04-bootstrap.html#model",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "href": "ae/ae-04-bootstrap.html#bootstrap-confidence-interval",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Bootstrap confidence interval",
    "text": "Bootstrap confidence interval\n\n1. Calculate the observed fit (slope)\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159.\n\n\n\n\n2. Take n bootstrap samples and fit models to each one.\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(091222)\n\nboot_fits &lt;- ______ |&gt;\n  specify(______) |&gt;\n  generate(reps = ____, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n\nWhy do we set a seed before taking the bootstrap samples?\nMake a histogram of the bootstrap samples to visualize the bootstrap distribution.\n\n# Code for histogram\n\n\n\n\n3. Compute the 95% confidence interval as the middle 95% of the bootstrap distribution\nFill in the code, then set eval: true .\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = _____, \n  level = ____,\n  type = \"percentile\"\n)"
  },
  {
    "objectID": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "href": "ae/ae-04-bootstrap.html#changing-confidence-level",
    "title": "AE 04: Bootstrap confidence intervals",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nModify the code from Step 3 to create a 90% confidence interval.\n\n# Paste code for 90% confidence interval\n\n\n\nModify the code from Step 3 to create a 99% confidence interval.\n\n# Paste code for 90% confidence interval\n\n\nWhich confidence level produces the most accurate confidence interval (90%, 95%, 99%)? Explain\nWhich confidence level produces the most precise confidence interval (90%, 95%, 99%)? Explain\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-04 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-05-sim-testing.html",
    "href": "ae/ae-05-sim-testing.html",
    "title": "AE 05: Randomization test for the slope",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-05 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class. The responses are due in your GitHub repo no later than Saturday, September 16 at 11:59pm.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nlibrary(knitr)"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#data",
    "href": "ae/ae-05-sim-testing.html#data",
    "title": "AE 05: Randomization test for the slope",
    "section": "Data",
    "text": "Data\nThe data are on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020. It was originally scraped from Zillow, and can be found in the duke_forest data set in the openintro R package.\n\nglimpse(duke_forest)\n\nRows: 98\nColumns: 13\n$ address    &lt;chr&gt; \"1 Learned Pl, Durham, NC 27705\", \"1616 Pinecrest Rd, Durha…\n$ price      &lt;dbl&gt; 1520000, 1030000, 420000, 680000, 428500, 456000, 1270000, …\n$ bed        &lt;dbl&gt; 3, 5, 2, 4, 4, 3, 5, 4, 4, 3, 4, 4, 3, 5, 4, 5, 3, 4, 4, 3,…\n$ bath       &lt;dbl&gt; 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 5.0, 2.0, 3.0, 3.0,…\n$ area       &lt;dbl&gt; 6040, 4475, 1745, 2091, 1772, 1950, 3909, 2841, 3924, 2173,…\n$ type       &lt;chr&gt; \"Single Family\", \"Single Family\", \"Single Family\", \"Single …\n$ year_built &lt;dbl&gt; 1972, 1969, 1959, 1961, 2020, 2014, 1968, 1973, 1972, 1964,…\n$ heating    &lt;chr&gt; \"Other, Gas\", \"Forced air, Gas\", \"Forced air, Gas\", \"Heat p…\n$ cooling    &lt;fct&gt; central, central, central, central, central, central, centr…\n$ parking    &lt;chr&gt; \"0 spaces\", \"Carport, Covered\", \"Garage - Attached, Covered…\n$ lot        &lt;dbl&gt; 0.97, 1.38, 0.51, 0.84, 0.16, 0.45, 0.94, 0.79, 0.53, 0.73,…\n$ hoa        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ url        &lt;chr&gt; \"https://www.zillow.com/homedetails/1-Learned-Pl-Durham-NC-…"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "href": "ae/ae-05-sim-testing.html#exploratory-data-analysis",
    "title": "AE 05: Randomization test for the slope",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#model",
    "href": "ae/ae-05-sim-testing.html#model",
    "title": "AE 05: Randomization test for the slope",
    "section": "Model",
    "text": "Model\n\ndf_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00"
  },
  {
    "objectID": "ae/ae-05-sim-testing.html#hypothesis-test",
    "href": "ae/ae-05-sim-testing.html#hypothesis-test",
    "title": "AE 05: Randomization test for the slope",
    "section": "Hypothesis test",
    "text": "Hypothesis test\n\n\n\n\n\n\nTip\n\n\n\nFor code chunks with fill-in-the-blank code, change code chunk option to #| eval: true once you’ve filled in the code.\n\n\n\nState the null and alternative hypotheses\n[Add hypotheses in mathematical notation]\n\n\nGenerate null distribution using permutation\nFill in the code, then set eval: true .\n\nn = 100\nset.seed(09132023)\n\nnull_dist &lt;- _____ |&gt;\n  specify(______) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = _____, type = \"permute\") |&gt;\n  fit()\n\n\n\nVisualize distribution\n\n# Code for histogram of null distribution\n\n\n\nCalculate the p-value.\n\n# get observed fit \nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\n# calculate p-value\nget_p_value(\n  ____,\n  obs_stat = ____,\n  direction = \"two-sided\"\n)\n\n\nWhat does the warning message mean?\n\n\n\nState conclusion\n[Write your conclusion in the context of the data.]\n\n\n\n\n\n\nImportant\n\n\n\nTo submit the AE:\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-05 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-07-model-eval.html",
    "href": "ae/ae-07-model-eval.html",
    "title": "AE 07: Model evaluation",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate your ae-07 repo to get started.\nRender, commit, and push your responses to GitHub by the end of class. The responses are due in your GitHub repo no later than Thursday, September 28 at 11:59pm.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(patchwork) #arrange plots in a grid"
  },
  {
    "objectID": "ae/ae-07-model-eval.html#data",
    "href": "ae/ae-07-model-eval.html#data",
    "title": "AE 07: Model evaluation",
    "section": "Data",
    "text": "Data\nThe data set for this assignment is a subset from the Spotify Songs Tidy Tuesday data set. The data were originally obtained from Spotify using the spotifyr R package.\nIt contains numerous characteristics for each song. You can see the full list of variables and definitions here. This analysis will focus specifically on the following variables:\n\n\n\n\n\n\n\n\nvariable\nclass\ndescription\n\n\n\n\ntrack_id\ncharacter\nSong unique ID\n\n\ntrack_name\ncharacter\nSong Name\n\n\ntrack_artist\ncharacter\nSong Artist\n\n\ntrack_popularity\ndouble\nSong Popularity (0-100) where higher is better\n\n\nenergy\ndouble\nEnergy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n\n\nvalence\ndouble\nA measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n\n\n\nspotify &lt;- read_csv(\"data/spotify-popular.csv\")\n\nAre high energy songs more positive? To answer this question, we’ll analyze data on some of the most popular songs on Spotify, i.e. those with track_popularity &gt;= 80. We’ll use linear regression to fit a model to predict a song’s positiveness (valence) based on its energy level (energy).\nBelow are plots as part of the exploratory data analysis.\n\np1 &lt;- ggplot(data = spotify, aes(x = valence)) + \n  geom_histogram() + \n  labs(title = \"Distribution of Valence\", \n       subtitle = \" for Popular songs on Spotify\", \n       x = \"Valence\")\n\np2 &lt;- ggplot(data = spotify, aes(x = energy)) + \n  geom_histogram() + \n  labs(title = \"Distribution of Energy\", \n       subtitle = \"for Popular songs on Spotify\", \n       x = \"Energy\")\np1 + p2\n\n\n\n\n\nggplot(data = spotify, aes(x = energy, y = valence)) + \n  geom_point() + \n  labs(title = \"Valence vs. Energy\", \n       subtitle = \"Popular songs on Spotify\", \n       x = \"Energy\", \n       y = \"Valence\")"
  },
  {
    "objectID": "ae/ae-07-model-eval.html#model-with-90-ci-for-coefficients",
    "href": "ae/ae-07-model-eval.html#model-with-90-ci-for-coefficients",
    "title": "AE 07: Model evaluation",
    "section": "Model with 90% CI for coefficients",
    "text": "Model with 90% CI for coefficients\n\nspotify_fit &lt;- linear_reg() |&gt;\n  fit(valence ~ energy, data = spotify)\n\ntidy(spotify_fit, conf.int = TRUE, conf.level = 0.9) |&gt; \n  kable(digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n0.121\n0.035\n3.401\n0.001\n0.062\n0.179\n\n\nenergy\n0.614\n0.054\n11.321\n0.000\n0.525\n0.703"
  },
  {
    "objectID": "ae/ae-07-model-eval.html#create-augmented-data-frame",
    "href": "ae/ae-07-model-eval.html#create-augmented-data-frame",
    "title": "AE 07: Model evaluation",
    "section": "Create augmented data frame",
    "text": "Create augmented data frame\n\nspotify_aug &lt;- augment(spotify_fit$fit)"
  },
  {
    "objectID": "ae/ae-07-model-eval.html#create-residual-plots",
    "href": "ae/ae-07-model-eval.html#create-residual-plots",
    "title": "AE 07: Model evaluation",
    "section": "Create residual plots",
    "text": "Create residual plots\n\nggplot(data = spotify_aug, aes(x = .fitted, y = .resid)) + \n  geom_point() + \n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Fitted values\", \n       y = \"Residuals\", \n       title = \"Residuals vs. fitted\")\n\n\n\n\n\nresid_hist &lt;- ggplot(data = spotify_aug, aes(x = .resid)) + \n  geom_histogram() + \n  labs(x = \"Residuals\", \n       title = \"Distribution of residuals\")\n\nresid_qq &lt;- ggplot(data = spotify_aug, aes(sample = .resid)) +\n  stat_qq() + \n  stat_qq_line() +\n  labs(x = \"Theoretical quantiles\",\n       y = \"Observed residuals\", \n       title = \"Normal QQ-plot\")\n\nresid_hist + resid_qq"
  },
  {
    "objectID": "ae/ae-07-model-eval.html#exercise-1",
    "href": "ae/ae-07-model-eval.html#exercise-1",
    "title": "AE 07: Model evaluation",
    "section": "Exercise 1",
    "text": "Exercise 1\nAssess the four model conditions. State whether the condition is satisfied and briefly explain your response.\n\nLinearity\nConstant variance\nNormality\nIndependence"
  },
  {
    "objectID": "ae/ae-07-model-eval.html#exercise-2",
    "href": "ae/ae-07-model-eval.html#exercise-2",
    "title": "AE 07: Model evaluation",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate \\(R^2\\) and interpret this value in the context of the data."
  },
  {
    "objectID": "ae/ae-07-model-eval.html#exercise-3",
    "href": "ae/ae-07-model-eval.html#exercise-3",
    "title": "AE 07: Model evaluation",
    "section": "Exercise 3",
    "text": "Exercise 3\nCalculate RMSE and interpret this value in the context of the data."
  },
  {
    "objectID": "ae/ae-07-model-eval.html#evaluate-response-from-chatgpt",
    "href": "ae/ae-07-model-eval.html#evaluate-response-from-chatgpt",
    "title": "AE 07: Model evaluation",
    "section": "Evaluate response from ChatGPT",
    "text": "Evaluate response from ChatGPT\nI typed the following prompt into ChatGPT (“an AI powered language model”) “How do you check the model conditions for simple linear regression?”\nThe response from ChatGPT shown below would receive partial credit. For each condition, state whether it is (1) correct, (2) incorrect and if so, what is wrong, (3) incomplete and if so, what is missing.\n\nIn simple linear regression, you’re trying to establish a linear relationship between two variables: a dependent variable (Y) and an independent variable (X). The model conditions or assumptions for simple linear regression are important to check to ensure that your model is valid and reliable. Here are the key assumptions and how to check them:\n1. Linearity Assumption:\n\nAssumption: The relationship between the independent variable (X) and the dependent variable (Y) is linear.\nHow to Check: Create a scatterplot of Y against X. If the points roughly form a straight line, the linearity assumption is likely met.\n\n2. Independence Assumption:\n\nAssumption: The residuals (the differences between observed Y and predicted Y) are independent of each other.\nHow to Check: Plot the residuals against the independent variable (X) or the predicted values. Look for patterns or trends in the residuals. There should be no clear structure or autocorrelation in the residuals.\n\n3. Homoscedasticity [Constant variance] Assumption:\n\nAssumption: The variance of the residuals is constant across all levels of the independent variable.\nHow to Check: Plot the residuals against the predicted values or the independent variable (X). The spread of the residuals should remain roughly constant across the range of X.\n\n4. Normality Assumption:\n\nAssumption: The residuals follow a normal distribution.\nHow to Check: Create a histogram or a normal probability plot (Q-Q plot) of the residuals. If the residuals are approximately normally distributed, they should follow a bell-shaped curve in the histogram and lie along a straight line in the Q-Q plot.\n\nIt’s important to note that these assumptions may not always hold perfectly in real-world data, and minor violations may not necessarily invalidate your model. However, if you detect significant violations of these assumptions, you may need to consider alternative modeling techniques or transformations of your data to address the issues.\n\n\n\n\n\n\n\nNote\n\n\n\nYou will start to think about the answer in class and come up with a final answer with your group in Lab 04."
  },
  {
    "objectID": "ae/ae-07-model-eval.html#to-submit-the-ae",
    "href": "ae/ae-07-model-eval.html#to-submit-the-ae",
    "title": "AE 07: Model evaluation",
    "section": "To submit the AE:",
    "text": "To submit the AE:\n\n\n\n\n\n\nImportant\n\n\n\n\nRender the document to produce the PDF with all of your work from today’s class.\nPush all your work to your ae-07 repo on GitHub. (You do not submit AEs on Gradescope)."
  },
  {
    "objectID": "ae/ae-02-bikeshare.html",
    "href": "ae/ae-02-bikeshare.html",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "",
    "text": "Important\n\n\n\nFor this AE, you will discuss the questions in groups and submit answers on Ed Discussion. This AE does not count towards the Application Exercise grade.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#data",
    "href": "ae/ae-02-bikeshare.html#data",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Data",
    "text": "Data\nOur dataset contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the dcbikeshare data set in the dsbox R package.\nWe will focus on the following variables in the analysis:\n\ncount: total bike rentals\ntemp_orig: Temperature in degrees Celsius\nseason: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick here for the full list of variables and definitions.\n\nbikeshare &lt;- read_csv(\"data/dcbikeshare.csv\")"
  },
  {
    "objectID": "ae/ae-02-bikeshare.html#daily-counts-and-temperature",
    "href": "ae/ae-02-bikeshare.html#daily-counts-and-temperature",
    "title": "AE 02: Bike rentals in Washington, DC",
    "section": "Daily counts and temperature",
    "text": "Daily counts and temperature\n\nExercise 1\nVisualize the distribution of daily bike rentals and temperature as well as the relationship between these two variables.\n\np1 &lt;- ggplot(bikeshare, aes(x = count)) +\n  geom_histogram(binwidth = 250) + \n  labs(x = \"Daily bike rentals\")\n\np2 &lt;- ggplot(bikeshare, aes(x = temp_orig)) +\n  geom_histogram() + \n  labs(x = \"Temperature (Celsius)\")\n\np3 &lt;- ggplot(bikeshare, aes(y = count, x = temp_orig)) +\n  geom_point() + \n  labs(x = \"Temperature (Celsius)\", \n       y = \"Daily bike rentals\")\n\n(p1 | p2) / p3\n\n\n\n\n\n\nExercise 2\nDescribe the relationship between daily bike rentals and temperature. Comment on how we expect the number of bike rentals to change as the temperature increases.\n\n\nExercise 3\nSuppose you want to fit a model so you can use the temperature to predict the number of bike rentals. Would a model of the form\n\\[\\text{count} = \\beta_0 + \\beta_1 ~ \\text{temp\\_orig} + \\epsilon\\]\nbe an appropriate fit for the data? Why or why not?\nPut your group’s vote on Ed Discussion and briefly describe your reasoning in the comments.\n\nSection 001 (10:05am): edstem.org/us/courses/44523/discussion/3361086\nSection 002 (1:25pm): edstem.org/us/courses/44523/discussion/3361091"
  },
  {
    "objectID": "project-instructions.html",
    "href": "project-instructions.html",
    "title": "Final project",
    "section": "",
    "text": "Instructions will be posted when the project is assigned.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n, visualizations and summary statistics to describe the following: –&gt;"
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access computing resources for the introductory data science courses offered by the Duke University Department of Statistical Science, go to the Duke Container Manager website, cmgr.oit.duke.edu/containers.\nIf this is your first time accessing the containers, click on reserve STA210 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA210 under My reservations to access the RStudio instance you’ll use for the course."
  },
  {
    "objectID": "slides/lab-02.html#reminders",
    "href": "slides/lab-02.html#reminders",
    "title": "Lab 02",
    "section": "Reminders",
    "text": "Reminders\n\n\nSelect the pages corresponding to each exercise when you when you submit the assignment on Gradescope.\n\nClick here for written and video instructions on submitting an assignment and marking pages on Gradescope.\n\nIn your write up:\n\nWrite all narrative in complete sentences.\nInclude an informative title and axis labels on graphs.\nWrite responses in the context of the data.\nDescribe distribution using shape, center, spread, and potential outliers. Describe relationships between variables using strength, direction, and shape."
  },
  {
    "objectID": "slides/lab-02.html#axis-labels-and-titles",
    "href": "slides/lab-02.html#axis-labels-and-titles",
    "title": "Lab 02",
    "section": "Axis labels and titles",
    "text": "Axis labels and titles\n\nBelow is a graph of association between flipper length in millimeters and body mass in grams of three species of penguins in Palmer Station, Antarctica. What are informative title and axis labels for this graph?"
  },
  {
    "objectID": "slides/lab-02.html#code-style",
    "href": "slides/lab-02.html#code-style",
    "title": "Lab 02",
    "section": "Code style",
    "text": "Code style\nWhich code chunk would you rather read?\n\n# code chunk 1\npenguins|&gt;filter(!is.na(flipper_length_mm))|&gt;group_by(species)|&gt;summarise(min=min(flipper_length_mm),mean=mean(flipper_length_mm),sd=sd(flipper_length_mm),max=max(flipper_length_mm),n=n())\n\n\n\n\n# code chunk 2\npenguins |&gt; \n  filter(!is.na(flipper_length_mm)) |&gt; \n  group_by(species) |&gt; \n  summarise(min = min(flipper_length_mm), \n            mean = mean(flipper_length_mm), \n            max = max(flipper_length_mm),\n            n = n())"
  },
  {
    "objectID": "slides/lab-02.html#code-style-contd",
    "href": "slides/lab-02.html#code-style-contd",
    "title": "Lab 02",
    "section": "Code style cont’d",
    "text": "Code style cont’d\nMake code easier to read and debug by\n\nPutting each element on a different line (start a new line after + and |&gt;)\nPutting spaces before and after operators (+, -, *, =, |&gt; )\nIn general, avoiding long lines of code, i.e. lines longer than 120 characters.\n\nSee the Tidyverse Style Guide for more tips on code styling."
  },
  {
    "objectID": "slides/lab-02.html#todays-lab",
    "href": "slides/lab-02.html#todays-lab",
    "title": "Lab 02",
    "section": "Today’s lab",
    "text": "Today’s lab\n\nRemember to use a reproducible workflow with regular commits (and informative commit messages).\nPush all updated files after each commit! The Git pane should be clear after each Render -&gt; Commit -&gt; Push.\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#statistics-experience-assignment",
    "href": "slides/04-slr-bootstrap.html#statistics-experience-assignment",
    "title": "SLR: Simulation-based inference",
    "section": "Statistics experience assignment",
    "text": "Statistics experience assignment\nGoal: Engage with statistics / data science outside the classroom and connect your experience with what you’re learning in the course.\nWhat: Have a statistics experience + create a slide reflecting on the experience. Counts as a homework grade.\nWhen: Must do the activity this semester. Reflection due Monday, November 20 at 11:59pm\nFor more info: sta210-fa23.netlify.app/stats-experience"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#statistician-of-the-day",
    "href": "slides/04-slr-bootstrap.html#statistician-of-the-day",
    "title": "SLR: Simulation-based inference",
    "section": "Statistician of the day",
    "text": "Statistician of the day\nWhat: Each week, we will highlight a statisticians, data scientists, or other scholars from groups who have been historically marginalized in the field and whose work has made a significant impact.\nGoal: Learn about scholars you may not see in traditional textbooks and see the breadth of past and current work in the field.\nWho: Scholars are from the CURV (connecting, uplifting, and recognizing voices) database started by Dr. Jo Hardin at Pomona College\nParticipate: Present a Statistician of the Day or contribute to the CURV data base as your statistics experience"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#w.e.b.-du-bois",
    "href": "slides/04-slr-bootstrap.html#w.e.b.-du-bois",
    "title": "SLR: Simulation-based inference",
    "section": "W.E.B. Du Bois",
    "text": "W.E.B. Du Bois\n\n\n\n\nDu Bois (1868 - 1963) was a sociologist who contributed to the field of data visualization through infographics related to the African American in the early twentieth century.\nIn 1900 Du Bois contributed approximately 60 data visualizations to an exhibit at the Exposition Universelle in Paris, an exhibit designed to illustrate the progress made by African Americans since the end of slavery (only 37 years prior, in 1863).\n\nSource: hardin47.github.io/CURV/scholars/dubois.html"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#w.e.b.-du-bois-1",
    "href": "slides/04-slr-bootstrap.html#w.e.b.-du-bois-1",
    "title": "SLR: Simulation-based inference",
    "section": "W.E.B. Du Bois",
    "text": "W.E.B. Du Bois\n\n\nThe set of visualizations demonstrate how powerfully a picture can tell 1000 words, as the information Du Bois used was primarily available from public records (e.g., census and other government reports).\nSource: hardin47.github.io/CURV/scholars/dubois.html\n\n\n\n\nVisualization by W.E.B. Du Bois"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#ae-03-follow-up-1",
    "href": "slides/04-slr-bootstrap.html#ae-03-follow-up-1",
    "title": "SLR: Simulation-based inference",
    "section": "AE 03 Follow-up",
    "text": "AE 03 Follow-up\nGoal: Use simple linear regression to model the relationship between temperature and daily bike rentals in the winter season"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#ae-03-follow-up-2",
    "href": "slides/04-slr-bootstrap.html#ae-03-follow-up-2",
    "title": "SLR: Simulation-based inference",
    "section": "AE 03 Follow-up",
    "text": "AE 03 Follow-up\nStatistical Model:\n\\[count = \\beta_0 +\\beta_1 ~ temp\\_orig + \\epsilon, \\hspace{5mm} \\epsilon \\sim N(0, \\sigma_{\\epsilon}^2)\\]\n\n\nwinter_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(count ~ temp_orig, data = winter)\n\ntidy(winter_fit) |&gt; kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n-111.038\n238.312\n-0.466\n0.642\n\n\ntemp_orig\n222.416\n18.459\n12.049\n0.000"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#ae-03-follow-up-3",
    "href": "slides/04-slr-bootstrap.html#ae-03-follow-up-3",
    "title": "SLR: Simulation-based inference",
    "section": "AE 03 Follow-up",
    "text": "AE 03 Follow-up\nUse the output to write out the estimated regression equation.\n\\[\n\\hat{count} =  -111.038 + 222.416 ~temp\\_orig\n\\]\n\n\n\n\n\n\n\nYour turn!\n\n\n\nInterpret the slope in the context of the data.\nWhy is there no error term in the regression equation?\n\n\n\n\n\nLaTex:\n\\$\\$\\hat{count} = -111.038 + 222.416 ~ temp\\_orig\\$\\$"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#topics",
    "href": "slides/04-slr-bootstrap.html#topics",
    "title": "SLR: Simulation-based inference",
    "section": "Topics",
    "text": "Topics\n\nFind range of plausible values for the slope using bootstrap confidence intervals"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computational-setup",
    "href": "slides/04-slr-bootstrap.html#computational-setup",
    "title": "SLR: Simulation-based inference",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for Duke Forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#data-houses-in-duke-forest",
    "href": "slides/04-slr-bootstrap.html#data-houses-in-duke-forest",
    "title": "SLR: Simulation-based inference",
    "section": "Data: Houses in Duke Forest",
    "text": "Data: Houses in Duke Forest\n\n\n\nData on houses that were sold in the Duke Forest neighborhood of Durham, NC around November 2020\nScraped from Zillow\nSource: openintro::duke_forest\n\n\n\n\n\nGoal: Use the area (in square feet) to understand variability in the price of houses in Duke Forest."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#exploratory-data-analysis",
    "href": "slides/04-slr-bootstrap.html#exploratory-data-analysis",
    "title": "SLR: Simulation-based inference",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\n\nCode\nggplot(duke_forest, aes(x = area, y = price)) +\n  geom_point(alpha = 0.7) +\n  labs(\n    x = \"Area (square feet)\",\n    y = \"Sale price (USD)\",\n    title = \"Price and area of houses in Duke Forest\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#modeling",
    "href": "slides/04-slr-bootstrap.html#modeling",
    "title": "SLR: Simulation-based inference",
    "section": "Modeling",
    "text": "Modeling\n\ndf_fit &lt;- linear_reg() |&gt;\n  #set_engine(\"lm\") |&gt;\n  fit(price ~ area, data = duke_forest)\n\ntidy(df_fit) |&gt;\n  kable(digits = 2) #neatly format table to 2 digits\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n116652.33\n53302.46\n2.19\n0.03\n\n\narea\n159.48\n18.17\n8.78\n0.00\n\n\n\n\n\n\n\n\n\n\nIntercept: Duke Forest houses that are 0 square feet are expected to sell, for $116,652, on average.\n\nIs this interpretation useful?\n\nSlope: For each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#from-sample-to-population",
    "href": "slides/04-slr-bootstrap.html#from-sample-to-population",
    "title": "SLR: Simulation-based inference",
    "section": "From sample to population",
    "text": "From sample to population\n\nFor each additional square foot, we expect the sale price of Duke Forest houses to be higher by $159, on average.\n\n\n\nThis estimate is valid for the single sample of 98 houses.\nBut what if we’re not interested quantifying the relationship between the size and price of a house in this single sample?\nWhat if we want to say something about the relationship between these variables for all houses in Duke Forest?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#statistical-inference",
    "href": "slides/04-slr-bootstrap.html#statistical-inference",
    "title": "SLR: Simulation-based inference",
    "section": "Statistical inference",
    "text": "Statistical inference\n\nStatistical inference provide methods and tools so we can use the single observed sample to make valid statements (inferences) about the population it comes from\nFor our inferences to be valid, the sample should be random and representative of the population we’re interested in"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#inference-for-simple-linear-regression",
    "href": "slides/04-slr-bootstrap.html#inference-for-simple-linear-regression",
    "title": "SLR: Simulation-based inference",
    "section": "Inference for simple linear regression",
    "text": "Inference for simple linear regression\n\nCalculate a confidence interval for the slope, \\(\\beta_1\\)\nConduct a hypothesis test for the slope,\\(\\beta_1\\)"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval",
    "href": "slides/04-slr-bootstrap.html#confidence-interval",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval",
    "text": "Confidence interval\n\n\nA plausible range of values for a population parameter is called a confidence interval\nUsing only a single point estimate is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net\n\nWe can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\nSimilarly, if we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval-for-the-slope-1",
    "href": "slides/04-slr-bootstrap.html#confidence-interval-for-the-slope-1",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence interval for the slope",
    "text": "Confidence interval for the slope\nA confidence interval will allow us to make a statement like “For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus X dollars.”\n\n\nShould X be $10? $100? $1000?\nIf we were to take another sample of 98 would we expect the slope calculated based on that sample to be exactly $159? Off by $10? $100? $1000?\nThe answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\nWe need a way to quantify the variability of the sample statistic"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#quantify-the-variability-of-the-slope",
    "href": "slides/04-slr-bootstrap.html#quantify-the-variability-of-the-slope",
    "title": "SLR: Simulation-based inference",
    "section": "Quantify the variability of the slope",
    "text": "Quantify the variability of the slope\nfor estimation\n\n\nTwo approaches:\n\nVia simulation (what we’ll do today)\nVia mathematical models (what we’ll do in the next class)\n\nBootstrapping to quantify the variability of the slope for the purpose of estimation:\n\nBootstrap new samples from the original sample\nFit models to each of the samples and estimate the slope\nUse features of the distribution of the bootstrapped slopes to construct a confidence interval"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-1",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-1",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-2",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-2",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-3",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-3",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-4",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-4",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-sample-5",
    "href": "slides/04-slr-bootstrap.html#bootstrap-sample-5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap sample 5",
    "text": "Bootstrap sample 5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso on and so forth…"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-samples-1---5",
    "href": "slides/04-slr-bootstrap.html#bootstrap-samples-1---5",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 5",
    "text": "Bootstrap samples 1 - 5"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#bootstrap-samples-1---100",
    "href": "slides/04-slr-bootstrap.html#bootstrap-samples-1---100",
    "title": "SLR: Simulation-based inference",
    "section": "Bootstrap samples 1 - 100",
    "text": "Bootstrap samples 1 - 100"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples",
    "href": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples-1",
    "href": "slides/04-slr-bootstrap.html#slopes-of-bootstrap-samples-1",
    "title": "SLR: Simulation-based inference",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples\n\nFill in the blank: For each additional square foot, we expect the sale price of Duke Forest houses to be higher, on average, by $159, plus or minus ___ dollars."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-level",
    "href": "slides/04-slr-bootstrap.html#confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Confidence level",
    "text": "Confidence level\n\nHow confident are you that the true slope is between $0 and $250? How about $150 and $170? How about $90 and $210?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#confidence-interval-1",
    "href": "slides/04-slr-bootstrap.html#confidence-interval-1",
    "title": "SLR: Simulation-based inference",
    "section": "95% confidence interval",
    "text": "95% confidence interval\n\n\n\nA 95% confidence interval is bounded by the middle 95% of the bootstrap distribution\nWe are 95% confident that for each additional square foot, the model predicts the sale price of Duke Forest houses to be higher, on average, by $90.43 to $205.77."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-i",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-i",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope I",
    "text": "Computing the CI for the slope I\nCalculate the observed slope:\n\nobserved_fit &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  fit()\n\nobserved_fit\n\n# A tibble: 2 × 2\n  term      estimate\n  &lt;chr&gt;        &lt;dbl&gt;\n1 intercept  116652.\n2 area          159."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-ii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope II",
    "text": "Computing the CI for the slope II\nTake 100 bootstrap samples and fit models to each one:\n\nset.seed(1120)\n\nboot_fits &lt;- duke_forest |&gt;\n  specify(price ~ area) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  fit()\n\nboot_fits\n\n# A tibble: 200 × 3\n# Groups:   replicate [100]\n   replicate term      estimate\n       &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# ℹ 190 more rows"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "href": "slides/04-slr-bootstrap.html#computing-the-ci-for-the-slope-iii",
    "title": "SLR: Simulation-based inference",
    "section": "Computing the CI for the slope III",
    "text": "Computing the CI for the slope III\nPercentile method: Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" #default method\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#precision-vs.-accuracy",
    "href": "slides/04-slr-bootstrap.html#precision-vs.-accuracy",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#precision-vs.-accuracy-1",
    "href": "slides/04-slr-bootstrap.html#precision-vs.-accuracy-1",
    "title": "SLR: Simulation-based inference",
    "section": "Precision vs. accuracy",
    "text": "Precision vs. accuracy\n\nHow can we get best of both worlds – high precision and high accuracy?"
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#changing-confidence-level",
    "href": "slides/04-slr-bootstrap.html#changing-confidence-level",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n\n\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          92.1     223.\n2 intercept -36765.   296528."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#changing-confidence-level-1",
    "href": "slides/04-slr-bootstrap.html#changing-confidence-level-1",
    "title": "SLR: Simulation-based inference",
    "section": "Changing confidence level",
    "text": "Changing confidence level\n\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          104.     212.\n2 intercept  -24380.  256730.\n\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n\n# A tibble: 2 × 3\n  term      lower_ci upper_ci\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 area          56.3     226.\n2 intercept -61950.   370395."
  },
  {
    "objectID": "slides/04-slr-bootstrap.html#recap",
    "href": "slides/04-slr-bootstrap.html#recap",
    "title": "SLR: Simulation-based inference",
    "section": "Recap",
    "text": "Recap\n\nPopulation: Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = \\(N\\))\nSample: Subset of the population, ideally random and representative (sample size = \\(n\\))\nSample statistic \\(\\ne\\) population parameter, but if the sample is good, it can be a good estimate\nStatistical inference: Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\nWe report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\nSince we can’t continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/lab-00.html#meet-your-ta",
    "href": "slides/lab-00.html#meet-your-ta",
    "title": "Welcome to STA 210 Labs!",
    "section": "Meet your TA!",
    "text": "Meet your TA!"
  },
  {
    "objectID": "slides/lab-00.html#meet-each-other",
    "href": "slides/lab-00.html#meet-each-other",
    "title": "Welcome to STA 210 Labs!",
    "section": "Meet each other!",
    "text": "Meet each other!\n\n\nGet into groups of 4 - 5.\nIntroduce yourself - Name, year, major\nChoose a reporter\n\nNeed help choosing? Person with birthday closest to today’s date.\n\nIdentify 8 things everyone in the group has in common\n\nNot being a Duke student\nNot clothes (e.g., we’re all wearing socks)\nNot body parts (e.g., we all have a nose)\n\nReporter will share list with the class.\n\n\n\n\n\n−+\n06:00"
  },
  {
    "objectID": "slides/lab-00.html#what-to-expect-in-lab",
    "href": "slides/lab-00.html#what-to-expect-in-lab",
    "title": "Welcome to STA 210 Labs!",
    "section": "What to expect in lab",
    "text": "What to expect in lab\n\nIntroduction to the lab assignment (~ 5 - 10 minutes)\nWork on the lab assignment (individual for the first few weeks, but in teams for the rest of the semester)\nLab instructions will be posted on the course website\nStart each lab by finding your assignment repo in the course GitHub organization\n\nMore on the computing tools during lecture"
  },
  {
    "objectID": "slides/lab-00.html#todays-lab",
    "href": "slides/lab-00.html#todays-lab",
    "title": "Welcome to STA 210 Labs!",
    "section": "Today’s lab",
    "text": "Today’s lab\nThe rest of the today’s lab is focused on setting up the computing for the course and completing the class survey. Click the link below for the Lab 00 instructions.\n🔗 sta210-fa23.netlify.app/labs/lab-00.html\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/03-slr-intro.html#topics",
    "href": "slides/03-slr-intro.html#topics",
    "title": "Simple Linear Regression",
    "section": "Topics",
    "text": "Topics\n\n\nUse simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nEstimate the slope and intercept of the regression line using the least squares method.\nInterpret the slope and intercept of the regression line.\nPredict the response given a value of the predictor variable.\nUse tidymodels to fit and summarize regression models in R."
  },
  {
    "objectID": "slides/03-slr-intro.html#computation-set-up",
    "href": "slides/03-slr-intro.html#computation-set-up",
    "title": "Simple Linear Regression",
    "section": "Computation set up",
    "text": "Computation set up\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\nlibrary(knitr)          # for formatting tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-scores",
    "href": "slides/03-slr-intro.html#movie-scores",
    "title": "Simple Linear Regression",
    "section": "Movie scores",
    "text": "Movie scores\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-intro.html#data-prep",
    "href": "slides/03-slr-intro.html#data-prep",
    "title": "Simple Linear Regression",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)"
  },
  {
    "objectID": "slides/03-slr-intro.html#data-overview",
    "href": "slides/03-slr-intro.html#data-overview",
    "title": "Simple Linear Regression",
    "section": "Data overview",
    "text": "Data overview\n\nglimpse(movie_scores)\n\nRows: 146\nColumns: 23\n$ film                       &lt;chr&gt; \"Avengers: Age of Ultron\", \"Cinderella\", \"A…\n$ year                       &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ critics                    &lt;int&gt; 74, 85, 80, 18, 14, 63, 42, 86, 99, 89, 84,…\n$ audience                   &lt;int&gt; 86, 80, 90, 84, 28, 62, 53, 64, 82, 87, 77,…\n$ metacritic                 &lt;int&gt; 66, 67, 64, 22, 29, 50, 53, 81, 81, 80, 71,…\n$ metacritic_user            &lt;dbl&gt; 7.1, 7.5, 8.1, 4.7, 3.4, 6.8, 7.6, 6.8, 8.8…\n$ imdb                       &lt;dbl&gt; 7.8, 7.1, 7.8, 5.4, 5.1, 7.2, 6.9, 6.5, 7.4…\n$ fandango_stars             &lt;dbl&gt; 5.0, 5.0, 5.0, 5.0, 3.5, 4.5, 4.0, 4.0, 4.5…\n$ fandango_ratingvalue       &lt;dbl&gt; 4.5, 4.5, 4.5, 4.5, 3.0, 4.0, 3.5, 3.5, 4.0…\n$ rt_norm                    &lt;dbl&gt; 3.70, 4.25, 4.00, 0.90, 0.70, 3.15, 2.10, 4…\n$ rt_user_norm               &lt;dbl&gt; 4.30, 4.00, 4.50, 4.20, 1.40, 3.10, 2.65, 3…\n$ metacritic_norm            &lt;dbl&gt; 3.30, 3.35, 3.20, 1.10, 1.45, 2.50, 2.65, 4…\n$ metacritic_user_nom        &lt;dbl&gt; 3.55, 3.75, 4.05, 2.35, 1.70, 3.40, 3.80, 3…\n$ imdb_norm                  &lt;dbl&gt; 3.90, 3.55, 3.90, 2.70, 2.55, 3.60, 3.45, 3…\n$ rt_norm_round              &lt;dbl&gt; 3.5, 4.5, 4.0, 1.0, 0.5, 3.0, 2.0, 4.5, 5.0…\n$ rt_user_norm_round         &lt;dbl&gt; 4.5, 4.0, 4.5, 4.0, 1.5, 3.0, 2.5, 3.0, 4.0…\n$ metacritic_norm_round      &lt;dbl&gt; 3.5, 3.5, 3.0, 1.0, 1.5, 2.5, 2.5, 4.0, 4.0…\n$ metacritic_user_norm_round &lt;dbl&gt; 3.5, 4.0, 4.0, 2.5, 1.5, 3.5, 4.0, 3.5, 4.5…\n$ imdb_norm_round            &lt;dbl&gt; 4.0, 3.5, 4.0, 2.5, 2.5, 3.5, 3.5, 3.5, 3.5…\n$ metacritic_user_vote_count &lt;int&gt; 1330, 249, 627, 31, 88, 34, 17, 124, 62, 54…\n$ imdb_user_vote_count       &lt;int&gt; 271107, 65709, 103660, 3136, 19560, 39373, …\n$ fandango_votes             &lt;int&gt; 14846, 12640, 12055, 1793, 1021, 397, 252, …\n$ fandango_difference        &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…"
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-scores-data",
    "href": "slides/03-slr-intro.html#movie-scores-data",
    "title": "Simple Linear Regression",
    "section": "Movie scores data",
    "text": "Movie scores data\nThe data set contains the “Tomatometer” score (critics) and audience score (audience) for 146 movies rated on rottentomatoes.com."
  },
  {
    "objectID": "slides/03-slr-intro.html#movie-ratings-data",
    "href": "slides/03-slr-intro.html#movie-ratings-data",
    "title": "Simple Linear Regression",
    "section": "Movie ratings data",
    "text": "Movie ratings data\nGoal: Fit a line to describe the relationship between the critics score and audience score.\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/03-slr-intro.html#why-fit-a-line",
    "href": "slides/03-slr-intro.html#why-fit-a-line",
    "title": "Simple Linear Regression",
    "section": "Why fit a line?",
    "text": "Why fit a line?\nWe fit a line to accomplish one or both of the following:\n\n\nPrediction\n\nWhat is the audience score expected to be for an upcoming movie that received 35% from the critics?\n\n\n\n\nInference\n\nIs the critics score a useful predictor of the audience score? By how much is the audience score expected to change for each additional point in the critics score?"
  },
  {
    "objectID": "slides/03-slr-intro.html#terminology",
    "href": "slides/03-slr-intro.html#terminology",
    "title": "Simple Linear Regression",
    "section": "Terminology",
    "text": "Terminology\n\n\n\nResponse, Y: variable describing the outcome of interest\nPredictor, X: variable we use to help understand the variability in the response\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model",
    "href": "slides/03-slr-intro.html#regression-model",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the response, \\(Y\\), and the predictor, \\(X\\).\n\\[\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model-1",
    "href": "slides/03-slr-intro.html#regression-model-1",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\\]\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mu_{Y|X}\\) is the mean value of \\(Y\\) given a particular value of \\(X\\)."
  },
  {
    "objectID": "slides/03-slr-intro.html#regression-model-2",
    "href": "slides/03-slr-intro.html#regression-model-2",
    "title": "Simple Linear Regression",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[5pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n\\end{aligned}\n\\]\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/03-slr-intro.html#slr-statistical-model",
    "href": "slides/03-slr-intro.html#slr-statistical-model",
    "title": "Simple Linear Regression",
    "section": "SLR: Statistical model",
    "text": "SLR: Statistical model\nWhen we have a quantitative response, \\(Y\\), and a single quantitative predictor, \\(X\\), we can use a simple linear regression model to describe the relationship between \\(Y\\) and \\(X\\). \\[\\Large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}\\]\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\\(\\epsilon\\): Error"
  },
  {
    "objectID": "slides/03-slr-intro.html#slr-regression-equation",
    "href": "slides/03-slr-intro.html#slr-regression-equation",
    "title": "Simple Linear Regression",
    "section": "SLR: Regression equation",
    "text": "SLR: Regression equation\n\\[\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}\\]\n\n\\(\\hat{\\beta}_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\\(\\hat{\\beta}_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\nNo error term!"
  },
  {
    "objectID": "slides/03-slr-intro.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "href": "slides/03-slr-intro.html#choosing-values-for-hatbeta_1-and-hatbeta_0",
    "title": "Simple Linear Regression",
    "section": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)",
    "text": "Choosing values for \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_0\\)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "slides/03-slr-intro.html#residuals",
    "href": "slides/03-slr-intro.html#residuals",
    "title": "Simple Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\\[\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#least-squares-line",
    "href": "slides/03-slr-intro.html#least-squares-line",
    "title": "Simple Linear Regression",
    "section": "Least squares line",
    "text": "Least squares line\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i\\]\n\nThe sum of squared residuals is\n\n\\[e^2_1 + e^2_2 + \\dots + e^2_n\\]\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/03-slr-intro.html#properties-of-least-squares-regression",
    "href": "slides/03-slr-intro.html#properties-of-least-squares-regression",
    "title": "Simple Linear Regression",
    "section": "Properties of least squares regression",
    "text": "Properties of least squares regression\n\n\nThe regression line goes through the center of mass point, the coordinates corresponding to average \\(X\\) and average \\(Y\\): \\(\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}\\)\nThe slope has the same sign as the correlation coefficient: \\(\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}\\)\nThe sum of the residuals is approximately zero: \\(\\sum_{i = 1}^n e_i \\approx 0\\)\nThe residuals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "slides/03-slr-intro.html#estimating-the-slope",
    "href": "slides/03-slr-intro.html#estimating-the-slope",
    "title": "Simple Linear Regression",
    "section": "Estimating the slope",
    "text": "Estimating the slope\n\\[\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}\\]\n\n\n\\[\\begin{aligned}\ns_X &= 30.1688 \\\\\ns_Y &=  20.0244 \\\\\nr &= 0.7814\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\n\\hat{\\beta}_1 &= 0.7814 \\times \\frac{20.0244}{30.1688} \\\\\n&= 0.5187\\end{aligned}\\]\n\n\n\n\nClickhere for details on deriving the equations for slope and intercept."
  },
  {
    "objectID": "slides/03-slr-intro.html#estimating-the-intercept",
    "href": "slides/03-slr-intro.html#estimating-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Estimating the intercept",
    "text": "Estimating the intercept\n\\[\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}\\]\n\n\n\\[\\begin{aligned}\n&\\bar{x} = 60.8493 \\\\\n&\\bar{y} = 63.8767 \\\\\n&\\hat{\\beta}_1 = 0.5187\n\\end{aligned}\\]\n\n\\[\\begin{aligned}\\hat{\\beta}_0 &= 63.8767 - 0.5187 \\times 60.8493 \\\\\n&= 32.3142\n\\end{aligned}\\]\n\n\n\n\nClick here for details on deriving the equations for slope and intercept."
  },
  {
    "objectID": "slides/03-slr-intro.html#interpretation",
    "href": "slides/03-slr-intro.html#interpretation",
    "title": "Simple Linear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\n\nPost your answers to the following questions on Ed Discussion:\n\nThe slope of the model for predicting audience score from critics score is 0.5187 . Which of the following is the best interpretation of this value?\n32.3142 is the predicted mean audience score for what type of movies?\n\n\n\n\nLink for Section 001 (10:05am lecture)\nLink for Section 002 (1:25pm lecture)\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/03-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "href": "slides/03-slr-intro.html#does-it-make-sense-to-interpret-the-intercept",
    "title": "Simple Linear Regression",
    "section": "Does it make sense to interpret the intercept?",
    "text": "Does it make sense to interpret the intercept?\n\n✅ The intercept is meaningful in the context of the data if\n\nthe predictor can feasibly take values equal to or near zero, or\nthere are values near zero in the observed data.\n\n\n\n🛑 Otherwise, the intercept may not be meaningful!"
  },
  {
    "objectID": "slides/03-slr-intro.html#making-a-prediction",
    "href": "slides/03-slr-intro.html#making-a-prediction",
    "title": "Simple Linear Regression",
    "section": "Making a prediction",
    "text": "Making a prediction\nSuppose that a movie has a critics score of 70. According to this model, what is the movie’s predicted audience score?\n\\[\\begin{aligned}\n\\widehat{\\text{audience}} &= 32.3142 + 0.5187 \\times \\text{critics} \\\\\n&= 32.3142 + 0.5187 \\times 70 \\\\\n&= 68.6232\n\\end{aligned}\\]"
  },
  {
    "objectID": "slides/03-slr-intro.html#tidymodels",
    "href": "slides/03-slr-intro.html#tidymodels",
    "title": "Simple Linear Regression",
    "section": "tidymodels",
    "text": "tidymodels\n\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\n\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.1.1\n✔ dials        1.2.0     ✔ tune         1.1.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.0     ✔ yardstick    1.2.0\n✔ recipes      1.0.6     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org"
  },
  {
    "objectID": "slides/03-slr-intro.html#why-tidymodels",
    "href": "slides/03-slr-intro.html#why-tidymodels",
    "title": "Simple Linear Regression",
    "section": "Why tidymodels?",
    "text": "Why tidymodels?\n\nConsistent syntax for different model types (linear, logistic, random forest, Bayesian, etc.)\nStreamline modeling workflow\n\nSplit data into train and test sets\nTransform and create new variables\nAssess model performance\nUse model for prediction and inference"
  },
  {
    "objectID": "slides/03-slr-intro.html#step-1-specify-model",
    "href": "slides/03-slr-intro.html#step-1-specify-model",
    "title": "Simple Linear Regression",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/03-slr-intro.html#step-2-set-model-fitting-engine",
    "href": "slides/03-slr-intro.html#step-2-set-model-fitting-engine",
    "title": "Simple Linear Regression",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\nlinear_reg() |&gt;\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/03-slr-intro.html#a-closer-look-at-the-regression-output",
    "href": "slides/03-slr-intro.html#a-closer-look-at-the-regression-output",
    "title": "Simple Linear Regression",
    "section": "A closer look at the regression output",
    "text": "A closer look at the regression output\n\nmovie_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(audience ~ critics, data = movie_scores)\n\nmovie_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = audience ~ critics, data = data)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187  \n\n\n\\[\\widehat{\\text{audience}} = 32.3155 + 0.5187 \\times \\text{critics}\\]\n\n\nNote: The intercept is off by a tiny bit from the hand-calculated intercept, this is just due to rounding in the hand calculation."
  },
  {
    "objectID": "slides/03-slr-intro.html#the-regression-output",
    "href": "slides/03-slr-intro.html#the-regression-output",
    "title": "Simple Linear Regression",
    "section": "The regression output",
    "text": "The regression output\nWe’ll focus on the first column for now…\n\nlinear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(audience ~ critics, data = movie_scores) |&gt;\n  tidy() \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-intro.html#format-output-with-kable",
    "href": "slides/03-slr-intro.html#format-output-with-kable",
    "title": "Simple Linear Regression",
    "section": "Format output with kable",
    "text": "Format output with kable\nUse the kable function from the knitr package to produce a table and specify number of significant digits\n\nlinear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(audience ~ critics, data = movie_scores) |&gt;\n  tidy() |&gt;\n  kable(digits = 4)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n32.3155\n2.3425\n13.7953\n0\n\n\ncritics\n0.5187\n0.0345\n15.0281\n0"
  },
  {
    "objectID": "slides/03-slr-intro.html#prediction-1",
    "href": "slides/03-slr-intro.html#prediction-1",
    "title": "Simple Linear Regression",
    "section": "Prediction",
    "text": "Prediction\n\n# create a data frame for a new movie\nnew_movie &lt;- tibble(critics = 70)\n\n# predict the outcome for a new movie\npredict(movie_fit, new_movie)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  68.6"
  },
  {
    "objectID": "slides/03-slr-intro.html#recap",
    "href": "slides/03-slr-intro.html#recap",
    "title": "Simple Linear Regression",
    "section": "Recap",
    "text": "Recap\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\nUsed the least squares method to estimate the slope and intercept.\nInterpreted the slope and intercept.\n\nSlope: For every one unit increase in \\(x\\), we expect y to change by \\(\\hat{\\beta}_1\\) units, on average.\nIntercept: If \\(x\\) is 0, then we expect \\(y\\) to be \\(\\hat{\\beta}_0\\) units\n\nPredicted the response given a value of the predictor variable.\nUsed tidymodels to fit and summarize regression models in R.\n\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#announcements",
    "href": "slides/03-slr-tidymodels.html#announcements",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Announcements",
    "text": "Announcements\n\nNo office hours today. Office hours start Tuesday, September 6. Click here for full schedule\nCheck your email for an email to join the course GitHub organization. You will receive one by Tuesday, September 6.\nSee Week 02 for this week’s activities."
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#topics",
    "href": "slides/03-slr-tidymodels.html#topics",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Topics",
    "text": "Topics\n\nIntroduce the computing toolkit - RStudio and GitHub\nUse tidymodels to fit and summarize regression models in R\nComplete an application exercise on exploratory data analysis and modeling"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#computational-setup",
    "href": "slides/03-slr-tidymodels.html#computational-setup",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(tidymodels)      # for modeling\nlibrary(fivethirtyeight) # for the fandango dataset\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#reproducibility-checklist",
    "href": "slides/03-slr-tidymodels.html#reproducibility-checklist",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Reproducibility checklist",
    "text": "Reproducibility checklist\n\nWhat does it mean for an analysis to be reproducible?\n\n\nNear term goals:\n✔️ Are the tables and figures reproducible from the code and data?\n✔️ Does the code actually do what you think it does?\n✔️ In addition to what was done, is it clear why it was done?\n\n\nLong term goals:\n✔️ Can the code be used for other data?\n✔️ Can you extend the code to do other things?"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#toolkit",
    "href": "slides/03-slr-tidymodels.html#toolkit",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Toolkit",
    "text": "Toolkit\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming (code, narrative, output in one place) \\(\\rightarrow\\) Quarto\nVersion control \\(\\rightarrow\\) Git / GitHub\n\nMore on this in this week’s lab"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#what-are-r-and-rstudio",
    "href": "slides/03-slr-tidymodels.html#what-are-r-and-rstudio",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "What are R and RStudio?",
    "text": "What are R and RStudio?\n\nR is a statistical programming language\nRStudio is a convenient interface for R (an integrated development environment, IDE)\n\n\n\nSource: Modern Dive"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#rstudio-ide",
    "href": "slides/03-slr-tidymodels.html#rstudio-ide",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "RStudio IDE",
    "text": "RStudio IDE"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#quarto",
    "href": "slides/03-slr-tidymodels.html#quarto",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Quarto",
    "text": "Quarto\n\nFully reproducible reports – the analysis is run from the beginning each time you render\nCode goes in chunks and narrative goes outside of chunks\nVisual editor to make document editing experience similar to a word processor (Google docs, Word, Pages, etc.)"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#quarto-1",
    "href": "slides/03-slr-tidymodels.html#quarto-1",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Quarto",
    "text": "Quarto"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#how-will-we-use-quarto",
    "href": "slides/03-slr-tidymodels.html#how-will-we-use-quarto",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "How will we use Quarto?",
    "text": "How will we use Quarto?\n\nEvery application exercise and assignment is written in a Quarto document\nYou’ll have a template Quarto document to start with\nThe amount of scaffolding in the template will decrease over the semester"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#application-exercise",
    "href": "slides/03-slr-tidymodels.html#application-exercise",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Application exercise",
    "text": "Application exercise\n\n📋 github.com/sta210-fa22/ae-02-bikeshare"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#recap-of-last-lecture",
    "href": "slides/03-slr-tidymodels.html#recap-of-last-lecture",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Recap of last lecture",
    "text": "Recap of last lecture\n\n\nUsed simple linear regression to describe the relationship between a quantitative predictor and quantitative outcome variable.\nUsed the least squares method to estimate the slope and intercept.\nWe interpreted the slope and intercept.\n\n\nSlope: For every one unit increase in \\(x\\), we expect y to be higher/lower by \\(\\hat{\\beta}_1\\) units, on average.\nIntercept: If \\(x\\) is 0, then we expect \\(y\\) to be \\(\\hat{\\beta}_0\\) units.\n\n\nPredicted the response given a value of the predictor variable.\nDefined extrapolation and why we should avoid it."
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#movie-ratings",
    "href": "slides/03-slr-tidymodels.html#movie-ratings",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Movie ratings",
    "text": "Movie ratings\n\n\n\nData behind the FiveThirtyEight story Be Suspicious Of Online Movie Ratings, Especially Fandango’s\nIn the fivethirtyeight package: fandango\nContains every film that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#data-prep",
    "href": "slides/03-slr-tidymodels.html#data-prep",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\nRename the dataset as movie_scores\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#tidymodels",
    "href": "slides/03-slr-tidymodels.html#tidymodels",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "tidymodels",
    "text": "tidymodels\n\nThe tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles.\n\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──\n\n\n✔ broom        1.0.5     ✔ rsample      1.1.1\n✔ dials        1.2.0     ✔ tune         1.1.1\n✔ infer        1.0.4     ✔ workflows    1.1.3\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.1\n✔ parsnip      1.1.0     ✔ yardstick    1.2.0\n✔ recipes      1.0.6     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#why-tidymodels",
    "href": "slides/03-slr-tidymodels.html#why-tidymodels",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Why tidymodels?",
    "text": "Why tidymodels?\n\nConsistent syntax for different model types (linear, logistic, random forest, Bayesian, etc.)\nStreamline modeling workflow\n\nSplit data into train and test sets\nTransform and create new variables\nAssess model performance\nUse model for prediction and inference"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#step-1-specify-model",
    "href": "slides/03-slr-tidymodels.html#step-1-specify-model",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Step 1: Specify model",
    "text": "Step 1: Specify model\n\nlinear_reg()\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#step-2-set-model-fitting-engine",
    "href": "slides/03-slr-tidymodels.html#step-2-set-model-fitting-engine",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Step 2: Set model fitting engine",
    "text": "Step 2: Set model fitting engine\n\nlinear_reg() |&gt;\n  set_engine(\"lm\") # lm: linear model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#a-closer-look-at-model-output",
    "href": "slides/03-slr-tidymodels.html#a-closer-look-at-model-output",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "A closer look at model output",
    "text": "A closer look at model output\n\nmovie_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(audience ~ critics, data = movie_scores)\n\nmovie_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = audience ~ critics, data = data)\n\nCoefficients:\n(Intercept)      critics  \n    32.3155       0.5187  \n\n\n\\[\\widehat{\\text{audience}} = 32.3155 + 0.5187 \\times \\text{critics}\\]\n\n\nNote: The intercept is off by a tiny bit from the hand-calculated intercept, this is likely just due to rounding in the hand calculation."
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#the-regression-output",
    "href": "slides/03-slr-tidymodels.html#the-regression-output",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "The regression output",
    "text": "The regression output\nWe’ll focus on the first column for now…\n\nlinear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(audience ~ critics, data = movie_scores) |&gt;\n  tidy() \n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#prediction",
    "href": "slides/03-slr-tidymodels.html#prediction",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Prediction",
    "text": "Prediction\n\n# create a data frame for a new movie\nnew_movie &lt;- tibble(critics = 70)\n\n# predict the outcome for a new movie\npredict(movie_fit, new_movie)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  68.6"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#application-exercise-1",
    "href": "slides/03-slr-tidymodels.html#application-exercise-1",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Application exercise",
    "text": "Application exercise\n\n📋 github.com/sta210-fa22/ae-02-bikeshare\n\n\n\nClose document tab"
  },
  {
    "objectID": "slides/03-slr-tidymodels.html#recap",
    "href": "slides/03-slr-tidymodels.html#recap",
    "title": "SLR: Fitting models in R with tidymodels",
    "section": "Recap",
    "text": "Recap\n\nIntroduced the computing toolkit - RStudio and GitHub\nUsed tidymodels to fit and summarize regression models in R\nCompleted an application exercise on exploratory data analysis and modeling\n\n\n\n\n🔗 Week 02"
  },
  {
    "objectID": "slides/01-welcome.html#meet-prof.-tackett",
    "href": "slides/01-welcome.html#meet-prof.-tackett",
    "title": "Welcome to STA 210!",
    "section": "Meet Prof. Tackett!",
    "text": "Meet Prof. Tackett!\n\n\nEducation and career journey\n\nBS in Math and MS in Statistics from University of Tennessee\nStatistician at Capital One\nPhD in Statistics from University of Virginia\nAssistant Professor of the Practice, Department of Statistical Science at Duke\n\nWork focuses on statistics education and sense of belonging in introductory math and statistics classes\nCo-leader of the Bass Connections team Mental Health and the Justice System in Durham County\nMom of (almost) 8-month-old twins 🙂"
  },
  {
    "objectID": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "href": "slides/01-welcome.html#meet-the-teaching-assistants-tas",
    "title": "Welcome to STA 210!",
    "section": "Meet the Teaching Assistants (TAs)",
    "text": "Meet the Teaching Assistants (TAs)\n\nSam Rosen (PhD): Head TA + Lab 01\nBethany Astor (MS): Lab 02\nJon Campbell (MS)\nDonald Cayton (MS): Lab 02\nAllison Li (UG)\nMitchelle Mojekwu (UG): Lab 04\nBen Thorpe (UG)\nLinxuan Wang (MS): Lab 03\nXiaojun Zheng (PhD): Lab 04"
  },
  {
    "objectID": "slides/01-welcome.html#what-is-regression-analysis",
    "href": "slides/01-welcome.html#what-is-regression-analysis",
    "title": "Welcome to STA 210!",
    "section": "What is regression analysis?",
    "text": "What is regression analysis?\n\n\n“In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or ‘predictors’). More specifically, regression analysis helps one understand how the typical value of the dependent variable (or ‘criterion variable’) changes when any one of the independent variables is varied, while the other independent variables are held fixed.”\n\nSource: Wikipedia (previous definition)"
  },
  {
    "objectID": "slides/01-welcome.html#examples-of-regression-in-practice",
    "href": "slides/01-welcome.html#examples-of-regression-in-practice",
    "title": "Welcome to STA 210!",
    "section": "Examples of regression in practice",
    "text": "Examples of regression in practice\n\nNew Yorkers Will Pay $56 A Month To Trim A Minute Off Their Commute\nHow FiveThirtyEight’s 2020 Presidential Forecast Works — And What’s Different Because Of COVID-19\nEffect of Forensic Evidence on Criminal Justice Case Processing\nWhy it’s so freaking hard to make a good COVID-19 model (from March 2020)"
  },
  {
    "objectID": "slides/01-welcome.html#course-faq",
    "href": "slides/01-welcome.html#course-faq",
    "title": "Welcome to STA 210!",
    "section": "Course FAQ",
    "text": "Course FAQ\nQ - What background is assumed for the course?\nA - Introductory statistics or probability course at Duke\n\nQ - Will we be doing computing?\nA - Yes. We will use the computing language R for analysis, Quarto for writing up results, and GitHub for version control and collaboration\n\n\nQ - Will we learn the mathematical theory of regression?\nA - Yes and No. The course is primarily focused on application; however, we will discuss some of the mathematics of simple linear regression. There a 0.5-credit course STA 211: Mathematics of Regression to take simultaneously or after this course to dive into more of the mathematics."
  },
  {
    "objectID": "slides/01-welcome.html#course-learning-objectives",
    "href": "slides/01-welcome.html#course-learning-objectives",
    "title": "Welcome to STA 210!",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will be able to…\n\nanalyze real-world data to answer questions about multivariable relationships.\nuse R to fit and evaluate linear and logistic regression models.\nassess whether a proposed model is appropriate and describe its limitations.\nuse Quarto to write reproducible reports and GitHub for version control and collaboration.\neffectively communicate statistical results through writing and oral presentations."
  },
  {
    "objectID": "slides/01-welcome.html#course-topics",
    "href": "slides/01-welcome.html#course-topics",
    "title": "Welcome to STA 210!",
    "section": "Course topics",
    "text": "Course topics\n\n\nUnit 1: Quantitative Response Variable\n\nSimple Linear Regression\nMultiple Linear Regression\n\n\nUnit 2: Categorical Response Variable\n\nLogistic Regression\nMultinomial logistic regression\n\n\nUnit 3: Looking Ahead\n\nSpecial topics\nPresenting statistical results"
  },
  {
    "objectID": "slides/01-welcome.html#course-toolkit",
    "href": "slides/01-welcome.html#course-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Course toolkit",
    "text": "Course toolkit\n\nCourse website: sta210-fa23.netlify.app\n\nCentral hub for the course!\nTour of the website\n\nSakai: sakai.duke.edu\n\nGradebook\nAnnouncements\nGradescope\nEd Discussion\n\nGitHub: github.com/sta210-fa23\n\nDistribute assignments\nPlatform for version control and collaboration"
  },
  {
    "objectID": "slides/01-welcome.html#computing-toolkit",
    "href": "slides/01-welcome.html#computing-toolkit",
    "title": "Welcome to STA 210!",
    "section": "Computing toolkit",
    "text": "Computing toolkit\n\n\n\n\n\n\n\n\n\n\n\nAll analyses using R, a statistical programming language\nWrite reproducible reports in Quarto\nAccess RStudio through STA 210 Docker Containers\n\n\n\n\n\n\n\n\n\n\n\n\nAccess assignments\nFacilitates version control and collaboration\nAll work in STA 210 course organization"
  },
  {
    "objectID": "slides/01-welcome.html#prepare-participate-practice-perform",
    "href": "slides/01-welcome.html#prepare-participate-practice-perform",
    "title": "Welcome to STA 210!",
    "section": "Prepare, Participate, Practice, Perform",
    "text": "Prepare, Participate, Practice, Perform\n\n\n\nPrepare: Introduce new content and prepare for lectures by completing the readings (and sometimes watching the videos)\nParticipate: Attend and actively participate in lectures and labs, office hours, team meetings\nPractice: Practice applying statistical concepts and computing with application exercises during lecture, graded for completion\nPerform: Put together what you’ve learned to analyze real-world data\n\nLab assignments (first individual, later team-based)\nHomework assignments (individual)\nTwo exams\nFinal group project"
  },
  {
    "objectID": "slides/01-welcome.html#grading",
    "href": "slides/01-welcome.html#grading",
    "title": "Welcome to STA 210!",
    "section": "Grading",
    "text": "Grading\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n35%\n\n\nFinal project\n15%\n\n\nLab\n15%\n\n\nExam 01\n15%\n\n\nExam 02\n15%\n\n\nApplication Exercises\n2.5%\n\n\nTeamwork\n2.5%\n\n\n\nSee the syllabus for details on how the final letter grade will be calculated."
  },
  {
    "objectID": "slides/01-welcome.html#support",
    "href": "slides/01-welcome.html#support",
    "title": "Welcome to STA 210!",
    "section": "Support",
    "text": "Support\n\nAttend office hours to meet with a member of the teaching team\n\nProf. Tackett’s office hours start Fri, Sep 1, 1 - 3pm\nFull office hours schedule starts Tue, Sep 5\n\nAsk and answer questions on course discussion forum\nUse email for questions regarding personal matters and/or grades\nSee the Course Support page for more details"
  },
  {
    "objectID": "slides/01-welcome.html#diversity-inclusion",
    "href": "slides/01-welcome.html#diversity-inclusion",
    "title": "Welcome to STA 210!",
    "section": "Diversity & inclusion",
    "text": "Diversity & inclusion\n\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know.\nPlease let me know your preferred pronouns, if you are comfortable sharing.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said or done in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "slides/01-welcome.html#accessibility",
    "href": "slides/01-welcome.html#accessibility",
    "title": "Welcome to STA 210!",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nIf you have documented accommodations from SDAO, please send the documentation as soon as possible.\nI am committed to making all course activities and materials accessible. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "slides/01-welcome.html#covid-19-and-other-illness",
    "href": "slides/01-welcome.html#covid-19-and-other-illness",
    "title": "Welcome to STA 210!",
    "section": "COVID-19 and other illness",
    "text": "COVID-19 and other illness\n\nPlease do not come to class if you have tested positive for COVID-19, have possible symptoms and have not yet been tested, or have other illness.\nLecture recordings are available for excused absences. See Lecture recording request in the syllabus for more information and a link to the request form.\nRead and follow the university guidelines regarding COVID-19 at coronavirus.duke.edu."
  },
  {
    "objectID": "slides/01-welcome.html#late-work-waivers-and-regrade-requests",
    "href": "slides/01-welcome.html#late-work-waivers-and-regrade-requests",
    "title": "Welcome to STA 210!",
    "section": "Late work, waivers, and regrade requests",
    "text": "Late work, waivers, and regrade requests\n\nWe have policies! We will discuss them in detail when the first assignment is released.\nRead more about them in the Course policies section of the syllabus and refer back to them as needed\nIf you have questions, email sta210@duke.edu"
  },
  {
    "objectID": "slides/01-welcome.html#academic-integrity",
    "href": "slides/01-welcome.html#academic-integrity",
    "title": "Welcome to STA 210!",
    "section": "Academic integrity",
    "text": "Academic integrity\n\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\nBy participating in this course, you are agreeing that all your work and conduct will be in accordance with the Duke Community Standard."
  },
  {
    "objectID": "slides/01-welcome.html#collaboration-sharing-code",
    "href": "slides/01-welcome.html#collaboration-sharing-code",
    "title": "Welcome to STA 210!",
    "section": "Collaboration & sharing code",
    "text": "Collaboration & sharing code\n\nWe have policies! We will discuss them in detail when the first assignment is released.\nRead about them in the Academic honesty section of the syllabus and refer to them as needed"
  },
  {
    "objectID": "slides/01-welcome.html#use-of-artificial-intelligence-ai",
    "href": "slides/01-welcome.html#use-of-artificial-intelligence-ai",
    "title": "Welcome to STA 210!",
    "section": "Use of artificial intelligence (AI)",
    "text": "Use of artificial intelligence (AI)\n\nYou should treat AI tools, such as ChatGPT, the same as other online resources.\nThere are two guiding principles that govern how you can use AI in this course:1\n\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎"
  },
  {
    "objectID": "slides/01-welcome.html#use-of-artificial-intelligence-ai-1",
    "href": "slides/01-welcome.html#use-of-artificial-intelligence-ai-1",
    "title": "Welcome to STA 210!",
    "section": "Use of artificial intelligence (AI)",
    "text": "Use of artificial intelligence (AI)\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code.\n❌ No AI tools for narrative: Unless instructed otherwise, AI is not permitted for writing narrative on assignments.\n\n\n\n\n\n\nImportant\n\n\nIn general, you may use AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content."
  },
  {
    "objectID": "slides/01-welcome.html#five-tips-for-success",
    "href": "slides/01-welcome.html#five-tips-for-success",
    "title": "Welcome to STA 210!",
    "section": "Five tips for success",
    "text": "Five tips for success\n\nComplete all the preparation work (readings and videos) before class.\nAsk questions.\nDo the homework and labs; get started on homework early when possible.\nDon’t procrastinate and don’t let a week pass by with lingering questions.\nStay up-to-date on announcements on Ed Discussion and sent via email."
  },
  {
    "objectID": "slides/01-welcome.html#application-exercise",
    "href": "slides/01-welcome.html#application-exercise",
    "title": "Welcome to STA 210!",
    "section": "Application exercise",
    "text": "Application exercise\n\n📋 AE 01 - Movie Budgets and Revenues"
  },
  {
    "objectID": "slides/01-welcome.html#for-this-week",
    "href": "slides/01-welcome.html#for-this-week",
    "title": "Welcome to STA 210!",
    "section": "For this week…",
    "text": "For this week…\n\nRead the syllabus\nSee the course schedule for an overview of the semester\nLabs start this week!\n\nSection 001: Labs on Tuesday\nSection 002: Labs on Thursday\n\nThis week’s lab is focused on introductions and computing\nWednesday’s lecture: The Big Picture\n\n\n\n\n🔗 STA 210 - Fall 2023 - Schedule"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#announcements",
    "href": "slides/04-slr-evaluation.html#announcements",
    "title": "SLR: Prediction + model evaluation",
    "section": "Announcements",
    "text": "Announcements\n\nOffice hours have started. Click here for full schedule.\nAccept the email invitation to join the sta210-fa22 GitHub organization by today at 11:59pm.\n\nYou may also go to the course organization and click to accept on the banner at the top of the page.\nIf you don’t see the email or banner invitation, please email Prof. Tackett (maria.tackett@duke.edu).\n\nLab 01 this week - will need access to RStudio and to be a member of the course GitHub organization.\nSee Week 02 for this week’s activities."
  },
  {
    "objectID": "slides/04-slr-evaluation.html#topics",
    "href": "slides/04-slr-evaluation.html#topics",
    "title": "SLR: Prediction + model evaluation",
    "section": "Topics",
    "text": "Topics\n\nMotivate the importance of model evaluation\nDescribe how \\(R^2\\) and RMSE are used to evaluate models\nAssess model’s predictive importance using data splitting and bootstrapping"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#computational-setup",
    "href": "slides/04-slr-evaluation.html#computational-setup",
    "title": "SLR: Prediction + model evaluation",
    "section": "Computational setup",
    "text": "Computational setup\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#application-exercise",
    "href": "slides/04-slr-evaluation.html#application-exercise",
    "title": "SLR: Prediction + model evaluation",
    "section": "Application exercise",
    "text": "Application exercise\n\n📋 github.com/sta210-fa22/ae-02-bikeshare"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#data-source",
    "href": "slides/04-slr-evaluation.html#data-source",
    "title": "SLR: Prediction + model evaluation",
    "section": "Data source",
    "text": "Data source\n\nThe data come from usdata::county_2019\nThese data have been compiled from the 2019 American Community Survey"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#uninsurance-rate",
    "href": "slides/04-slr-evaluation.html#uninsurance-rate",
    "title": "SLR: Prediction + model evaluation",
    "section": "Uninsurance rate",
    "text": "Uninsurance rate"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#high-school-graduation-rate",
    "href": "slides/04-slr-evaluation.html#high-school-graduation-rate",
    "title": "SLR: Prediction + model evaluation",
    "section": "High school graduation rate",
    "text": "High school graduation rate"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#examining-the-relationship",
    "href": "slides/04-slr-evaluation.html#examining-the-relationship",
    "title": "SLR: Prediction + model evaluation",
    "section": "Examining the relationship",
    "text": "Examining the relationship\n\n\nThe NC Labor and Economic Analysis Division (LEAD) “collects data, conducts research and analysis and publishes reports about the state’s economy and labor market. Information and data produced by LEAD help stakeholders make more informed decisions on business recruitment, education and workforce policies and career development, as well as gain a more extensive view of North Carolina’s economy.”\nSuppose that an analyst working for LEAD is interested in the relationship between uninsurance and high school graduation rates in NC counties.\n\n\n\n\nWhat type of visualization should the analyst make to examine the relationship between these two variables?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#data-prep",
    "href": "slides/04-slr-evaluation.html#data-prep",
    "title": "SLR: Prediction + model evaluation",
    "section": "Data prep",
    "text": "Data prep\n\ncounty_2019_nc &lt;- county_2019 |&gt;\n  as_tibble() |&gt;\n  filter(state == \"North Carolina\") |&gt;\n  select(name, hs_grad, uninsured)\n\ncounty_2019_nc\n\n# A tibble: 100 × 3\n   name             hs_grad uninsured\n   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;\n 1 Alamance County     86.3      11.2\n 2 Alexander County    82.4       8.9\n 3 Alleghany County    77.5      11.3\n 4 Anson County        80.7      11.1\n 5 Ashe County         85.1      12.6\n 6 Avery County        83.6      15.9\n 7 Beaufort County     87.7      12  \n 8 Bertie County       78.4      11.9\n 9 Bladen County       81.3      12.9\n10 Brunswick County    91.3       9.8\n# … with 90 more rows"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#uninsurance-vs.-hs-graduation-rates",
    "href": "slides/04-slr-evaluation.html#uninsurance-vs.-hs-graduation-rates",
    "title": "SLR: Prediction + model evaluation",
    "section": "Uninsurance vs. HS graduation rates",
    "text": "Uninsurance vs. HS graduation rates\n\n\nCode\nggplot(county_2019_nc,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  ) +\n  geom_point(data = county_2019_nc |&gt; filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured), shape = \"circle open\", color = \"#8F2D56\", size = 4, stroke = 2) +\n  geom_text(data = county_2019_nc |&gt; filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured, label = name), color = \"#8F2D56\", fontface = \"bold\", nudge_y = 3, nudge_x = 2)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#modeling-the-relationship",
    "href": "slides/04-slr-evaluation.html#modeling-the-relationship",
    "title": "SLR: Prediction + model evaluation",
    "section": "Modeling the relationship",
    "text": "Modeling the relationship\n\n\nCode\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#fitting-the-model",
    "href": "slides/04-slr-evaluation.html#fitting-the-model",
    "title": "SLR: Prediction + model evaluation",
    "section": "Fitting the model",
    "text": "Fitting the model\nWith fit():\n\nnc_fit &lt;- linear_reg() |&gt;\n  set_engine(\"lm\") |&gt;\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   33.9      3.99        8.50 2.12e-13\n2 hs_grad       -0.262    0.0468     -5.61 1.88e- 7"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#augmenting-the-data",
    "href": "slides/04-slr-evaluation.html#augmenting-the-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Augmenting the data",
    "text": "Augmenting the data\nWith augment() to add columns for predicted values (.fitted), residuals (.resid), etc.:\n\nnc_aug &lt;- augment(nc_fit$fit)\nnc_aug\n\n# A tibble: 100 × 8\n   uninsured hs_grad .fitted  .resid   .hat .sigma    .cooksd .std.resid\n       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1      11.2    86.3   11.3  -0.0633 0.0107   2.10 0.00000501    -0.0305\n 2       8.9    82.4   12.3  -3.39   0.0138   2.07 0.0186        -1.63  \n 3      11.3    77.5   13.6  -2.27   0.0393   2.09 0.0252        -1.11  \n 4      11.1    80.7   12.7  -1.63   0.0199   2.09 0.00633       -0.790 \n 5      12.6    85.1   11.6   1.02   0.0100   2.10 0.00122        0.492 \n 6      15.9    83.6   12.0   3.93   0.0112   2.06 0.0203         1.89  \n 7      12      87.7   10.9   1.10   0.0133   2.10 0.00191        0.532 \n 8      11.9    78.4   13.3  -1.44   0.0328   2.09 0.00830       -0.700 \n 9      12.9    81.3   12.6   0.324  0.0174   2.10 0.000218       0.157 \n10       9.8    91.3    9.95 -0.151  0.0291   2.10 0.0000806     -0.0734\n# … with 90 more rows"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-i",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-i",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model I",
    "text": "Visualizing the model I\n\n\n\n\nBlack circles: Observed values (y = uninsured)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-ii",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-ii",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model II",
    "text": "Visualizing the model II\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-iii",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-iii",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model III",
    "text": "Visualizing the model III\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line\nMaroon triangles: Predicted values (y = .fitted)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#visualizing-the-model-iv",
    "href": "slides/04-slr-evaluation.html#visualizing-the-model-iv",
    "title": "SLR: Prediction + model evaluation",
    "section": "Visualizing the model IV",
    "text": "Visualizing the model IV\n\n\n\n\nBlack circles: Observed values (y = uninsured)\nPink solid line: Least squares regression line\nMaroon triangles: Predicted values (y = .fitted)\nGray dashed lines: Residuals"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#evaluating-the-model-fit",
    "href": "slides/04-slr-evaluation.html#evaluating-the-model-fit",
    "title": "SLR: Prediction + model evaluation",
    "section": "Evaluating the model fit",
    "text": "Evaluating the model fit\n\nHow can we evaluate whether the model for predicting uninsurance rate from high school graduation rate for NC counties is a good fit?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#two-statistics",
    "href": "slides/04-slr-evaluation.html#two-statistics",
    "title": "SLR: Prediction + model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\n\n\n\nWhat indicates a good model fit? Higher or lower \\(R^2\\)? Higher or lower RMSE?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#r2",
    "href": "slides/04-slr-evaluation.html#r2",
    "title": "SLR: Prediction + model evaluation",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\nRanges between 0 (terrible predictor) and 1 (perfect predictor)\nHas no units\nCalculate with rsq() using the augmented data:\n\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.243"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#interpreting-r2",
    "href": "slides/04-slr-evaluation.html#interpreting-r2",
    "title": "SLR: Prediction + model evaluation",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\n🗳️ Vote on Ed Discussion\n\n\nThe \\(R^2\\) of the model for predicting uninsurance rate from high school graduation rate for NC counties is 24.3%. Which of the following is the correct interpretation of this value?\n\n\nHigh school graduation rates correctly predict 24.3% of uninsurance rates in NC counties.\n24.3% of the variability in uninsurance rates in NC counties can be explained by high school graduation rates.\n24.3% of the variability in high school graduation rates in NC counties can be explained by uninsurance rates.\n24.3% of the time uninsurance rates in NC counties can be predicted by high school graduation rates.\n\n\n\nVote - Section 001\nVote - Section 002"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#alternative-approach-for-r2",
    "href": "slides/04-slr-evaluation.html#alternative-approach-for-r2",
    "title": "SLR: Prediction + model evaluation",
    "section": "Alternative approach for \\(R^2\\)",
    "text": "Alternative approach for \\(R^2\\)\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(nc_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.243         0.235  2.09      31.5 0.000000188     1  -214.  435.  443.\n# … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\nglance(nc_fit)$r.squared\n\n[1] 0.2430694"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#rmse",
    "href": "slides/04-slr-evaluation.html#rmse",
    "title": "SLR: Prediction + model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nCalculate with rmse() using the augmented data:\n\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard        2.07\n\n\nThe value of RMSE is not very meaningful on its own, but it’s useful for comparing across models (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#obtaining-r2-and-rmse",
    "href": "slides/04-slr-evaluation.html#obtaining-r2-and-rmse",
    "title": "SLR: Prediction + model evaluation",
    "section": "Obtaining \\(R^2\\) and RMSE",
    "text": "Obtaining \\(R^2\\) and RMSE\n\n\nUse rsq() and rmse(), respectively\n\nrsq(nc_aug, truth = uninsured, estimate = .fitted)\nrmse(nc_aug, truth = uninsured, estimate = .fitted)\n\nFirst argument: data frame containing truth and estimate columns\nSecond argument: name of the column containing truth (observed outcome)\nThird argument: name of the column containing estimate (predicted outcome)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#purpose-of-model-evaluation",
    "href": "slides/04-slr-evaluation.html#purpose-of-model-evaluation",
    "title": "SLR: Prediction + model evaluation",
    "section": "Purpose of model evaluation",
    "text": "Purpose of model evaluation\n\n\\(R^2\\) tells us how our model is doing to predict the data we already have\nBut generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e. out-of-sample prediction\nWe have a couple ways of simulating out-of-sample prediction before actually getting new data to evaluate the performance of our models"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#spending-our-data",
    "href": "slides/04-slr-evaluation.html#spending-our-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Spending our data",
    "text": "Spending our data\n\n\nThere are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\nDoing all of this on the entire data we have available leaves us with no other data to assess our choices\nWe can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we’ve done so far)"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#simulation-data-splitting",
    "href": "slides/04-slr-evaluation.html#simulation-data-splitting",
    "title": "SLR: Prediction + model evaluation",
    "section": "Simulation: data splitting",
    "text": "Simulation: data splitting\n\n\n\n\nTake a random sample of 10% of the data and set aside (testing data)\nFit a model on the remaining 90% of the data (training data)\nUse the coefficients from this model to make predictions for the testing data\nRepeat 10 times"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#predictive-performance",
    "href": "slides/04-slr-evaluation.html#predictive-performance",
    "title": "SLR: Prediction + model evaluation",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different testing datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#bootstrapping-our-data",
    "href": "slides/04-slr-evaluation.html#bootstrapping-our-data",
    "title": "SLR: Prediction + model evaluation",
    "section": "Bootstrapping our data",
    "text": "Bootstrapping our data\n\n\nThe idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\nWith bootstrapping, we simulate resampling from the population by resampling from the sample we observed\nBootstrap samples are the sampled with replacement from the original sample and same size as the original sample\n\nFor example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc."
  },
  {
    "objectID": "slides/04-slr-evaluation.html#simulation-bootstrapping",
    "href": "slides/04-slr-evaluation.html#simulation-bootstrapping",
    "title": "SLR: Prediction + model evaluation",
    "section": "Simulation: bootstrapping",
    "text": "Simulation: bootstrapping\n\n\n\n\nTake a bootstrap sample – sample with replacement from the original data, same size as the original data\nFit model to the sample and make predictions for that sample\nRepeat many times"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#predictive-performance-1",
    "href": "slides/04-slr-evaluation.html#predictive-performance-1",
    "title": "SLR: Prediction + model evaluation",
    "section": "Predictive performance",
    "text": "Predictive performance\n\n\n\n\n\nHow consistent are the predictions for different bootstrap datasets?\nHow consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#recap",
    "href": "slides/04-slr-evaluation.html#recap",
    "title": "SLR: Prediction + model evaluation",
    "section": "Recap",
    "text": "Recap\n\nMotivated the importance of model evaluation\nDescribed how \\(R^2\\) and RMSE are used to evaluate models\nAssessed model’s predictive importance using data splitting and bootstrapping"
  },
  {
    "objectID": "slides/04-slr-evaluation.html#next-week",
    "href": "slides/04-slr-evaluation.html#next-week",
    "title": "SLR: Prediction + model evaluation",
    "section": "Next week",
    "text": "Next week\nInference on the slope using\n\nSimulation-based methods\nMathematical models\n\n\n\n\n🔗 Week 02"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#announcements",
    "href": "slides/08-slr-model-eval.html#announcements",
    "title": "SLR: Model evaluation",
    "section": "Announcements",
    "text": "Announcements\n\nHW 02 due Mon, Oct 2 at 11:59pm. (released after section 002)\nAll lecture recordings available until Wed, Oct 4 at 9am.\n\nClick here for link to videos. You can also find the link in the navigation bar of the course website.\n\nLab groups start this week. You will get your assigned group when you go to lab.\nLooking ahead: Exam 01:\n\nClosed note in-class: Wed, Oct 4\nOpen note take-home: Wed, Oct 4 - Fri, Oct 6\n\nReleased after Section 002\n\nExam review: Mon, Oct 2"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#statistician-of-the-day-robert-santos",
    "href": "slides/08-slr-model-eval.html#statistician-of-the-day-robert-santos",
    "title": "SLR: Model evaluation",
    "section": "Statistician of the day: Robert Santos",
    "text": "Statistician of the day: Robert Santos\n\n\n\n\nRobert Santos received an MA in Statistics from the University of Michigan, Ann Arbor. He served as president of the American Statistical Association in 2021. As a survey researcher, he worked at National Opinion Research Center (NORC, University of Chicago) and the Urban Institute in Washington, DC.\nAs a Mexican-American, he is the first non-white person to serve as the Director of the US Census Bureau (appointed by Joe Biden and approved by the US Senate in 2022).\nSource: hardin47.github.io/CURV/scholars/santos.html"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#robert-santos",
    "href": "slides/08-slr-model-eval.html#robert-santos",
    "title": "SLR: Model evaluation",
    "section": "Robert Santos",
    "text": "Robert Santos\nSantos is a survey researcher with much of his recent focus on the US Census. In particular, he has written extensively about miscounting particular groups of people in the Census and the relationship between race and ethnicity in surveys.\nFrom his article “Is It Time to Postpone the 2020 Census?“ (written during his time at the Urban Institute)\n\n“This would create a worst-case scenario when it comes to political representation and allocation of federal resources…And the 2020 counts would then be baked in to population projections used to calibrate federal statistics and surveys, thus informing federal funds allocations and eligibility thresholds for the next 10 years.\n\nRelated work: Interactive feature Who’s at Risk of Being Miscounted?"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#computational-set-up",
    "href": "slides/08-slr-model-eval.html#computational-set-up",
    "title": "SLR: Model evaluation",
    "section": "Computational set up",
    "text": "Computational set up\n\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(openintro)   # for the duke_forest dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#model-conditions-1",
    "href": "slides/08-slr-model-eval.html#model-conditions-1",
    "title": "SLR: Model evaluation",
    "section": "Model conditions",
    "text": "Model conditions\n\nLinearity: There is a linear relationship between the outcome and predictor variables\nConstant variance: The variability of the errors is equal for all values of the predictor variable\nNormality: The errors follow a normal distribution\nIndependence: The errors are independent from each other"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#augmented-data-frame",
    "href": "slides/08-slr-model-eval.html#augmented-data-frame",
    "title": "SLR: Model evaluation",
    "section": "Augmented data frame",
    "text": "Augmented data frame\n\ndf_fit &lt;- linear_reg() |&gt;\n  fit(price ~ area, data = duke_forest)\n\ndf_aug &lt;- augment(df_fit$fit)\n\nhead(df_aug)\n\n# A tibble: 6 × 8\n    price  area  .fitted  .resid   .hat  .sigma  .cooksd .std.resid\n    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 1520000  6040 1079931. 440069. 0.133  162605. 0.604         2.80 \n2 1030000  4475  830340. 199660. 0.0435 168386. 0.0333        1.21 \n3  420000  1745  394951.  25049. 0.0226 169664. 0.000260      0.150\n4  680000  2091  450132. 229868. 0.0157 168011. 0.0150        1.37 \n5  428500  1772  399257.  29243. 0.0220 169657. 0.000345      0.175\n6  456000  1950  427645.  28355. 0.0182 169659. 0.000266      0.170"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#two-statistics",
    "href": "slides/08-slr-model-eval.html#two-statistics",
    "title": "SLR: Model evaluation",
    "section": "Two statistics",
    "text": "Two statistics\n\n\nR-squared, \\(R^2\\) : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\\[\nR^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n\\]\nRoot mean square error, RMSE: A measure of the average error (average difference between observed and predicted values of the outcome)\n\\[\nRMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n\\]\n\n\n\n\nWhat indicates a good model fit? Higher or lower \\(R^2\\)? Higher or lower RMSE?"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#r2",
    "href": "slides/08-slr-model-eval.html#r2",
    "title": "SLR: Model evaluation",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\nRanges between 0 (terrible predictor) and 1 (perfect predictor)\nHas no units\nCalculate with rsq() using the augmented data:\n\n\nrsq(df_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rsq     standard       0.445"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#interpreting-r2",
    "href": "slides/08-slr-model-eval.html#interpreting-r2",
    "title": "SLR: Model evaluation",
    "section": "Interpreting \\(R^2\\)",
    "text": "Interpreting \\(R^2\\)\n\n🗳️ Discussion\n\n\nThe \\(R^2\\) of the model for price from area of houses in Duke Forest is 44.5%. Which of the following is the correct interpretation of this value?\n\n\nArea correctly predicts 44.5% of price for houses in Duke Forest.\n44.5% of the variability in price for houses in Duke Forest can be explained by area.\n44.5% of the variability in area for houses in Duke Forest can be explained by price\n44.5% of the time price for houses in Duke Forest can be predicted by area."
  },
  {
    "objectID": "slides/08-slr-model-eval.html#alternative-approach-for-r2",
    "href": "slides/08-slr-model-eval.html#alternative-approach-for-r2",
    "title": "SLR: Model evaluation",
    "section": "Alternative approach for \\(R^2\\)",
    "text": "Alternative approach for \\(R^2\\)\nAlternatively, use glance() to construct a single row summary of the model fit, including \\(R^2\\):\n\nglance(df_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared   sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.445         0.439 168798.      77.0 6.29e-14     1 -1318. 2641. 2649.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\nglance(df_fit)$r.squared\n\n[1] 0.4451945"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#rmse",
    "href": "slides/08-slr-model-eval.html#rmse",
    "title": "SLR: Model evaluation",
    "section": "RMSE",
    "text": "RMSE\n\n\nRanges between 0 (perfect predictor) and infinity (terrible predictor)\nSame units as the response variable\nCalculate with rmse() using the augmented data:\n\nrmse(df_aug, truth = price, estimate = .fitted)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard     167067.\n\n\nThe value of RMSE is not very meaningful on its own, but it’s useful for comparing across models (more on this when we get to regression with multiple predictors)"
  },
  {
    "objectID": "slides/08-slr-model-eval.html#obtaining-r2-and-rmse",
    "href": "slides/08-slr-model-eval.html#obtaining-r2-and-rmse",
    "title": "SLR: Model evaluation",
    "section": "Obtaining \\(R^2\\) and RMSE",
    "text": "Obtaining \\(R^2\\) and RMSE\n\n\nUse rsq() and rmse(), respectively\n\nrsq(df_aug, truth = price, estimate = .fitted)\nrmse(df_aug, truth = price, estimate = .fitted)\n\nFirst argument: data frame containing truth and estimate columns\nSecond argument: name of the column containing truth (observed outcome)\nThird argument: name of the column containing estimate (predicted outcome)"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 on Duke Container Manager\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nDiscussion forum\n🔗 on Ed Discussion\n\n\nAssignment submission\n🔗 on Gradescope\n\n\nZoom links\n🔗 on Sakai"
  },
  {
    "objectID": "project-tips.html",
    "href": "project-tips.html",
    "title": "Final project tips + resources",
    "section": "",
    "text": "Data sources\n\nSome resources that may be helpful as you find data:\n\nR Data Sources for Regression Analysis\nFiveThirtyEight data\nTidyTuesday\n\n\n\nOther data repositories\n\nWorld Health Organization\nThe National Bureau of Economic Research\nInternational Monetary Fund\nGeneral Social Survey\nUnited Nations Data\nUnited Nations Statistics Division\nU.K. Data\nU.S. Data\nU.S. Census Data\nEuropean Statistics\nStatistics Canada\nPew Research\nUNICEF\nCDC\nWorld Bank\nElection Studies\n\n\n\n\nTips\n\nAsk questions if any of the expectations are unclear.\nCode: In your write up your code should be hidden (echo = FALSE) so that your document is neat and easy to read. However your document should include all your code such that if I re-knit your Qmd file I should be able to obtain the results you presented.\n\nException: If you want to highlight something specific about a piece of code, you’re welcome to show that portion.\n\nMerge conflicts will happen, issues will arise, and that’s fine! Commit and push often, and ask questions when stuck.\nMake sure each team member is contributing, both in terms of quality and quantity of contribution (we will be reviewing commits from different team members).\nAll team members are expected to contribute equally to the completion of this assignment and group assessments will be given at its completion - anyone judged to not have sufficient contributed to the final product will have their grade penalized. While different teams members may have different backgrounds and abilities, it is the responsibility of every team member to understand how and why all code and approaches in the assignment works.\n\n\n\nFormatting + communication tips\n\nSuppress Code, Warnings, & Messages\n\nInclude the following code in a code chunk at the top of your .qmd file to suppress all code, warnings, and other messages. Use the code chunk header {r set-up, include = FALSE} to suppress this set up code.\n\nknitr::opts_chunk$set(echo = FALSE,\n                      warning = FALSE, \n                      message = FALSE)\n\nAn alternative approach is to add the following code to the YAML:\n\nexecute:\n  echo: false\n  warning: false\n  message: false\n\n\n\n\nHeaders\n\nUse headers to clearly label each section. Make sure there is a space between the last # and the title, so the header renders correctly. For example, ###Section Title will not render as header, but ### Section Title will.\n\n\n\nReferences\n\nInclude all references in a section called “References” at the end of the report.\nThis course does not have specific requirements for formatting citations and references.\n\n\n\nAppendix\n\nIf you have additional work that does not fit or does not belong in the body of the report, you may put it at the end of the document in section called “Appendix”.\nThe items in the appendix should be properly labeled.\nThe appendix should only be for additional material. The reader should be able to fully understand your report without viewing content in the appendix.\n\n\n\nResize figures\n\nResize plots and figures, so you have more space for the narrative.\n\nResize individual figures: Use the code chunk header {r plot1, fig.height = 3, fig.width = 5}, replacing plot1 with a meaningful label and the height and width with values appropriate for your write up.\nResize all figures: Include the fig_width and fig_height options in your YAML header as shown below:\n\n\n\n---\ntitle: \"Your Title\"\nauthor: \"Team Name + Group Members\"\noutput: \n  pdf_document:\n    fig_width: 5\n    fig_height: 3\n---\nReplace the height and width values with values appropriate for your write up.\n\n\nArranging plots\nArrange plots in a grid, instead of one after the other. This is especially useful when displaying plots for exploratory data analysis and to check assumptions.\n\nIf you’re using ggplot2 functions, the patchwork package makes it easy to arrange plots in a grid. See the documentation and examples here.\nIf you’re using base R function, i.e. when using the emplogit functions, put the code par(mfrow = c(rows,columns)) before the code to make the plots. For example, par(mfrow = c(2,3)) will arrange plots in a grid with 2 rows and 3 columns.\n\n\n\nPlot titles and axis labels\nBe sure all plot titles and axis labels are visible and easy to read.\n\nUse informative titles, not variable names, for titles and axis labels.\nUse coord_flip() to flip the x and y axes on the plot. This is useful if you a bar plot with an x-axis that is difficult to read due to overlapping text.\n\n❌ NO! The x-axis is hard to read because the names overlap.\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar()\n\n\n\n\n✅ YES! Names are readable\n\nggplot(data = mpg, aes(x = manufacturer)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\nDo a little more to make the plot look professional!\n\nInformative title and axis labels\nFlipped coordinates to make names readable\nArranged bars based on count\nCapitalized manufacturer names\nOptional: Added color - Use a coordinated color scheme throughout paper / presentation\nOptional: Applied a theme - Use same theme throughout paper / presentation\n\n\nmpg |&gt;\n  count(manufacturer) |&gt;\n  mutate(manufacturer = str_to_title(manufacturer)) |&gt;\n  ggplot(aes(x = fct_reorder(manufacturer,n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  coord_flip() +\n  labs(x = \"Manufacturer\", \n       y = \"Count\", \n       title = \"The most common manufacturer is Dodge\") +\n  theme_bw() \n\n\n\n\n\n\nTables and model output\n\nUse the kable function from the knitr package to neatly output all tables and model output. This will also ensure all model coefficients are displayed.\n\nUse the digits argument to display only 3 or 4 significant digits.\nUse the caption argument to add captions to your table.\n\n\n\nmodel &lt;- lm(mpg ~ hp, data = mtcars)\ntidy(model) |&gt;\n  kable(digits = 3)\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n30.099\n1.634\n18.421\n0\n\n\nhp\n-0.068\n0.010\n-6.742\n0\n\n\n\n\n\n\n\nGuidelines for communicating results\n\nDon’t use variable names in your narrative! Use descriptive terms, so the reader understands your narrative without relying on the data dictionary.\n\n❌ There is a negative linear relationship between mpg and hp.\n✅ There is a negative linear relationship between a car’s fuel economy (in miles per gallon) and its horsepower.\n\nKnow your audience: Your report should be written for a general audience who has an understanding of statistics at the level of STA 210.\nAvoid subject matter jargon: Don’t assume the audience knows all of the specific terminology related to your subject area. If you must use jargon, include a brief definition the first time you introduce a term.\nTell the “so what”: Your report and presentation should be more than a list of interpretations and technical definitions. Focus on what the results mean, i.e. what you want the audience to know about your topic after reading your report or viewing your presentation.\n\n❌ For every one unit increase in horsepower, we expect the miles per gallon to decrease by 0.068 units, on average.\n✅ If the priority is to have good fuel economy, then one should choose a car with lower horsepower. Based on our model, the fuel economy is expected to decrease, on average, by 0.68 miles per gallon for every 10 additional horsepower.\n\nTell a story: All visualizations, tables, model output, and narrative should tell a cohesive story!\nUse one voice: Though multiple people are writing the report, it should read as if it’s from a single author. At least one team member should read through the report before submission to ensure it reads like a cohesive document.\n\n\n\n\nAdditional resources\n\nExploring RStudio’s Visual Markdown Editor\nR for Data Science\nQuarto documentation:\n\nQuarto PDF Basics\nPresentations in Quarto\n\nData visualization\n\nggplot2 Reference\nggplot2: Elegant Graphics for Data Analysis\nData Visualization: A Practice Introduction\nPatchwork R Package"
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers).\n\nIf the status shows something other than Operational, this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course forum to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!\nIf the status shows Operational, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course forum with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots)."
  }
]